\chapter{教程}
\section{术语}

首先，让我们介绍一些将在文档中使用的术语：

\emph{语义动作} 是与解析器相关联的任意逻辑片段，仅在解析器匹配时执行。

简单的解析器可以组合形成更复杂的解析器。给定一些组合操作 \ci{C}，以及解析器 \texttt{P0}、\texttt{P1}、...、\texttt{PN}，\texttt{C(P0, P1, ... PN)} 创建一个新的解析器 \texttt{Q}。这会创建一个 \emph{解析树}。 \texttt{Q} 是 \texttt{P1} 的父节点，\texttt{P2} 是 \texttt{Q} 的子节点，等等。解析器按照这种拓扑结构自上而下地应用。当你使用 \texttt{Q} 解析字符串时，它将使用 \texttt{P0}、\texttt{P1} 等来完成实际工作。如果 \texttt{P3} 正在解析输入，这意味着 \texttt{Q} 也在解析，因为 \texttt{Q} 的解析方式是通过派遣其子节点来完成部分或全部工作。在解析的任何时刻，只有一个没有子节点的解析器正在解析输入；所有其他正在使用的解析器都是解析树中的祖先节点。

\emph{子解析器} 是另一个解析器的子节点的解析器。

\emph{顶级解析器} 是解析器树的根节点。

\emph{当前解析器} 或 \emph{最底层解析器} 是当前用于解析输入的没有子节点的解析器。

\emph{规则} 是一种解析器，使构建大型复杂解析器变得更容易。 \emph{子规则} 是某个其他规则的子节点的规则。 \emph{当前规则} 或 \emph{最底层规则} 是当前用于解析输入且没有子规则的规则。请注意，虽然始终只有一个当前解析器，但可能有也可能没有当前规则——规则是一种解析器，你可能在解析的某个点上使用它，也可能不使用。

\emph{顶级解析} 是由顶级解析器执行的解析操作。这个术语是必要的，因为尽管大多数解析失败是特定解析器的局部失败，但有些解析失败会导致 \texttt{parse()} 调用指示整个解析失败。对于这些情况，我们说这种局部失败“导致顶级解析失败”。

在 Boost.Parser 文档中，我将提到“对 \texttt{parse()} 的调用”。将其理解为“对 \texttt{parse()} API 中描述的任何一个函数的调用”。这包括 \texttt{prefix\_parse()}、\texttt{callback\_parse()} 和 \texttt{callback\_prefix\_parse()}。

在本文档中经常出现一些特殊类型的解析器。

其中一个是 \emph{序列解析器}；你会看到它使用 \texttt{operator>>} 创建，如 \texttt{p1 >> p2 >> p3}。序列解析器尝试按顺序将其所有子解析器匹配到输入；如果所有子解析器都匹配，则匹配输入。

另一个是 \emph{选择解析器}；你会看到它使用 \texttt{operator|} 创建，如 \texttt{p1 | p2 | p3}。选择解析器尝试按顺序将其所有子解析器匹配到输入；它在最多匹配一个子解析器后停止。如果其中一个子解析器匹配，则匹配输入。

最后是 \emph{排列解析器}；它使用 \texttt{operator||} 创建，如 \texttt{p1 || p2 || p3}。排列解析器尝试以任意顺序将其所有子解析器匹配到输入。因此，解析器 \texttt{p1 || p2 || p3} 等价于 \texttt{(p1 >> p2 >> p3) | (p1 >> p3 >> p2) | (p2 >> p1 >> p3) | (p2 >> p3 >> p1) | (p3 >> p1 >> p2) | (p3 >> p2 >> p1)}。希望它的简洁性是不言自明的。如果所有子解析器都匹配，则匹配输入，无论它们匹配的顺序如何。

Boost.Parser 的解析器每个都有一个 \emph{属性} 与之关联，或者明确没有属性。属性是解析器在匹配输入时生成的值。例如，解析器 \texttt{double\_} 在匹配输入时生成一个 \texttt{double}。 \emph{\texttt{ATTR}}\texttt{()} 是一个概念上的宏，它扩展为传递给它的解析器的属性类型；\emph{\texttt{ATTR}}\texttt{(double\_)} 是 \texttt{double}。这类似于 \texttt{attribute} 类型特征。

接下来，我们将看一些使用 Boost.Parser 进行解析的简单程序。我们将从小处开始，然后逐步构建。

\subsection{你好，任何人}

这是使用 Boost.Parser 编写的最简约的示例之一。我们从命令行获取一个字符串，如果没有给定，则使用 \texttt{"World"}，然后我们解析它：

\begin{code}
#include <boost/parser/parser.hpp>

#include <iostream>
#include <string>


namespace bp = boost::parser;

int main(int argc, char const * argv[])
{
    std::string input = "World";
    if (1 < argc)
        input = argv[1];

    std::string result;
    bp::parse(input, *bp::char_, result);
    std::cout << "Hello, " << result << "!\n";
}
\end{code}

表达式 \texttt{*bp::char\_} 是一个解析器表达式。它使用了 Boost.Parser 提供的众多解析器之一：\texttt{char\_}。像所有 Boost.Parser 解析器一样，它有一些定义的操作。在这种情况下，\texttt{*bp::char\_} 使用了重载的 \texttt{operator*} 作为 C++ 版本的 Kleene 星操作符。由于 C++ 没有后缀一元 \texttt{*} 操作符，我们必须使用现有的操作符，所以它被用作前缀。

因此，\texttt{*bp::char\_} 的意思是“任意数量的字符”。换句话说，它实际上不会失败。即使是空字符串也会匹配。

解析操作是通过调用 \texttt{parse()} 函数来执行的，将解析器作为参数之一传递：

\begin{code}
bp::parse(input, *bp::char_, result);
\end{code}

这里的参数是：\texttt{input}，要解析的范围；\texttt{*bp::char\_}，用于解析的解析器；以及 \texttt{result}，一个用于存放解析结果的输出参数。不要过于纠结于这种从 \texttt{parse()} 获取解析结果的方法；有多种方法可以做到这一点，我们将在后续章节中介绍所有这些方法。

另外，暂时忽略 Boost.Parser 如何确定 \texttt{*bp::char\_} 解析器的结果类型是 \texttt{std::string} 的事实。对此有明确的规则，我们稍后会介绍。

这次调用 \texttt{parse()} 的效果并不太有趣——因为我们给它的解析器永远不会失败，并且因为我们将输出放在与输入相同的类型中，它只是将 \texttt{input} 的内容复制到 \texttt{result} 中。

\subsection{一个简单的示例}

让我们看一个稍微复杂一点的示例，即使它仍然很简单。我们不再接受任意的 \texttt{char}，而是要求一些结构。我们来解析一个或多个用逗号分隔的 \texttt{double}。

Boost.Parser 的 \texttt{double} 解析器是 \texttt{double\_}。所以，要解析一个 \texttt{double}，我们只需使用它。如果我们想连续解析两个 \texttt{double}，我们会使用：

\begin{code}
boost::parser::double_ >> boost::parser::double_
\end{code}

这个表达式中的 \texttt{operator>>} 是序列操作符；可以将其理解为“后跟”。如果我们将序列操作符与 \ci{Kleene *}结合起来，我们可以通过编写以下代码来获得我们想要的解析器：

\begin{code}
boost::parser::double_ >> *(',' >> boost::parser::double_)
\end{code}

这是一个匹配至少一个 \texttt{double} 的解析器——因为上面表达式中的第一个 \texttt{double\_}——后跟零个或多个逗号后跟一个 \texttt{double} 的实例。注意我们可以直接使用 \ci{','}。尽管它不是解析器，\texttt{operator>>} 和定义在 Boost.Parser 解析器上的其他操作符有接受字符/解析器对参数的重载；这些操作符重载将创建正确的解析器来识别 \ci{','}。

\begin{code}
#include <boost/parser/parser.hpp>

#include <iostream>
#include <string>


namespace bp = boost::parser;

int main()
{
    std::cout << "Enter a list of doubles, separated by commas.  No pressure. ";
    std::string input;
    std::getline(std::cin, input);

    auto const result = bp::parse(input, bp::double_ >> *(',' >> bp::double_));

    if (result) {
        std::cout << "Great! It looks like you entered:\n";
        for (double x : *result) {
            std::cout << x << "\n";
        }
    } else {
        std::cout
            << "Good job!  Please proceed to the recovery annex for cake.\n";
    }
}
\end{code}

第一个示例使用了一个输出参数来传递解析结果。这次对 \texttt{parse()} 的调用则返回一个结果。如你所见，结果可以上下文转换为 \texttt{bool}，并且 \texttt{*result} 是某种范围。实际上，这次对 \texttt{parse()} 的调用返回的类型是 \texttt{std::optional<std::vector<double>>}。自然地，如果解析失败，则返回 \texttt{std::nullopt}。稍后我们将看看 Boost.Parser 如何将解析器的类型映射到返回类型或填充的输出参数的类型。

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Note \\
有一个类型特征可以告诉你解析器的属性类型，即 \texttt{attribute}（以及一个相关的别名 \texttt{attribute\_t}）。我们将在属性生成部分详细讨论它。 & \\
\end{longtable}

If I run it in a shell, this is the result:

\begin{code}
$ example/trivial
Enter a list of doubles, separated by commas.  No pressure. 5.6,8.9
Great! It looks like you entered:
5.6
8.9
$ example/trivial
Enter a list of doubles, separated by commas.  No pressure. 5.6, 8.9
Good job!  Please proceed to the recovery annex for cake.
\end{code}

它无法识别 \texttt{"5.6, 8.9"}。这是因为它期望逗号后面 \emph{立即} 跟一个 \texttt{double}，但我在逗号后插入了一个空格。如果我在逗号前、逗号前后或 \texttt{double} 列表前后放置空格，也会发生同样的解析失败。

还有一件事：有一种更好的方法来编写上面的解析器。我们可以不重复 \texttt{double\_} 子解析器，而是这样写：

\begin{code}
bp::double_ % ','
\end{code}

这在语义上等同于 \texttt{bp::double\_ >> *(',' >> bp::double\_)}。这种模式——一些输入重复一次或多次，每个实例之间有一个分隔符——非常常见，因此有一个专门的操作符 \texttt{operator\%}。从现在开始我们将使用这个操作符。

\subsection{一个优雅处理空白的简单示例}

让我们修改刚才看到的简单解析器，以忽略在 \texttt{double} 和逗号之间可能出现的任何空格。为了在任何地方跳过空白字符，我们可以将一个 \emph{跳过解析器} 传递给 \texttt{parse()} 调用（我们不需要修改传递给 \texttt{parse()} 的解析器）。在这里，我们使用 \texttt{ws}，它匹配任何 Unicode 空白字符。

\begin{code}
#include <boost/parser/parser.hpp>

#include <iostream>
#include <string>


namespace bp = boost::parser;

int main()
{
    std::cout << "Enter a list of doubles, separated by commas.  No pressure. ";
    std::string input;
    std::getline(std::cin, input);

    auto const result = bp::parse(input, bp::double_ % ',', bp::ws);

    if (result) {
        std::cout << "Great! It looks like you entered:\n";
        for (double x : *result) {
            std::cout << x << "\n";
        }
    } else {
        std::cout
            << "Good job!  Please proceed to the recovery annex for cake.\n";
    }
}
\end{code}

跳过解析器，或称 \emph{skipper}，在传递给 \texttt{parse()} 的解析器中的子解析器之间运行。在这种情况下，skipper 在解析第一个 \texttt{double} 之前、在解析任何后续的逗号或 \texttt{double} 之前以及在结束时运行。因此，字符串 \texttt{"3.6,5.9"} 和 \texttt{" 3.6 , \textbackslash{}t 5.9 "} 被这个程序解析的结果是相同的。

跳过是 Boost.Parser 中的一个重要概念。你可以跳过任何东西，不仅仅是空白字符；还有很多其他你可能想跳过的东西。传递给 \texttt{parse()} 的 skipper 可以是任意解析器。例如，如果你为脚本语言编写解析器，你可以编写一个 skipper 来跳过空白字符、内联注释和行尾注释。

在接下来的文档中，我们几乎会专门使用跳过解析器。忽略输入中你不关心的部分的能力是如此方便，以至于在实际操作中不使用跳过解析的情况很少见。

\subsection{语义动作}

像所有解析系统（lex \& yacc、Boost.Spirit 等）一样，Boost.Parser 有一种机制可以将语义动作与解析的不同部分关联起来。这里是与我们在前一个示例中看到的几乎相同的程序，只是它是通过一个语义动作来实现的，该动作将每个解析的 \texttt{double} 附加到结果中，而不是自动构建和返回结果。为此，我们将前一个示例中的 \texttt{double\_} 替换为 \texttt{double\_{[}action{]}}；\texttt{action} 是我们的语义动作：

\begin{code}
#include <boost/parser/parser.hpp>

#include <iostream>
#include <string>


namespace bp = boost::parser;

int main()
{
    std::cout << "Enter a list of doubles, separated by commas. ";
    std::string input;
    std::getline(std::cin, input);

    std::vector<double> result;
    auto const action = [&result](auto & ctx) {
        std::cout << "Got one!\n";
        result.push_back(_attr(ctx));
    };
    auto const action_parser = bp::double_[action];
    auto const success = bp::parse(input, action_parser % ',', bp::ws);

    if (success) {
        std::cout << "You entered:\n";
        for (double x : result) {
            std::cout << x << "\n";
        }
    } else {
        std::cout << "Parse failure.\n";
    }
}
\end{code}

Run in a shell, it looks like this:

\begin{code}
$ example/semantic_actions
Enter a list of doubles, separated by commas. 4,3
Got one!
Got one!
You entered:
4
3
\end{code}

在 Boost.Parser 中，语义动作是通过可调用对象实现的，这些对象接受一个解析上下文对象作为参数。解析上下文对象表示当前的解析状态。在示例中，我们使用了这个 lambda 作为我们的可调用对象：

\begin{code}
auto const action = [&result](auto & ctx) {
    std::cout << "Got one!\n";
    result.push_back(_attr(ctx));
};
\end{code}

我们在 lambda 中同时打印一条消息到 \texttt{std::cout} 并记录解析结果。如果你愿意，它可以做这两件事中的任意一件或都不做。我们通过向解析上下文请求解析的 \texttt{double} 来在 lambda 中获取它。 \texttt{\_attr(ctx)} 是你向解析上下文请求解析器生成的属性的方式。还有很多类似 \texttt{\_attr()} 的函数可以用来访问解析上下文中的状态。我们稍后会介绍更多这些函数。解析上下文定义了解析上下文的具体内容及其工作方式。

注意，你不能直接将一个未修饰的 lambda 写为语义动作。否则，编译器会看到两个 \texttt{'{[}'} 字符并认为它即将解析一个属性。使用括号可以解决这个问题：

\begin{code}
p[([](auto & ctx){/*...*/})]
\end{code}

在你这样做之前，请注意，你编写的作为语义动作的 lambda 函数几乎总是通用的（具有 \texttt{auto \& ctx} 参数），因此非常频繁地可重用。大多数你编写的语义动作 lambda 函数应该写在行外，并给它们一个好的名字。即使它们不被重用，命名的 lambda 也能使你的解析器更小、更易读。

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Important \\
Attaching a semantic action to a parser removes its attribute. That is, \emph{\texttt{ATTR}}\texttt{(p{[}a{]})} is always the special no-attribute type \texttt{none}, regardless of what type \emph{\texttt{ATTR}}\texttt{(p)} is. & \\
\end{longtable}

\subsubsection{规则中的语义动作}

在 \texttt{rules} 中使用语义动作时，还有一些其他形式。详情请参见“更多关于规则”的部分。

\subsection{解析以查找子范围}

到目前为止，我们已经看到了解析一些文本并生成相关属性的示例。有时，你想找到输入中包含你要查找内容的某个子范围，而不想生成属性。

有两个 \emph{指令} 会影响任何解析器的属性类型，\texttt{raw{[}{]}} 和 \texttt{string\_view{[}{]}}。（我们将在后面的指令部分详细介绍指令。现在，你只需要知道指令包装一个解析器，并改变其某些功能方面。）

\subsubsection{raw{[}{]}}

\texttt{raw{[}{]}} 将其解析器的属性更改为一个 \texttt{subrange}，其 \texttt{begin()} 和 \texttt{end()} 返回匹配 \texttt{p} 的序列的边界。

\begin{code}
namespace bp = boost::parser;
auto int_parser = bp::int_ % ',';            // ATTR(int_parser) is std::vector<int>
auto subrange_parser = bp::raw[int_parser];  // ATTR(subrange_parser) is a subrange

// Parse using int_parser, generating integers.
auto ints = bp::parse("1, 2, 3, 4", int_parser, bp::ws);
assert(ints);
assert(*ints == std::vector<int>({1, 2, 3, 4}));

// Parse again using int_parser, but this time generating only the
// subrange matched by int_parser.  (prefix_parse() allows matches that
// don't consume the entire input.)
auto const str = std::string("1, 2, 3, 4, a, b, c");
auto first = str.begin();
auto range = bp::prefix_parse(first, str.end(), subrange_parser, bp::ws);
assert(range);
assert(range->begin() == str.begin());
assert(range->end() == str.begin() + 10);

static_assert(std::is_same_v<
              decltype(range),
              std::optional<bp::subrange<std::string::const_iterator>>>);
\end{code}

请注意，\texttt{subrange} 的迭代器类型是 \texttt{std::string::const\_iterator}，因为这是传递给 \texttt{prefix\_parse()} 的迭代器类型。如果我们传递 \texttt{char const *} 迭代器给 \texttt{prefix\_parse()}，那将是迭代器类型。唯一的例外来自支持 Unicode 的解析（参见 Unicode 支持）。在某些情况下，解析中使用的迭代器不是你传递的那个。例如，如果你用 \texttt{char8\_t *} 迭代器调用 \texttt{prefix\_parse()}，它将创建一个从 UTF-8 到 UTF-32 的转码视图，并解析该视图的迭代器。在这种情况下，你会得到一个迭代器类型为转码迭代器的 \texttt{subrange}。当这种情况发生时，你可以通过调用返回的 \texttt{subrange} 中每个转码迭代器的 \texttt{.base()} 成员函数来获取底层迭代器——即你传递给 \texttt{prefix\_parse()} 的那个迭代器。

\begin{code}
auto const u8str = std::u8string(u8"1, 2, 3, 4, a, b, c");
auto u8first = u8str.begin();
auto u8range = bp::prefix_parse(u8first, u8str.end(), subrange_parser, bp::ws);
assert(u8range);
assert(u8range->begin().base() == u8str.begin());
assert(u8range->end().base() == u8str.begin() + 10);
\end{code}

\subsubsection{string\_view{[}{]}}

\texttt{string\_view{[}{]}} 的语义与 \texttt{raw{[}{]}} 非常相似，不同之处在于它生成一个 \texttt{std::basic\_string\_view<CharT>}（其中 \texttt{CharT} 是正在解析的底层范围的类型），而不是 \texttt{subrange}。为了使其工作，底层范围必须是连续的。在 C++20 之前无法检测迭代器的连续性，因此此指令仅在 C++20 及更高版本中可用。

\begin{code}
namespace bp = boost::parser;
auto int_parser = bp::int_ % ',';              // ATTR(int_parser) is std::vector<int>
auto sv_parser = bp::string_view[int_parser];  // ATTR(sv_parser) is a string_view

auto const str = std::string("1, 2, 3, 4, a, b, c");
auto first = str.begin();
auto sv1 = bp::prefix_parse(first, str.end(), sv_parser, bp::ws);
assert(sv1);
assert(*sv1 == str.substr(0, 10));

static_assert(std::is_same_v<decltype(sv1), std::optional<std::string_view>>);
\end{code}

由于 \texttt{string\_view{[}{]}} 生成 \texttt{string\_view}，它不能像上面描述的 \texttt{raw{[}{]}} 那样返回转码迭代器。如果你用 \texttt{string\_view{[}{]}} 解析一个 \texttt{CharT} 序列，你会得到一个 \texttt{std::basic\_string\_view<CharT>}。如果解析使用了 Unicode 感知路径中的转码，\texttt{string\_view{[}{]}} 将根据需要分解转码迭代器。如果你将转码视图传递给 \texttt{parse()} 或将转码迭代器传递给 \texttt{prefix\_parse()}，\texttt{string\_view{[}{]}} 仍然会透过转码迭代器并给你一个底层范围部分的 \texttt{string\_view}。

\begin{code}
auto sv2 = bp::parse("1, 2, 3, 4" | bp::as_utf32, sv_parser, bp::ws);
assert(sv2);
assert(*sv2 == "1, 2, 3, 4");

static_assert(std::is_same_v<decltype(sv2), std::optional<std::string_view>>);
\end{code}

\subsection{解析上下文}

现在是详细描述解析上下文的好时机。你编写的任何语义动作都需要使用解析上下文中的状态，所以你需要知道有哪些可用的内容。

解析上下文是一个存储当前解析状态的对象——当前迭代器和结束迭代器、错误处理程序等。数据可能会在解析过程中“添加”到或“移除”出解析上下文。例如，当一个带有语义动作 \texttt{a} 的解析器 \texttt{p} 成功时，解析上下文会将 \texttt{p} 生成的属性添加到解析上下文中，然后调用 \texttt{a}，并将上下文传递给它。

尽管解析上下文对象似乎有东西被添加或移除，但实际上并没有一个单一的上下文对象。上下文是在解析过程中在不同时间点形成的，通常是在启动子解析器时。每个上下文都是通过获取前一个上下文并根据需要添加或更改成员来形成一个新的上下文对象。当包含新上下文对象的函数返回时，其上下文对象（如果有的话）会被析构。这种操作是高效的，因为解析上下文只有大约十二个数据成员，每个数据成员的大小都小于或等于一个指针的大小。因此，在修改上下文时复制整个上下文是快速的。解析上下文不进行内存分配。

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Tip \\
所有这些以解析上下文作为第一个参数的函数都可以通过参数依赖查找（Argument-Dependent Lookup）找到。你可能永远不需要用 \texttt{boost::parser::} 来限定它们。 & \\
\end{longtable}

\subsubsection{Accessors for data that are always available}

By convention, the names of all Boost.Parser functions that take a parse context, and are therefore intended for use inside semantic actions, contain a leading underscore.

\subsubsection{\_pass()}

\texttt{\_pass()} returns a reference to a \texttt{bool} indicating the success of failure of the current parse. This can be used to force the current parse to pass or fail:

\begin{code}
[](auto & ctx) {
    // If the attribute fails to meet this predicate, fail the parse.
    if (!necessary_condition(_attr(ctx)))
        _pass(ctx) = false;
}
\end{code}

请注意，要执行语义动作，其关联的解析器必须已经成功。因此，除非你之前在动作中写了 \texttt{\_pass(ctx) = false}，否则 \texttt{\_pass(ctx) = true} 没有任何作用；它是多余的。

\subsubsection{\_begin()、\_end() 和 \_where()}

\texttt{\_begin()} 和 \texttt{\_end()} 分别返回传递给 \texttt{parse()} 的范围的开始和结束。 \texttt{\_where()} 返回一个 \texttt{subrange}，表示当前解析匹配的输入范围的边界。如果你只想解析一些文本并返回某些元素的位置而不生成任何其他属性，\texttt{\_where()} 会很有用。 \texttt{\_where()} 也可以在跟踪元素位置时至关重要，以便在解析的后期提供良好的诊断。想想 XML 中的不匹配标签；如果你在元素的末尾解析一个关闭标签，并且它与打开标签不匹配，你会希望生成一条提到或显示两个标签的错误消息。将 \texttt{\_where(ctx).begin()} 存储在关闭标签解析器可用的某个地方将实现这一点。有关示例，请参见错误处理和调试。

\subsubsection{\_error\_handler()}

\texttt{\_error\_handler()} 返回一个引用，指向与传递给 \texttt{parse()} 的解析器关联的错误处理程序。使用 \texttt{\_error\_handler()}，你可以从语义动作中生成错误和警告。有关具体示例，请参见错误处理和调试。

\subsubsection{仅在某些情况下可用的数据访问器}

\subsubsection{\_attr()}

\texttt{\_attr()} 返回对当前解析器属性值的引用。仅当当前解析器的解析成功时才可用。如果解析器没有语义动作，则不会将任何属性添加到解析上下文中。它可以用来读取和写入当前解析器的属性：

\begin{code}
[](auto & ctx) { _attr(ctx) = 3; }
\end{code}

如果当前解析器没有属性，则返回 \texttt{none}。

\subsubsection{\_val()}

\texttt{\_val()} 返回对当前规则的属性值的引用（如果有），即使在规则的解析成功之前也可用。它可以用来设置当前规则的属性，即使是在规则内的子解析器中。假设我们正在编写一个带有语义动作的解析器，该动作在一个规则内。如果我们想将当前规则的值设置为子解析器属性的某个函数，我们会编写这个语义动作：

\begin{code}
[](auto & ctx) { _val(ctx) = some_function(_attr(ctx)); }
\end{code}

如果没有当前规则，或者当前规则没有属性，则返回 \texttt{none}。

当 \texttt{rule} 的解析器的默认属性与 \texttt{rule} 的属性类型不直接兼容时，你需要使用 \texttt{\_val()}。在这些情况下，你需要编写类似上面示例的代码，以从 \texttt{rule} 的解析器生成的属性计算 \texttt{rule} 的属性。有关 \texttt{rules} 的更多信息，请参见下一页和更多关于规则的内容。

\subsubsection{\_globals()}

\texttt{\_globals()} 返回对用户提供的对象的引用，该对象包含你希望在解析期间使用的任何数据。解析的“全局变量”是一个对象——通常是一个结构体——你提供给顶级解析器。然后你可以在解析期间随时使用 \texttt{\_globals()} 访问它。我们将在后面的 \texttt{parse()} API 中看到全局变量如何与顶级解析器关联。例如，假设你在解析的早期部分需要记录一些黑名单值，而解析的后期部分可能需要解析值，如果看到黑名单值则解析失败。在解析的早期部分，你可以编写类似这样的代码。

\begin{code}
[](auto & ctx) {
    // black_list is a std::unordered_set.
    _globals(ctx).black_list.insert(_attr(ctx));
}
\end{code}

Later in the parse, you could then use \texttt{black\_list} to check values as they are parsed.

\begin{code}
[](auto & ctx) {
    if (_globals(ctx).black_list.contains(_attr(ctx)))
        _pass(ctx) = false;
}
\end{code}

\subsubsection{\_locals()}

\texttt{\_locals()} 返回对当前正在解析的规则的一个或多个局部值的引用（如果有）。如果有两个或更多局部值，\texttt{\_locals()} 返回对 \texttt{boost::parser::tuple} 的引用。我们还没有涉及带有局部变量的规则（参见更多关于规则的内容），但现在你只需要知道你可以为 \texttt{rule} 提供一个模板参数（\texttt{LocalState}），并且该规则将默认构造一个该类型的对象以在规则内使用。你可以通过 \texttt{\_locals()} 访问它：

\begin{code}
[](auto & ctx) {
    auto & local = _locals(ctx);
    // Use local here.  If 'local' is a hana::tuple, access its members like this:
    using namespace hana::literals;
    auto & first_element = local[0_c];
    auto & second_element = local[1_c];
}
\end{code}

如果没有当前规则，或者当前规则没有局部变量，则返回 \texttt{none}。

\subsubsection{\_params()}

\texttt{\_params()} 类似于 \texttt{\_locals()}，适用于当前用于解析的规则（如果有）（参见更多关于规则的内容）。如果当前规则只有一个参数，它返回对单个值的引用；如果当前规则有多个参数，它返回一个 \texttt{boost::parser::tuple}。如果没有当前规则，或者当前规则没有参数，则返回 \texttt{none}。

与 \texttt{\_locals()} 不同，你 \textbf{不} 需要为 \texttt{rule} 提供模板参数。相反，你调用 \texttt{rule} 的 \texttt{with()} 成员函数（同样，参见更多关于规则的内容）。

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Note \\
\texttt{none} 是一个类型，用作 Boost.Parser 中解析上下文访问器的返回值。 \texttt{none} 可以转换为任何具有默认构造函数的类型，可以从任何类型转换而来，可以从任何类型赋值，并且对所有可重载的操作符都有模板化的重载。其目的是确保误用 \texttt{\_val()}、\texttt{\_globals()} 等操作在编译时不会报错，而是在运行时产生断言。经验表明，使用调试器调查导致错误的堆栈比筛选编译器诊断信息提供了更好的用户体验。有关详细解释，请参见基本原理部分。 & \\
\end{longtable}

\subsubsection{\texorpdfstring{\texttt{\_no\_case()}}{\_no\_case()}}

\texttt{\_no\_case()} 返回 \texttt{true}，如果当前解析上下文在一个或多个（可能嵌套的）\texttt{no\_case{[}{]}} 指令内。我没有这个的用例，但如果我不暴露它，它将是上下文中唯一不能从语义动作内部检查的东西。添加它很容易，所以我就做了。

\subsection{规则解析器}

这个示例与我们迄今为止看到的其他示例非常相似。不同之处在于它使用了一个 \texttt{rule}。作为类比，可以将解析器如 \texttt{char\_} 或 \texttt{double\_} 看作单独的一行代码，而将 \texttt{rule} 看作一个函数。像函数一样，\texttt{rule} 有自己的名字，甚至可以被前向声明。以下是我们定义 \texttt{rule} 的方式，这类似于前向声明一个函数：

\begin{code}
bp::rule<struct doubles, std::vector<double>> doubles = "doubles";
\end{code}

这声明了规则本身。 \texttt{rule} 是一个解析器，我们可以立即在其他解析器中使用它。这个定义相当密集；请注意以下几点：

\begin{itemize}
\item
  第一个模板参数是标签类型 \texttt{struct doubles}。这里我们声明了标签类型并一次性使用了它；你也可以使用先前声明的标签类型。
\item
  第二个模板参数是解析器的属性类型。如果你不提供这个参数，规则将没有属性。
\item
  这个规则对象本身叫做 \texttt{doubles}。
\item
  我们给 \texttt{doubles} 提供了诊断文本 \texttt{"doubles"}，以便 Boost.Parser 在调试期间生成解析器的跟踪时知道如何引用它。
\end{itemize}

好了，那么如果 \texttt{doubles} 是一个解析器，它做什么呢？我们通过定义一个现在应该看起来很熟悉的单独解析器来定义规则的行为：

\begin{code}
auto const doubles_def = bp::double_ % ',';
\end{code}

这类似于为前向声明的函数编写定义。请注意，我们使用了名称 \texttt{doubles\_def}。现在，\texttt{doubles} 规则解析器和 \texttt{doubles\_def} 非规则解析器之间没有任何连接。这是有意的——我们希望能够单独定义它们。为了连接它们，我们声明了一个 Boost.Parser 能理解的接口函数，并使用标签类型 \texttt{struct doubles} 将它们连接在一起。我们使用一个宏来实现这一点：

\begin{code}
BOOST_PARSER_DEFINE_RULES(doubles);
\end{code}

这个宏展开为使规则 \texttt{doubles} 和其解析器 \texttt{doubles\_def} 一起工作的必要代码。 \texttt{\_def} 后缀是这个宏依赖的命名约定。标签类型允许规则解析器 \texttt{doubles} 在用作解析器时调用这些重载之一。

\texttt{BOOST\_PARSER\_DEFINE\_RULES} 展开为两个名为 \texttt{parse\_rule()} 的函数重载。在上面的例子中，每个重载都接受一个 \texttt{struct doubles} 参数（以将它们与其他规则的 \texttt{parse\_rule()} 重载区分开来）并使用 \texttt{doubles\_def} 进行解析。你永远不需要自己调用任何 \texttt{parse\_rule()} 的重载；它在实现 \texttt{rules} 的解析器 \texttt{rule\_parser} 内部使用。

以下是为每个规则展开的宏定义：
\begin{code}
#define BOOST_PARSER_DEFINE_IMPL(_, rule_name_)                                \
    template<                                                                  \
        typename Iter,                                                         \
        typename Sentinel,                                                     \
        typename Context,                                                      \
        typename SkipParser>                                                   \
    decltype(rule_name_)::parser_type::attr_type parse_rule(                   \
        decltype(rule_name_)::parser_type::tag_type *,                         \
        Iter & first,                                                          \
        Sentinel last,                                                         \
        Context const & context,                                               \
        SkipParser const & skip,                                               \
        boost::parser::detail::flags flags,                                    \
        bool & success,                                                        \
        bool & dont_assign)                                                    \
    {                                                                          \
        auto const & parser = BOOST_PARSER_PP_CAT(rule_name_, _def);           \
        using attr_t =                                                         \
            decltype(parser(first, last, context, skip, flags, success));      \
        using attr_type = decltype(rule_name_)::parser_type::attr_type;        \
        if constexpr (boost::parser::detail::is_nope_v<attr_t>) {              \
            dont_assign = true;                                                \
            parser(first, last, context, skip, flags, success);                \
            return {};                                                         \
        } else if constexpr (std::is_same_v<attr_type, attr_t>) {              \
            return parser(first, last, context, skip, flags, success);         \
        } else if constexpr (std::is_constructible_v<attr_type, attr_t>) {     \
            return attr_type(                                                  \
                parser(first, last, context, skip, flags, success));           \
        } else {                                                               \
            attr_type attr{};                                                  \
            parser(first, last, context, skip, flags, success, attr);          \
            return attr;                                                       \
        }                                                                      \
    }                                                                          \
                                                                               \
    template<                                                                  \
        typename Iter,                                                         \
        typename Sentinel,                                                     \
        typename Context,                                                      \
        typename SkipParser,                                                   \
        typename Attribute>                                                    \
    void parse_rule(                                                           \
        decltype(rule_name_)::parser_type::tag_type *,                         \
        Iter & first,                                                          \
        Sentinel last,                                                         \
        Context const & context,                                               \
        SkipParser const & skip,                                               \
        boost::parser::detail::flags flags,                                    \
        bool & success,                                                        \
        bool & dont_assign,                                                    \
        Attribute & retval)                                                    \
    {                                                                          \
        auto const & parser = BOOST_PARSER_PP_CAT(rule_name_, _def);           \
        using attr_t =                                                         \
            decltype(parser(first, last, context, skip, flags, success));      \
        if constexpr (boost::parser::detail::is_nope_v<attr_t>) {              \
            parser(first, last, context, skip, flags, success);                \
        } else {                                                               \
            parser(first, last, context, skip, flags, success, retval);        \
        }                                                                      \
    }
\end{code}
现在我们有了 \texttt{doubles} 解析器，我们可以像使用其他解析器一样使用它：

\begin{code}
auto const result = bp::parse(input, doubles, bp::ws);
\end{code}

完整程序：

\begin{code}
#include <boost/parser/parser.hpp>

#include <deque>
#include <iostream>
#include <string>


namespace bp = boost::parser;


bp::rule<struct doubles, std::vector<double>> doubles = "doubles";
auto const doubles_def = bp::double_ % ',';
BOOST_PARSER_DEFINE_RULES(doubles);

int main()
{
    std::cout << "Please enter a list of doubles, separated by commas. ";
    std::string input;
    std::getline(std::cin, input);

    auto const result = bp::parse(input, doubles, bp::ws);

    if (result) {
        std::cout << "You entered:\n";
        for (double x : *result) {
            std::cout << x << "\n";
        }
    } else {
        std::cout << "Parse failure.\n";
    }
}
\end{code}

所有这些都是为了介绍 \texttt{rules} 的概念。你可能仍然不清楚为什么要使用 \texttt{rules}。关于 \texttt{rules} 的使用场景和详细信息，请参见后面的章节“更多关于规则”。

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Note \\
The existence of \texttt{rules} means that will probably never have to write a low-level parser. You can just put existing parsers together into \texttt{rules} instead. & \\
\end{longtable}

\subsection{解析到结构体和类}

到目前为止，我们只看到了简单的解析器，它们重复解析相同的值（有或没有逗号和空格）。解析一些特定顺序的值也是很常见的。假设你想解析一个员工记录。以下是你可能编写的解析器：
\begin{code}
namespace bp = boost::parser;
auto employee_parser = bp::lit("employee")
    >> '{'
    >> bp::int_ >> ','
    >> quoted_string >> ','
    >> quoted_string >> ','
    >> bp::double_
    >> '}';
\end{code}

\texttt{employee\_parser} 的属性类型是 \texttt{boost::parser::tuple<int, std::string, std::string, double>}。这很好，因为你在不需要编写任何语义动作的情况下获得了记录的所有解析数据。但不太好的是，你现在必须使用 \texttt{get()} 按索引获取所有单独的元素。将数据解析到程序将要使用的最终数据结构中会更好。这通常是一些 \texttt{struct} 或 \texttt{class}。Boost.Parser 支持解析到任意聚合 \texttt{struct}，以及可以从当前元组构造的非聚合类型。

\subsubsection{作为属性的聚合类型}

如果我们有一个 \texttt{struct}，其数据成员类型与 \texttt{employee\_parser} 的 \texttt{boost::parser::tuple} 属性类型中列出的类型相同，那么直接解析到它，而不是先解析到一个元组然后再构造我们的 \texttt{struct}，会更好。幸运的是，这在 Boost.Parser 中是可行的。以下是直接解析到兼容聚合类型的示例。

\begin{code}
#include <boost/parser/parser.hpp>

#include <iostream>
#include <string>


struct employee
{
    int age;
    std::string surname;
    std::string forename;
    double salary;
};

namespace bp = boost::parser;

int main()
{
    std::cout << "Enter employee record. ";
    std::string input;
    std::getline(std::cin, input);

    auto quoted_string = bp::lexeme['"' >> +(bp::char_ - '"') >> '"'];
    auto employee_p = bp::lit("employee")
        >> '{'
        >> bp::int_ >> ','
        >> quoted_string >> ','
        >> quoted_string >> ','
        >> bp::double_
        >> '}';

    employee record;
    auto const result = bp::parse(input, employee_p, bp::ws, record);

    if (result) {
        std::cout << "You entered:\nage:      " << record.age
                  << "\nsurname:  " << record.surname
                  << "\nforename: " << record.forename
                  << "\nsalary  : " << record.salary << "\n";
    } else {
        std::cout << "Parse failure.\n";
    }
}
\end{code}

不幸的是，这利用了松散的属性赋值逻辑；\texttt{employee\_parser} 解析器仍然具有 \texttt{boost::parser::tuple} 属性。有关属性输出参数兼容性的描述，请参见 \texttt{parse()} API。

因此，更常见的是希望创建一个返回特定类型（如 \texttt{employee}）的规则。只需给规则一个 \texttt{struct} 类型，我们就能确保这个解析器无论在解析的哪个位置，其属性始终是一个 \texttt{employee} 结构。如果我们创建一个使用 \texttt{employee\_p} 规则的简单解析器 \texttt{P}，如 \texttt{bp::int >> employee\_p}，那么 \texttt{P} 的属性类型将是 \texttt{boost::parser::tuple<int, employee>}。

\begin{code}
#include <boost/parser/parser.hpp>

#include <iostream>
#include <string>


struct employee
{
    int age;
    std::string surname;
    std::string forename;
    double salary;
};

namespace bp = boost::parser;

bp::rule<struct quoted_string, std::string> quoted_string = "quoted name";
bp::rule<struct employee_p, employee> employee_p = "employee";

auto quoted_string_def = bp::lexeme['"' >> +(bp::char_ - '"') >> '"'];
auto employee_p_def = bp::lit("employee")
    >> '{'
    >> bp::int_ >> ','
    >> quoted_string >> ','
    >> quoted_string >> ','
    >> bp::double_
    >> '}';

BOOST_PARSER_DEFINE_RULES(quoted_string, employee_p);

int main()
{
    std::cout << "Enter employee record. ";
    std::string input;
    std::getline(std::cin, input);

    static_assert(std::is_aggregate_v<std::decay_t<employee &>>);

    auto const result = bp::parse(input, employee_p, bp::ws);

    if (result) {
        std::cout << "You entered:\nage:      " << result->age
                  << "\nsurname:  " << result->surname
                  << "\nforename: " << result->forename
                  << "\nsalary  : " << result->salary << "\n";
    } else {
        std::cout << "Parse failure.\n";
    }
}
\end{code}

正如当解析器的属性类型是元组时，你可以将 \texttt{struct} 作为输出参数传递给 \texttt{parse()}，当解析器的属性类型是 \texttt{struct} 时，你也可以将元组作为输出参数传递给 \texttt{parse()}：

\begin{code}
// Using the employee_p rule from above, with attribute type employee...
boost::parser::tuple<int, std::string, std::string, double> tup;
auto const result = bp::parse(input, employee_p, bp::ws, tup); // Ok!
\end{code}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Important \\
这种将 \texttt{struct} 自动用作元组的功能依赖于一些元编程。由于编译器的限制，检测 \texttt{struct} 数据成员数量的元程序有一个最大成员数的限制。幸运的是，这个限制是可配置的；请参见 \texttt{BOOST\_PARSER\_MAX\_AGGREGATE\_SIZE}。 & \\
\end{longtable}

\subsubsection{作为属性的一般类类型}

很多时候你没有一个聚合结构体来生成解析结果。如果 Boost.Parser 能检测到元组中的成员可以用作某个类型的构造函数参数，那就更好了。所以，Boost.Parser 确实做到了这一点。

\begin{code}
#include <boost/parser/parser.hpp>

#include <iostream>
#include <string>


namespace bp = boost::parser;

int main()
{
    std::cout << "Enter a string followed by two unsigned integers. ";
    std::string input;
    std::getline(std::cin, input);

    constexpr auto string_uint_uint =
        bp::lexeme[+(bp::char_ - ' ')] >> bp::uint_ >> bp::uint_;
    std::string string_from_parse;
    if (parse(input, string_uint_uint, bp::ws, string_from_parse))
        std::cout << "That yields this string: " << string_from_parse << "\n";
    else
        std::cout << "Parse failure.\n";

    std::cout << "Enter an unsigned integer followed by a string. ";
    std::getline(std::cin, input);
    std::cout << input << "\n";

    constexpr auto uint_string = bp::uint_ >> +bp::char_;
    std::vector<std::string> vector_from_parse;
    if (parse(input, uint_string, bp::ws, vector_from_parse)) {
        std::cout << "That yields this vector of strings:\n";
        for (auto && str : vector_from_parse) {
            std::cout << "  '" << str << "'\n";
        }
    } else {
        std::cout << "Parse failure.\n";
    }
}
\end{code}

Let's look at the first parse.

\begin{code}
constexpr auto string_uint_uint =
    bp::lexeme[+(bp::char_ - ' ')] >> bp::uint_ >> bp::uint_;
std::string string_from_parse;
if (parse(input, string_uint_uint, bp::ws, string_from_parse))
    std::cout << "That yields this string: " << string_from_parse << "\n";
else
    std::cout << "Parse failure.\n";
\end{code}

这里，我们使用解析器 \texttt{string\_uint\_uint}，它生成一个 \texttt{boost::parser::tuple<std::string, unsigned int, unsigned int>} 属性。当我们尝试将其解析为一个 out-param \texttt{std::string} 属性时，它就能正常工作。这是因为 \texttt{std::string} 有一个构造函数，它接受一个 \texttt{std::string}、一个偏移量和一个长度。以下是另一个解析：

\begin{code}
constexpr auto uint_string = bp::uint_ >> +bp::char_;
std::vector<std::string> vector_from_parse;
if (parse(input, uint_string, bp::ws, vector_from_parse)) {
    std::cout << "That yields this vector of strings:\n";
    for (auto && str : vector_from_parse) {
        std::cout << "  '" << str << "'\n";
    }
} else {
    std::cout << "Parse failure.\n";
}
\end{code}

现在我们有了解析器 \texttt{uint\_string}，它生成 \texttt{boost::parser::tuple<unsigned int, std::string>} 属性——结尾的两个 \texttt{char} 组合成一个 \texttt{std::string}。这两个值可以通过计数 \texttt{T} 构造函数来构造一个 \texttt{std::vector<std::string>}。

就像在元组中使用聚合一样，非聚合 \texttt{class} 类型可以在大多数地方替代元组。这包括使用非聚合 \texttt{class} 类型作为 \texttt{rule} 的属性类型。

然而，虽然兼容的元组可以替代聚合，但你\textbf{不能}仅仅因为元组可以用来构造某个 \texttt{class} 类型 \texttt{T} 就替代它。想象一下试图在上面的第二个解析中反转替代。将一个 \texttt{std::vector<std::string>} 转换为 \texttt{boost::parser::tuple<unsigned int, std::string>} 是没有意义的。

\subsection{替代解析器}

通常，你需要解析可能有多种形式的内容。重载的 \texttt{operator|} 用于形成替代解析器。例如：

\begin{code}
namespace bp = boost::parser;
auto const parser_1 = bp::int_ | bp::eps;
\end{code}

\texttt{parser\_1} matches an integer, or if that fails, it matches \emph{epsilon}, the empty string. This is equivalent to writing:

\begin{code}
namespace bp = boost::parser;
auto const parser_2 = -bp::int_;
\end{code}

However, neither \texttt{parser\_1} nor \texttt{parser\_2} is equivalent to writing this:

\begin{code}
namespace bp = boost::parser;
auto const parser_3 = bp::eps | bp::int_; // Does not do what you think.
\end{code}

原因是替代解析器会依次尝试它们的每个子解析器，并在第一个匹配的子解析器上停止。 \emph{Epsilon} 匹配任何内容，因为它是零长度且不消耗任何输入。它甚至匹配输入的结尾。这意味着 \texttt{parser\_3} 本身就相当于 \texttt{eps}。

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Note \\
For this reason, writing \texttt{eps | p} for any parser p is considered a bug. Debug builds will assert when \texttt{eps | p} is encountered. & \\
\end{longtable}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Warning \\
这种错误在涉及 \texttt{eps} 时非常常见，而且也很容易检测到。然而，有可能写出 \texttt{P1 >> P2}，其中 \texttt{P1} 是 \texttt{P2} 的前缀，例如 \texttt{int\_ | int >> int\_}，或者 \texttt{repeat(4){[}hex\_digit{]} | repeat(8){[}hex\_digit{]}}。这几乎肯定是一个错误，但在一般情况下是不可能检测到的——请记住，\texttt{rules} 可以单独编译，并且考虑一对规则，其关联的 \texttt{\_def} 解析器分别是 \texttt{int\_} 和 \texttt{int\_ >> int\_}。 & \\
\end{longtable}

\subsection{解析带引号的字符串}

解析带引号的字符串是非常常见的需求。然而，当使用跳过器时（而且你应该在99%的情况下使用跳过器），解析带引号的字符串会稍微有些棘手。你不希望在字符串中间允许任意的空白字符，也不希望从字符串中移除所有的空白字符。这两种情况都会在使用典型的跳过器 \texttt{ws} 时发生。

所以，这里是大多数人编写带引号字符串解析器的方法：

\begin{code}
namespace bp = boost::parser;
const auto string = bp::lexeme['"' >> *(bp::char_ - '"') > '"'];
\end{code}

Some things to note:

\begin{itemize}
\item
  the result is a string;
\item
  the quotes are not included in the result;
\item
  there is an expectation point before the close-quote;
\item
  the use of \texttt{lexeme{[}{]}} disables skipping in the parser, and it must be written around the quotes, not around the \texttt{operator*} expression; and
\item
  there's no way to write a quote in the middle of the string.
\end{itemize}

This is a very common pattern. I have written a quoted string parser like this dozens of times. The parser above is the quick-and-dirty version. A more robust version would be able to handle escaped quotes within the string, and then would immediately also need to support escaped escape characters.

Boost.Parser provides \texttt{quoted\_string} to use in place of this very common pattern. It supports quote- and escaped-character-escaping, using backslash as the escape character.

\begin{code}
namespace bp = boost::parser;

auto result1 = bp::parse("\"some text\"", bp::quoted_string, bp::ws);
assert(result1);
std::cout << *result1 << "\n"; // Prints: some text

auto result2 =
    bp::parse("\"some \\\"text\\\"\"", bp::quoted_string, bp::ws);
assert(result2);
std::cout << *result2 << "\n"; // Prints: some "text"
\end{code}

As common as this use case is, there are very similar use cases that it does not cover. So, \texttt{quoted\_string} has some options. If you call it with a single character, it returns a \texttt{quoted\_string} that uses that single character as the quote-character.

\begin{code}
auto result3 = bp::parse("!some text!", bp::quoted_string('!'), bp::ws);
assert(result3);
std::cout << *result3 << "\n"; // Prints: some text
\end{code}

You can also supply a range of characters. One of the characters from the range must quote both ends of the string; mismatches are not allowed. Think of how Python allows you to quote a string with either \texttt{'"'} or \texttt{'\textbackslash{}''}, but the same character must be used on both sides.

\begin{code}
auto result4 = bp::parse("'some text'", bp::quoted_string("'\""), bp::ws);
assert(result4);
std::cout << *result4 << "\n"; // Prints: some text
\end{code}

Another common thing to do in a quoted string parser is to recognize escape sequences. If you have simple escape sequencecs that do not require any real parsing, like say the simple escape sequences from C++, you can provide a \texttt{symbols} object as well. The template parameter \texttt{T} to \texttt{symbols<T>} must be \texttt{char} or \texttt{char32\_t}. You don't need to include the escaped backslash or the escaped quote character, since those always work.

\begin{code}
// the c++ simple escapes
bp::symbols<char> const escapes = {
    {"'", '\''},
    {"?", '\?'},
    {"a", '\a'},
    {"b", '\b'},
    {"f", '\f'},
    {"n", '\n'},
    {"r", '\r'},
    {"t", '\t'},
    {"v", '\v'}};
auto result5 =
    bp::parse("\"some text\r\"", bp::quoted_string('"', escapes), bp::ws);
assert(result5);
std::cout << *result5 << "\n"; // Prints (with a CRLF newline): some text
\end{code}

\phantomsection\label{tutorial_split_002.html}{}

\subsection{Parsing In Detail}

Now that you've seen some examples, let's see how parsing works in a bit more detail. Consider this example.

\begin{code}
namespace bp = boost::parser;
auto int_pair = bp::int_ >> bp::int_;         // Attribute: tuple<int, int>
auto int_pairs_plus = +int_pair >> bp::int_;  // Attribute: tuple<std::vector<tuple<int, int>>, int>
\end{code}

\texttt{int\_pairs\_plus} must match a pair of \texttt{int}s (using \texttt{int\_pair}) one or more times, and then must match an additional \texttt{int}. In other words, it matches any odd number (greater than 1) of \texttt{int}s in the input. Let's look at how this parse proceeds.

\begin{code}
auto result = bp::parse("1 2 3", int_pairs_plus, bp::ws);
\end{code}

At the beginning of the parse, the top level parser uses its first subparser (if any) to start parsing. So, \texttt{int\_pairs\_plus}, being a sequence parser, would pass control to its first parser \texttt{+int\_pair}. Then \texttt{+int\_pair} would use \texttt{int\_pair} to do its parsing, which would in turn use \texttt{bp::int\_}. This creates a stack of parsers, each one using a particular subparser.

Step 1) The input is \texttt{"1 2 3"}, and the stack of active parsers is \texttt{int\_pairs\_plus} -> \texttt{+int\_pair} -> \texttt{int\_pair} -> \texttt{bp::int\_}. (Read "-\textgreater" as "uses".) This parses \texttt{"1"}, and the whitespace after is skipped by \texttt{bp::ws}. Control passes to the second \texttt{bp::int\_} parser in \texttt{int\_pair}.

Step 2) The input is \texttt{"2 3"} and the stack of parsers looks the same, except the active parser is the second \texttt{bp::int\_} from \texttt{int\_pair}. This parser consumes \texttt{"2"} and then \texttt{bp::ws} skips the subsequent space. Since we've finished with \texttt{int\_pair}'s match, its \texttt{boost::parser::tuple<int, int>} attribute is complete. It's parent is \texttt{+int\_pair}, so this tuple attribute is pushed onto the back of \texttt{+int\_pair}'s attribute, which is a \texttt{std::vector<boost::parser::tuple<int, int>>}. Control passes up to the parent of \texttt{int\_pair}, \texttt{+int\_pair}. Since \texttt{+int\_pair} is a one-or-more parser, it starts a new iteration; control passes to \texttt{int\_pair} again.

Step 3) The input is \texttt{"3"} and the stack of parsers looks the same, except the active parser is the first \texttt{bp::int\_} from \texttt{int\_pair} again, and we're in the second iteration of \texttt{+int\_pair}. This parser consumes \texttt{"3"}. Since this is the end of the input, the second \texttt{bp::int\_} of \texttt{int\_pair} does not match. This partial match of \texttt{"3"} should not count, since it was not part of a full match. So, \texttt{int\_pair} indicates its failure, and \texttt{+int\_pair} stops iterating. Since it did match once, \texttt{+int\_pair} does not fail; it is a zero-or-more parser; failure of its subparser after the first success does not cause it to fail. Control passes to the next parser in sequence within \texttt{int\_pairs\_plus}.

Step 4) The input is \texttt{"3"} again, and the stack of parsers is \texttt{int\_pairs\_plus} -> \texttt{bp::int\_}. This parses the \texttt{"3"}, and the parse reaches the end of input. Control passes to \texttt{int\_pairs\_plus}, which has just successfully matched with all parser in its sequence. It then produces its attribute, a \texttt{boost::parser::tuple<std::vector<boost::parser::tuple<int, int>>, int>}, which gets returned from \texttt{bp::parse()}.

Something to take note of between Steps \#3 and \#4: at the beginning of \#4, the input position had returned to where is was at the beginning of \#3. This kind of backtracking happens in alternative parsers when an alternative fails. The next page has more details on the semantics of backtracking.

\subsubsection{Parsers in detail}

So far, parsers have been presented as somewhat abstract entities. You may be wanting more detail. A Boost.Parser parser \texttt{P} is an invocable object with a pair of call operator overloads. The two functions are very similar, and in many parsers one is implemented in terms of the other. The first function does the parsing and returns the default attribute for the parser. The second function does exactly the same parsing, but takes an out-param into which it writes the attribute for the parser. The out-param does not need to be the same type as the default attribute, but they need to be compatible.

Compatibility means that the default attribute is assignable to the out-param in some fashion. This usually means direct assignment, but it may also mean a tuple -> aggregate or aggregate -> tuple conversion. For sequence types, compatibility means that the sequence type has \texttt{insert} or \texttt{push\_back} with the usual semantics. This means that the parser \texttt{+boost::parser::int\_} can fill a \texttt{std::set<int>} just as well as a \texttt{std::vector<int>}.

Some parsers also have additional state that is required to perform a match. For instance, \texttt{char\_} parsers can be parameterized with a single code point to match; the exact value of that code point is stored in the parser object.

No parser has direct support for all the operations defined on parsers (\texttt{operator|}, \texttt{operator>>}, etc.). Instead, there is a template called \texttt{parser\_interface} that supports all of these operations. \texttt{parser\_interface} wraps each parser, storing it as a data member, adapting it for general use. You should only ever see \texttt{parser\_interface} in the debugger, or possibly in some of the reference documentation. You should never have to write it in your own code.

\subsection{Backtracking}

As described in the previous page, backtracking occurs when the parse attempts to match the current parser \texttt{P}, matches part of the input, but fails to match all of \texttt{P}. The part of the input consumed during the parse of \texttt{P} is essentially "given back".

This is necessary because \texttt{P} may consist of subparsers, and each subparser that succeeds will try to consume input, produce attributes, etc. When a later subparser fails, the parse of \texttt{P} fails, and the input must be rewound to where it was when \texttt{P} started its parse, not where the latest matching subparser stopped.

Alternative parsers will often evaluate multiple subparsers one at a time, advancing and then restoring the input position, until one of the subparsers succeeds. Consider this example.

\begin{code}
namespace bp = boost::parser;
auto const parser = repeat(53)[other_parser] | repeat(10)[other_parser];
\end{code}

Evaluating \texttt{parser} means trying to match \texttt{other\_parser} 53 times, and if that fails, trying to match \texttt{other\_parser} 10 times. Say you parse input that matches \texttt{other\_parser} 11 times. \texttt{parser} will match it. It will also evaluate \texttt{other\_parser} 21 times during the parse.

The attributes of the \texttt{repeat(53){[}other\_parser{]}} and \texttt{repeat(10){[}other\_parser{]}} are each \texttt{std::vector<}\emph{\texttt{ATTR}}\texttt{(other\_parser)>}; let's say that \emph{\texttt{ATTR}}\texttt{(other\_parser)} is \texttt{int}. The attribute of \texttt{parser} as a whole is the same, \texttt{std::vector<int>}. Since \texttt{other\_parser} is busy producing \texttt{int}s --- 21 of them to be exact --- you may be wondering what happens to the ones produced during the evaluation of \texttt{repeat(53){[}other\_parser{]}} when it fails to find all 53 inputs. Its \texttt{std::vector<int>} will contain 11 \texttt{int}s at that point.

When a repeat-parser fails, and attributes are being generated, it clears its container. This applies to parsers such as the ones above, but also all the other repeat parsers, including ones made using \texttt{operator+} or \texttt{operator*}.

So, at the end of a successful parse by \texttt{parser} of 10 inputs (since the right side of the alternative only eats 10 repetitions), the \texttt{std::vector<int>} attribute of \texttt{parser} would contain 10 \texttt{int}s.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Note \\
Users of Boost.Spirit may be familiar with the \texttt{hold{[}{]}} directive. Because of the behavior described above, there is no such directive in Boost.Parser. & \\
\end{longtable}

\subsubsection{Expectation points}

Ok, so if parsers all try their best to match the input, and are all-or-nothing, doesn't that leave room for all kinds of bad input to be ignored? Consider the top-level parser from the Parsing JSON example.

\begin{code}
auto const value_p_def =
    number | bp::bool_ | null | string | array_p | object_p;
\end{code}

What happens if I use this to parse \texttt{"\textbackslash{}""}? The parse tries \texttt{number}, fails. It then tries \texttt{bp::bool\_}, fails. Then \texttt{null} fails too. Finally, it starts parsing \texttt{string}. Good news, the first character is the open-quote of a JSON string. Unfortunately, that's also the end of the input, so \texttt{string} must fail too. However, we probably don't want to just give up on parsing \texttt{string} now and try \texttt{array\_p}, right? If the user wrote an open-quote with no matching close-quote, that's not the prefix of some later alternative of \texttt{value\_p\_def}; it's ill-formed JSON. Here's the parser for the \texttt{string} rule:

\begin{code}
auto const string_def = bp::lexeme['"' >> *(string_char - '"') > '"'];
\end{code}

Notice that \texttt{operator>} is used on the right instead of \texttt{operator>>}. This indicates the same sequence operation as \texttt{operator>>}, except that it also represents an expectation. If the parse before the \texttt{operator>} succeeds, whatever comes after it \textbf{must} also succeed. Otherwise, the top-level parse is failed, and a diagnostic is emitted. It will say something like "Expected \textquotesingle"' here.", quoting the line, with a caret pointing to the place in the input where it expected the right-side match.

Choosing to use \texttt{>} versus \texttt{>>} is how you indicate to Boost.Parser that parse failure is or is not a hard error, respectively.

\subsection{Symbol Tables}

When writing a parser, it often comes up that there is a set of strings that, when parsed, are associated with a set of values one-to-one. It is tedious to write parsers that recognize all the possible input strings when you have to associate each one with an attribute via a semantic action. Instead, we can use a symbol table.

Say we want to parse Roman numerals, one of the most common work-related parsing problems. We want to recognize numbers that start with any number of "M"s, representing thousands, followed by the hundreds, the tens, and the ones. Any of these may be absent from the input, but not all. Here are three symbol Boost.Parser tables that we can use to recognize ones, tens, and hundreds values, respectively:

\begin{code}
bp::symbols<int> const ones = {
    {"I", 1},
    {"II", 2},
    {"III", 3},
    {"IV", 4},
    {"V", 5},
    {"VI", 6},
    {"VII", 7},
    {"VIII", 8},
    {"IX", 9}};

bp::symbols<int> const tens = {
    {"X", 10},
    {"XX", 20},
    {"XXX", 30},
    {"XL", 40},
    {"L", 50},
    {"LX", 60},
    {"LXX", 70},
    {"LXXX", 80},
    {"XC", 90}};

bp::symbols<int> const hundreds = {
    {"C", 100},
    {"CC", 200},
    {"CCC", 300},
    {"CD", 400},
    {"D", 500},
    {"DC", 600},
    {"DCC", 700},
    {"DCCC", 800},
    {"CM", 900}};
\end{code}

A \texttt{symbols} maps strings of \texttt{char} to their associated attributes. The type of the attribute must be specified as a template parameter to \texttt{symbols} --- in this case, \texttt{int}.

Any "M"s we encounter should add 1000 to the result, and all other values come from the symbol tables. Here are the semantic actions we'll need to do that:

\begin{code}
int result = 0;
auto const add_1000 = [&result](auto & ctx) { result += 1000; };
auto const add = [&result](auto & ctx) { result += _attr(ctx); };
\end{code}

\texttt{add\_1000} just adds \texttt{1000} to \texttt{result}. \texttt{add} adds whatever attribute is produced by its parser to \texttt{result}.

Now we just need to put the pieces together to make a parser:

\begin{code}
using namespace bp::literals;
auto const parser =
    *'M'_l[add_1000] >> -hundreds[add] >> -tens[add] >> -ones[add];
\end{code}

We've got a few new bits in play here, so let's break it down. \texttt{'M'\_l} is a \emph{literal parser}. That is, it is a parser that parses a literal \texttt{char}, code point, or string. In this case, a \texttt{char} \texttt{'M'} is being parsed. The \texttt{\_l} bit at the end is a UDL suffix that you can put after any \texttt{char}, \texttt{char32\_t}, or \texttt{char const *} to form a literal parser. You can also make a literal parser by writing \texttt{lit()}, passing an argument of one of the previously mentioned types.

Why do we need any of this, considering that we just used a literal \ci{','} in our previous example? The reason is that \texttt{'M'} is not used in an expression with another Boost.Parser parser. It is used within \texttt{*'M'\_l{[}add\_1000{]}}. If we'd written \texttt{*'M'{[}add\_1000{]}}, clearly that would be ill-formed; \texttt{char} has no \texttt{operator*}, nor an \texttt{operator{[}{]}}, associated with it.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Tip \\
Any time you want to use a \texttt{char}, \texttt{char32\_t}, or string literal in a Boost.Parser parser, write it as-is if it is combined with a preexisting Boost.Parser subparser \texttt{p}, as in \texttt{'x' >> p}. Otherwise, you need to wrap it in a call to \texttt{lit()}, or use the \texttt{\_l} UDL suffix. & \\
\end{longtable}

On to the next bit: \texttt{-hundreds{[}add{]}}. By now, the use of the index operator should be pretty familiar; it associates the semantic action \texttt{add} with the parser \texttt{hundreds}. The \texttt{operator-} at the beginning is new. It means that the parser it is applied to is optional. You can read it as "zero or one". So, if \texttt{hundreds} is not successfully parsed after \texttt{*'M'{[}add\_1000{]}}, nothing happens, because \texttt{hundreds} is allowed to be missing --- it's optional. If \texttt{hundreds} is parsed successfully, say by matching \texttt{"CC"}, the resulting attribute, \texttt{200}, is added to \texttt{result} inside \texttt{add}.

Here is the full listing of the program. Notice that it would have been inappropriate to use a whitespace skipper here, since the entire parse is a single number, so it was removed.

\begin{code}
#include <boost/parser/parser.hpp>

#include <iostream>
#include <string>


namespace bp = boost::parser;

int main()
{
    std::cout << "Enter a number using Roman numerals. ";
    std::string input;
    std::getline(std::cin, input);

    bp::symbols<int> const ones = {
        {"I", 1},
        {"II", 2},
        {"III", 3},
        {"IV", 4},
        {"V", 5},
        {"VI", 6},
        {"VII", 7},
        {"VIII", 8},
        {"IX", 9}};

    bp::symbols<int> const tens = {
        {"X", 10},
        {"XX", 20},
        {"XXX", 30},
        {"XL", 40},
        {"L", 50},
        {"LX", 60},
        {"LXX", 70},
        {"LXXX", 80},
        {"XC", 90}};

    bp::symbols<int> const hundreds = {
        {"C", 100},
        {"CC", 200},
        {"CCC", 300},
        {"CD", 400},
        {"D", 500},
        {"DC", 600},
        {"DCC", 700},
        {"DCCC", 800},
        {"CM", 900}};

    int result = 0;
    auto const add_1000 = [&result](auto & ctx) { result += 1000; };
    auto const add = [&result](auto & ctx) { result += _attr(ctx); };

    using namespace bp::literals;
    auto const parser =
        *'M'_l[add_1000] >> -hundreds[add] >> -tens[add] >> -ones[add];

    if (bp::parse(input, parser) && result != 0)
        std::cout << "That's " << result << " in Arabic numerals.\n";
    else
        std::cout << "That's not a Roman number.\n";
}
\end{code}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Important \\
\texttt{symbols} stores all its strings in UTF-32 internally. If you do Unicode or ASCII parsing, this will not matter to you at all. If you do non-Unicode parsing of a character encoding that is not a subset of Unicode (EBCDIC, for instance), it could cause problems. See the section on Unicode Support for more information. & \\
\end{longtable}

\subsubsection{Diagnostic messages}

Just like with a \texttt{rule}, you can give a \texttt{symbols} a bit of diagnostic text that will be used in error messages generated by Boost.Parser when the parse fails at an expectation point, as described in Error Handling and Debugging. See the \texttt{symbols} constructors for details.

\subsection{Mutable Symbol Tables}

The previous example showed how to use a symbol table as a fixed lookup table. What if we want to add things to the table during the parse? We can do that, but we need to do so within a semantic action. First, here is our symbol table, already with a single value in it:

\begin{code}
bp::symbols<int> const symbols = {{"c", 8}};
assert(parse("c", symbols));
\end{code}

No surprise that it works to use the symbol table as a parser to parse the one string in the symbol table. Now, here's our parser:

\begin{code}
auto const parser = (bp::char_ >> bp::int_)[add_symbol] >> symbols;
\end{code}

Here, we've attached the semantic action not to a simple parser like \texttt{double\_}, but to the sequence parser \texttt{(bp::char\_ >> bp::int\_)}. This sequence parser contains two parsers, each with its own attribute, so it produces two attributes as a tuple.

\begin{code}
auto const add_symbol = [&symbols](auto & ctx) {
    using namespace bp::literals;
    // symbols::insert() requires a string, not a single character.
    char chars[2] = {_attr(ctx)[0_c], 0};
    symbols.insert(ctx, chars, _attr(ctx)[1_c]);
};
\end{code}

Inside the semantic action, we can get the first element of the attribute tuple using UDLs provided by Boost.Hana, and \texttt{boost::hana::tuple::operator{[}{]}()}. The first attribute, from the \texttt{char\_}, is \texttt{\_attr(ctx){[}0\_c{]}}, and the second, from the \texttt{int\_}, is \texttt{\_attr(ctx){[}1\_c{]}} (if \texttt{boost::parser::tuple} aliases to \texttt{std::tuple}, you'd use \texttt{std::get} or \texttt{boost::parser::get} instead). To add the symbol to the symbol table, we call \texttt{insert()}.

\begin{code}
auto const parser = (bp::char_ >> bp::int_)[add_symbol] >> symbols;
\end{code}

During the parse, \texttt{("X", 9)} is parsed and added to the symbol table. Then, the second \texttt{'X'} is recognized by the symbol table parser. However:

\begin{code}
assert(!parse("X", symbols));
\end{code}

If we parse again, we find that \texttt{"X"} did not stay in the symbol table. The fact that \texttt{symbols} was declared const might have given you a hint that this would happen.

The full program:

\begin{code}
#include <boost/parser/parser.hpp>

#include <iostream>
#include <string>


namespace bp = boost::parser;

int main()
{
    bp::symbols<int> const symbols = {{"c", 8}};
    assert(parse("c", symbols));

    auto const add_symbol = [&symbols](auto & ctx) {
        using namespace bp::literals;
        // symbols::insert() requires a string, not a single character.
        char chars[2] = {_attr(ctx)[0_c], 0};
        symbols.insert(ctx, chars, _attr(ctx)[1_c]);
    };
    auto const parser = (bp::char_ >> bp::int_)[add_symbol] >> symbols;

    auto const result = parse("X 9 X", parser, bp::ws);
    assert(result && *result == 9);
    (void)result;

    assert(!parse("X", symbols));
}
\end{code}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Important \\
\texttt{symbols} stores all its strings in UTF-32 internally. If you do Unicode or ASCII parsing, this will not matter to you at all. If you do non-Unicode parsing of a character encoding that is not a subset of Unicode (EBCDIC, for instance), it could cause problems. See the section on Unicode Support for more information. & \\
\end{longtable}

It is possible to add symbols to a \texttt{symbols} permanently. To do so, you have to use a mutable \texttt{symbols} object \texttt{s}, and add the symbols by calling \texttt{s.insert\_for\_next\_parse()}, instead of \texttt{s.insert()}. These two operations are orthogonal, so if you want to both add a symbol to the table for the current top-level parse, and leave it in the table for subsequent top-level parses, you need to call both functions.

It is also possible to erase a single entry from the symbol table, or to clear the symbol table entirely. Just as with insertion, there are versions of erase and clear for the current parse, and another that applies only to subsequent parses. The full set of operations can be found in the \texttt{symbols} API docs.

{[}mpte There are two versions of each of the \texttt{symbols} \texttt{*\_for\_next\_parse()} functions --- one that takes a context, and one that does not. The one with the context is meant to be used within a semantic action. The one without the context is for use outside of any parse.{]}

\subsection{The Parsers And Their Uses}

Boost.Parser comes with all the parsers most parsing tasks will ever need. Each one is a \texttt{constexpr} object, or a \texttt{constexpr} function. Some of the non-functions are also callable, such as \texttt{char\_}, which may be used directly, or with arguments, as in \texttt{char\_}\texttt{('a', 'z')}. Any parser that can be called, whether a function or callable object, will be called a \emph{callable parser} from now on. Note that there are no nullary callable parsers; they each take one or more arguments.

Each callable parser takes one or more \emph{parse arguments}. A parse argument may be a value or an invocable object that accepts a reference to the parse context. The reference parameter may be mutable or constant. For example:

\begin{code}
struct get_attribute
{
    template<typename Context>
    auto operator()(Context & ctx)
    {
        return _attr(ctx);
    }
};
\end{code}

This can also be a lambda. For example:

\begin{code}
[](auto const & ctx) { return _attr(ctx); }
\end{code}

The operation that produces a value from a parse argument, which may be a value or a callable taking a parse context argument, is referred to as \emph{resolving} the parse argument. If a parse argument \texttt{arg} can be called with the current context, then the resolved value of \texttt{arg} is \texttt{arg(ctx)}; otherwise, the resolved value is just \texttt{arg}.

Some callable parsers take a \emph{parse predicate}. A parse predicate is not quite the same as a parse argument, because it must be a callable object, and cannot be a value. A parse predicate's return type must be contextually convertible to \texttt{bool}. For example:

\begin{code}
struct equals_three
{
    template<typename Context>
    bool operator()(Context const & ctx)
    {
        return _attr(ctx) == 3;
    }
};
\end{code}

This may of course be a lambda:

\begin{code}
[](auto & ctx) { return _attr(ctx) == 3; }
\end{code}

The notional macro \emph{\texttt{RESOLVE}}\texttt{()} expands to the result of resolving a parse argument or parse predicate. You'll see it used in the rest of the documentation.

An example of how parse arguments are used:

\begin{code}
namespace bp = boost::parser;
// This parser matches one code point that is at least 'a', and at most
// the value of last_char, which comes from the globals.
auto last_char = [](auto & ctx) { return _globals(ctx).last_char; }
auto subparser = bp::char_('a', last_char);
\end{code}

Don't worry for now about what the globals are for now; the take-away is that you can make any argument you pass to a parser depend on the current state of the parse, by using the parse context:

\begin{code}
namespace bp = boost::parser;
// This parser parses two code points.  For the parse to succeed, the
// second one must be >= 'a' and <= the first one.
auto set_last_char = [](auto & ctx) { _globals(ctx).last_char = _attr(x); };
auto parser = bp::char_[set_last_char] >> subparser;
\end{code}

Each callable parser returns a new parser, parameterized using the arguments given in the invocation.

This table lists all the Boost.Parser parsers. For the callable parsers, a separate entry exists for each possible arity of arguments. For a parser \texttt{p}, if there is no entry for \texttt{p} without arguments, \texttt{p} is a function, and cannot itself be used as a parser; it must be called. In the table below:

\begin{itemize}
\item
  each entry is a global object usable directly in your parsers, unless otherwise noted;
\item
  "code point" is used to refer to the elements of the input range, which assumes that the parse is being done in the Unicode-aware code path (if the parse is being done in the non-Unicode code path, read "code point" as "\texttt{char}");
\item
  \emph{\texttt{RESOLVE}}\texttt{()} is a notional macro that expands to the resolution of parse argument or evaluation of a parse predicate (see The Parsers And Their Uses);
\item
  "\emph{\texttt{RESOLVE}}\texttt{(pred) == true}" is a shorthand notation for "\emph{\texttt{RESOLVE}}\texttt{(pred)} is contextually convertible to \texttt{bool} and \texttt{true}"; likewise for \texttt{false};
\item
  \texttt{c} is a character of type \texttt{char}, \texttt{char8\_t}, or \texttt{char32\_t};
\item
  \texttt{str} is a string literal of type \texttt{char const{[}{]}}, \texttt{char8\_t const {[}{]}}, or \texttt{char32\_t const {[}{]}};
\item
  \texttt{pred} is a parse predicate;
\item
  \texttt{arg0}, \texttt{arg1}, \texttt{arg2}, ... are parse arguments;
\item
  \texttt{a} is a semantic action;
\item
  \texttt{r} is an object whose type models \texttt{parsable\_range};
\item
  \texttt{p}, \texttt{p1}, \texttt{p2}, ... are parsers; and
\item
  \texttt{escapes} is a \texttt{symbols<T>} object, where \texttt{T} is \texttt{char} or \texttt{char32\_t}.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Note \\
\begin{minipage}[t]{\linewidth}\raggedright
The definition of \texttt{parsable\_range} is:

\begin{code}
template<typename T>
concept parsable_range = std::ranges::forward_range<T> &&
    code_unit<std::ranges::range_value_t<T>>;
\end{code}
\end{minipage} & \\
\end{longtable}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Note \\
Some of the parsers in this table consume no input. All parsers consume the input they match unless otherwise stated in the table below. & \\
\end{longtable}

\textbf{Table~26.6.~Parsers and Their Semantics}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Parser & Semantics & Attribute Type & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{eps} & Matches \emph{epsilon}, the empty string. Always matches, and consumes no input. & None. & Matching \texttt{eps} an unlimited number of times creates an infinite loop, which is undefined behavior in C++. Boost.Parser will assert in debug mode when it encounters \texttt{*eps}, \texttt{+eps}, etc (this applies to unconditional \texttt{eps} only). \\
\texttt{eps(pred)} & Fails to match the input if \emph{\texttt{RESOLVE}}\texttt{(pred) == false}. Otherwise, the semantics are those of \texttt{eps}. & None. & \\
\texttt{ws} & Matches a single whitespace code point (see note), according to the Unicode White\_Space property. & None. & For more info, see the Unicode properties. \texttt{ws} may consume one code point or two. It only consumes two code points when it matches \texttt{"\textbackslash{}r\textbackslash{}n"}. \\
\texttt{eol} & Matches a single newline (see note), following the "hard" line breaks in the Unicode line breaking algorithm. & None. & For more info, see the Unicode Line Breaking Algorithm. \texttt{eol} may consume one code point or two. It only consumes two code points when it matches \texttt{"\textbackslash{}r\textbackslash{}n"}. \\
\texttt{eoi} & Matches only at the end of input, and consumes no input. & None. & \\
\texttt{attr}\texttt{(arg0)} & Always matches, and consumes no input. Generates the attribute \emph{\texttt{RESOLVE}}\texttt{(arg0)}. & \texttt{decltype(}\emph{\texttt{RESOLVE}}\texttt{(arg0))}. & An important use case for \texttt{attribute} is to provide a default attribute value as a trailing alternative. For instance, an \textbf{optional} comma-delmited list is: \texttt{int\_ \% ',' | attr(std::vector<int>)}. Without the "\texttt{| attr(...)}", at least one \texttt{int\_} match would be required. \\
\texttt{char\_} & Matches any single code point. & The code point type in Unicode parsing, or \texttt{char} in non-Unicode parsing. See Attribute Generation. & \\
\texttt{char\_(arg0)} & Matches exactly the code point \emph{\texttt{RESOLVE}}\texttt{(arg0)}. & The code point type in Unicode parsing, or \texttt{char} in non-Unicode parsing. See Attribute Generation. & \\
\texttt{char\_(arg0, arg1)} & Matches the next code point \texttt{n} in the input, if \emph{\texttt{RESOLVE}}\texttt{(arg0) <= n \&\& n <= }\emph{\texttt{RESOLVE}}\texttt{(arg1)}. & The code point type in Unicode parsing, or \texttt{char} in non-Unicode parsing. See Attribute Generation. & \\
\texttt{char\_(r)} & Matches the next code point \texttt{n} in the input, if \texttt{n} is one of the code points in \texttt{r}. & The code point type in Unicode parsing, or \texttt{char} in non-Unicode parsing. See Attribute Generation. & \texttt{r} is taken to be in a UTF encoding. The exact UTF used depends on \texttt{r}'s element type. If you do not pass UTF encoded ranges for \texttt{r}, the behavior of \texttt{char\_} is undefined. Note that ASCII is a subset of UTF-8, so ASCII is fine. EBCDIC is not. \texttt{r} is not copied; a reference to it is taken. The lifetime of \texttt{char\_(r)} must be within the lifetime of \texttt{r}. This overload of \texttt{char\_} does \textbf{not} take parse arguments. \\
\texttt{cp} & Matches a single code point. & \texttt{char32\_t} & Similar to \texttt{char\_}, but with a fixed \texttt{char32\_t} attribute type; \texttt{cp} has all the same call operator overloads as \texttt{char\_}, though they are not repeated here, for brevity. \\
\texttt{cu} & Matches a single code point. & \texttt{char} & Similar to \texttt{char\_}, but with a fixed \texttt{char} attribute type; \texttt{cu} has all the same call operator overloads as \texttt{char\_}, though they are not repeated here, for brevity. Even though the name "\texttt{cu}" suggests that this parser match at the code unit level, it does not. The name refers to the attribute type generated, much like the names \texttt{int\_} versus \texttt{uint\_}. \\
\texttt{blank} & Equivalent to \texttt{ws - eol}. & The code point type in Unicode parsing, or \texttt{char} in non-Unicode parsing. See the entry for \texttt{char\_}. & \\
\texttt{control} & Matches a single control-character code point. & The code point type in Unicode parsing, or \texttt{char} in non-Unicode parsing. See the entry for \texttt{char\_}. & \\
\texttt{digit} & Matches a single decimal digit code point. & The code point type in Unicode parsing, or \texttt{char} in non-Unicode parsing. See the entry for \texttt{char\_}. & \\
\texttt{punct} & Matches a single punctuation code point. & The code point type in Unicode parsing, or \texttt{char} in non-Unicode parsing. See the entry for \texttt{char\_}. & \\
\texttt{hex\_digit} & Matches a single hexidecimal digit code point. & The code point type in Unicode parsing, or \texttt{char} in non-Unicode parsing. See the entry for \texttt{char\_}. & \\
\texttt{lower} & Matches a single lower-case code point. & The code point type in Unicode parsing, or \texttt{char} in non-Unicode parsing. See the entry for \texttt{char\_}. & \\
\texttt{upper} & Matches a single upper-case code point. & The code point type in Unicode parsing, or \texttt{char} in non-Unicode parsing. See the entry for \texttt{char\_}. & \\
\texttt{lit}\texttt{(c)} & Matches exactly the given code point \texttt{c}. & None. & \texttt{lit()} does \textbf{not} take parse arguments. \\
\texttt{c\_l} & Matches exactly the given code point \texttt{c}. & None. & This is a UDL that represents \texttt{lit(c)}, for example \texttt{'F'\_l}. \\
\texttt{lit}\texttt{(r)} & Matches exactly the given string \texttt{r}. & None. & \texttt{lit()} does \textbf{not} take parse arguments. \\
\texttt{str\_l} & Matches exactly the given string \texttt{str}. & None. & This is a UDL that represents \texttt{lit(s)}, for example \texttt{"a string"\_l}. \\
\texttt{string(r)} & Matches exactly \texttt{r}, and generates the match as an attribute. & \texttt{std::string} & \texttt{string()} does \textbf{not} take parse arguments. \\
\texttt{str\_p} & Matches exactly \texttt{str}, and generates the match as an attribute. & \texttt{std::string} & This is a UDL that represents \texttt{string(s)}, for example \texttt{"a string"\_p}. \\
\texttt{bool\_} & Matches \texttt{"true"} or \texttt{"false"}. & \texttt{bool} & \\
\texttt{bin} & Matches a binary unsigned integral value. & \texttt{unsigned int} & For example, \texttt{bin} would match \texttt{"101"}, and generate an attribute of \texttt{5u}. \\
\texttt{bin(arg0)} & Matches exactly the binary unsigned integral value \emph{\texttt{RESOLVE}}\texttt{(arg0)}. & \texttt{unsigned int} & \\
\texttt{oct} & Matches an octal unsigned integral value. & \texttt{unsigned int} & For example, \texttt{oct} would match \texttt{"31"}, and generate an attribute of \texttt{25u}. \\
\texttt{oct(arg0)} & Matches exactly the octal unsigned integral value \emph{\texttt{RESOLVE}}\texttt{(arg0)}. & \texttt{unsigned int} & \\
\texttt{hex} & Matches a hexadecimal unsigned integral value. & \texttt{unsigned int} & For example, \texttt{hex} would match \texttt{"ff"}, and generate an attribute of \texttt{255u}. \\
\texttt{hex(arg0)} & Matches exactly the hexadecimal unsigned integral value \emph{\texttt{RESOLVE}}\texttt{(arg0)}. & \texttt{unsigned int} & \\
\texttt{ushort\_} & Matches an unsigned integral value. & \texttt{unsigned short} & \\
\texttt{ushort\_(arg0)} & Matches exactly the unsigned integral value \emph{\texttt{RESOLVE}}\texttt{(arg0)}. & \texttt{unsigned short} & \\
\texttt{uint\_} & Matches an unsigned integral value. & \texttt{unsigned int} & \\
\texttt{uint\_(arg0)} & Matches exactly the unsigned integral value \emph{\texttt{RESOLVE}}\texttt{(arg0)}. & \texttt{unsigned int} & \\
\texttt{ulong\_} & Matches an unsigned integral value. & \texttt{unsigned long} & \\
\texttt{ulong\_(arg0)} & Matches exactly the unsigned integral value \emph{\texttt{RESOLVE}}\texttt{(arg0)}. & \texttt{unsigned long} & \\
\texttt{ulong\_long} & Matches an unsigned integral value. & \texttt{unsigned long long} & \\
\texttt{ulong\_long(arg0)} & Matches exactly the unsigned integral value \emph{\texttt{RESOLVE}}\texttt{(arg0)}. & \texttt{unsigned long long} & \\
\texttt{short\_} & Matches a signed integral value. & \texttt{short} & \\
\texttt{short\_(arg0)} & Matches exactly the signed integral value \emph{\texttt{RESOLVE}}\texttt{(arg0)}. & \texttt{short} & \\
\texttt{int\_} & Matches a signed integral value. & \texttt{int} & \\
\texttt{int\_(arg0)} & Matches exactly the signed integral value \emph{\texttt{RESOLVE}}\texttt{(arg0)}. & \texttt{int} & \\
\texttt{long\_} & Matches a signed integral value. & \texttt{long} & \\
\texttt{long\_(arg0)} & Matches exactly the signed integral value \emph{\texttt{RESOLVE}}\texttt{(arg0)}. & \texttt{long} & \\
\texttt{long\_long} & Matches a signed integral value. & \texttt{long long} & \\
\texttt{long\_long(arg0)} & Matches exactly the signed integral value \emph{\texttt{RESOLVE}}\texttt{(arg0)}. & \texttt{long long} & \\
\texttt{float\_} & Matches a floating-point number. \texttt{float\_} uses parsing implementation details from Boost.Spirit. The specifics of what formats are accepted can be found in their real number parsers. Note that only the default \texttt{RealPolicies} is supported by \texttt{float\_}. & \texttt{float} & \\
\texttt{double\_} & Matches a floating-point number. \texttt{double\_} uses parsing implementation details from Boost.Spirit. The specifics of what formats are accepted can be found in their real number parsers. Note that only the default \texttt{RealPolicies} is supported by \texttt{double\_}. & \texttt{double} & \\
\texttt{repeat(arg0){[}p{]}} & Matches iff \texttt{p} matches exactly \emph{\texttt{RESOLVE}}\texttt{(arg0)} times. & \texttt{std::string} if \emph{\texttt{ATTR}}\texttt{(p)} is \texttt{char} or \texttt{char32\_t}, otherwise \texttt{std::vector<}\emph{\texttt{ATTR}}\texttt{(p)>} & The special value \texttt{Inf} may be used; it indicates unlimited repetition. \texttt{decltype(}\emph{\texttt{RESOLVE}}\texttt{(arg0))} must be implicitly convertible to \texttt{int64\_t}. Matching \texttt{eps} an unlimited number of times creates an infinite loop, which is undefined behavior in C++. Boost.Parser will assert in debug mode when it encounters \texttt{repeat(Inf){[}eps{]}} (this applies to unconditional \texttt{eps} only). \\
\texttt{repeat(arg0, arg1){[}p{]}} & Matches iff \texttt{p} matches between \emph{\texttt{RESOLVE}}\texttt{(arg0)} and \emph{\texttt{RESOLVE}}\texttt{(arg1)} times, inclusively. & \texttt{std::string} if \emph{\texttt{ATTR}}\texttt{(p)} is \texttt{char} or \texttt{char32\_t}, otherwise \texttt{std::vector<}\emph{\texttt{ATTR}}\texttt{(p)>} & The special value \texttt{Inf} may be used for the upper bound; it indicates unlimited repetition. \texttt{decltype(}\emph{\texttt{RESOLVE}}\texttt{(arg0))} and \texttt{decltype(}\emph{\texttt{RESOLVE}}\texttt{(arg1))} each must be implicitly convertible to \texttt{int64\_t}. Matching \texttt{eps} an unlimited number of times creates an infinite loop, which is undefined behavior in C++. Boost.Parser will assert in debug mode when it encounters \texttt{repeat(n, Inf){[}eps{]}} (this applies to unconditional \texttt{eps} only). \\
\texttt{if\_(pred){[}p{]}} & Equivalent to \texttt{eps(pred) >> p}. & \texttt{std::optional<}\emph{\texttt{ATTR}}\texttt{(p)>} & It is an error to write \texttt{if\_(pred)}. That is, it is an error to omit the conditionally matched parser \texttt{p}. \\
\texttt{switch\_(arg0)(arg1, p1)(arg2, p2) ...} & Equivalent to \texttt{p1} when \emph{\texttt{RESOLVE}}\texttt{(arg0) == }\emph{\texttt{RESOLVE}}\texttt{(arg1)}, \texttt{p2} when \emph{\texttt{RESOLVE}}\texttt{(arg0) == }\emph{\texttt{RESOLVE}}\texttt{(arg2)}, etc. If there is such no \texttt{argN}, the behavior of \texttt{switch\_()} is undefined. & \texttt{std::variant<}\emph{\texttt{ATTR}}\texttt{(p1), }\emph{\texttt{ATTR}}\texttt{(p2), ...>} & It is an error to write \texttt{switch\_(arg0)}. That is, it is an error to omit the conditionally matched parsers \texttt{p1}, \texttt{p2}, .... \\
\texttt{symbols<T>} & \texttt{symbols} is an associative container of key, value pairs. Each key is a \texttt{std::string} and each value has type \texttt{T}. In the Unicode parsing path, the strings are considered to be UTF-8 encoded; in the non-Unicode path, no encoding is assumed. \texttt{symbols} Matches the longest prefix \texttt{pre} of the input that is equal to one of the keys \texttt{k}. If the length \texttt{len} of \texttt{pre} is zero, and there is no zero-length key, it does not match the input. If \texttt{len} is positive, the generated attribute is the value associated with \texttt{k}. & \texttt{T} & Unlike the other entries in this table, \texttt{symbols} is a type, not an object. \\
\texttt{quoted\_string} & Matches \texttt{'"'}, followed by zero or more characters, followed by \texttt{'"'}. & \texttt{std::string} & The result does not include the quotes. A quote within the string can be written by escaping it with a backslash. A backslash within the string can be written by writing two consecutive backslashes. Any other use of a backslash will fail the parse. Skipping is disabled while parsing the entire string, as if using \texttt{lexeme{[}{]}}. \\
\texttt{quoted\_string(c)} & Matches \texttt{c}, followed by zero or more characters, followed by \texttt{c}. & \texttt{std::string} & The result does not include the \texttt{c} quotes. A \texttt{c} within the string can be written by escaping it with a backslash. A backslash within the string can be written by writing two consecutive backslashes. Any other use of a backslash will fail the parse. Skipping is disabled while parsing the entire string, as if using \texttt{lexeme{[}{]}}. \\
\texttt{quoted\_string(r)} & Matches some character \texttt{Q} in \texttt{r}, followed by zero or more characters, followed by \texttt{Q}. & \texttt{std::string} & The result does not include the \texttt{Q} quotes. A \texttt{Q} within the string can be written by escaping it with a backslash. A backslash within the string can be written by writing two consecutive backslashes. Any other use of a backslash will fail the parse. Skipping is disabled while parsing the entire string, as if using \texttt{lexeme{[}{]}}. \\
\texttt{quoted\_string(c, symbols)} & Matches \texttt{c}, followed by zero or more characters, followed by \texttt{c}. & \texttt{std::string} & The result does not include the \texttt{c} quotes. A \texttt{c} within the string can be written by escaping it with a backslash. A backslash within the string can be written by writing two consecutive backslashes. A backslash followed by a successful match using \texttt{symbols} will be interpreted as the corresponding value produced by \texttt{symbols}. Any other use of a backslash will fail the parse. Skipping is disabled while parsing the entire string, as if using \texttt{lexeme{[}{]}}. \\
\texttt{quoted\_string(r, symbols)} & Matches some character \texttt{Q} in \texttt{r}, followed by zero or more characters, followed by \texttt{Q}. & \texttt{std::string} & The result does not include the \texttt{Q} quotes. A \texttt{Q} within the string can be written by escaping it with a backslash. A backslash within the string can be written by writing two consecutive backslashes. A backslash followed by a successful match using \texttt{symbols} will be interpreted as the corresponding value produced by \texttt{symbols}. Any other use of a backslash will fail the parse. Skipping is disabled while parsing the entire string, as if using \texttt{lexeme{[}{]}}. \\
\end{longtable}

\hfill\break

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Important \\
All the character parsers, like \texttt{char\_}, \texttt{cp} and \texttt{cu} produce either \texttt{char} or \texttt{char32\_t} attributes. So when you see "\texttt{std::string} if \emph{\texttt{ATTR}}\texttt{(p)} is \texttt{char} or \texttt{char32\_t}, otherwise \texttt{std::vector<}\emph{\texttt{ATTR}}\texttt{(p)>}" in the table above, that effectively means that every sequences of character attributes get turned into a \texttt{std::string}. The only time this does not happen is when you introduce your own rules with attributes using another character type (or use \texttt{attribute} to do so). & \\
\end{longtable}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Note \\
A slightly more complete description of the attributes generated by these parsers is in a subsequent section. The attributes are repeated here so you can use see all the properties of the parsers in one place. & \\
\end{longtable}

If you have an integral type \texttt{IntType} that is not covered by any of the Boost.Parser parsers, you can use a more verbose declaration to declare a parser for \texttt{IntType}. If \texttt{IntType} were unsigned, you would use \texttt{uint\_parser}. If it were signed, you would use \texttt{int\_parser}. For example:

\begin{code}
constexpr parser_interface<int_parser<IntType>> hex_int;
\end{code}

\texttt{uint\_parser} and \texttt{int\_parser} accept three more non-type template parameters after the type parameter. They are \texttt{Radix}, \texttt{MinDigits}, and \texttt{MaxDigits}. \texttt{Radix} defaults to \texttt{10}, \texttt{MinDigits} to \texttt{1}, and \texttt{MaxDigits} to \texttt{-1}, which is a sentinel value meaning that there is no max number of digits.

So, if you wanted to parse exactly eight hexadecimal digits in a row in order to recognize Unicode character literals like C++ has (e.g. \texttt{\textbackslash{}Udeadbeef}), you could use this parser for the digits at the end:

\begin{code}
constexpr parser_interface<uint_parser<unsigned int, 16, 8, 8>> hex_int;
\end{code}

\subsection{Directives}

A directive is an element of your parser that doesn't have any meaning by itself. Some are second-order parsers that need a first-order parser to do the actual parsing. Others influence the parse in some way. You can often spot a directive lexically by its use of \texttt{{[}{]}}; directives always \texttt{{[}{]}}. Non-directives might, but only when attaching a semantic action.

The directives that are second order parsers are technically directives, but since they are also used to create parsers, it is more useful just to focus on that. The directives \texttt{repeat()} and \texttt{if\_()} were already described in the section on parsers; we won't say much about them here.

\subsubsection{Interaction with sequence, alternative, and permutation parsers}

Sequence, alternative, and permutation parsers do not nest in most cases. (Let's consider just sequence parsers to keep thinkgs simple, but most of this logic applies to alternative parsers as well.) \texttt{a >> b >> c} is the same as \texttt{(a >> b) >> c} and \texttt{a >> (b >> c)}, and they are each represented by a single \texttt{seq\_parser} with three subparsers, \texttt{a}, \texttt{b}, and \texttt{c}. However, if something prevents two \texttt{seq\_parsers} from interacting directly, they \textbf{will} nest. For instance, \texttt{lexeme{[}a >> b{]} >> c} is a \texttt{seq\_parser} containing two parsers, \texttt{lexeme{[}a >> b{]}} and \texttt{c}. This is because \texttt{lexeme{[}{]}} takes its given parser and wraps it in a \texttt{lexeme\_parser}. This in turn turns off the sequence parser combining logic, since both sides of the second \texttt{operator>>} in \texttt{lexeme{[}a >> b{]} >> c} are not \texttt{seq\_parsers}. Sequence parsers have several rules that govern what the overall attribute type of the parser is, based on the positions and attributes of it subparsers (see Attribute Generation). Therefore, it's important to know which directives create a new parser (and what kind), and which ones do not; this is indicated for each directive below.

\subsubsection{The directives}

\subsubsection{repeat()}

See The Parsers And Their Uses. Creates a \texttt{repeat\_parser}.

\subsubsection{if\_()}

See The Parsers And Their Uses. Creates a \texttt{seq\_parser}.

\subsubsection{omit{[}{]}}

\texttt{omit{[}p{]}} disables attribute generation for the parser \texttt{p}. Not only does \texttt{omit{[}p{]}} have no attribute, but any attribute generation work that normally happens within \texttt{p} is skipped.

This directive can be useful in cases like this: say you have some fairly complicated parser \texttt{p} that generates a large and expensive-to-construct attribute. Now say that you want to write a function that just counts how many times \texttt{p} can match a string (where the matches are non-overlapping). Instead of using \texttt{p} directly, and building all those attributes, or rewriting \texttt{p} without the attribute generation, use \texttt{omit{[}{]}}.

Creates an \texttt{omit\_parser}.

\phantomsection\label{tutorial_split_003.html}{}

\subsubsection{raw{[}{]}}

\texttt{raw{[}p{]}} changes the attribute from \emph{\texttt{ATTR}}\texttt{(p)} to to a view that delimits the subrange of the input that was matched by \texttt{p}. The type of the view is \texttt{subrange<I>}, where \texttt{I} is the type of the iterator used within the parse. Note that this may not be the same as the iterator type passed to \texttt{parse()}. For instance, when parsing UTF-8, the iterator passed to \texttt{parse()} may be \texttt{char8\_t const *}, but within the parse it will be a UTF-8 to UTF-32 transcoding (converting) iterator. Just like \texttt{omit{[}{]}}, \texttt{raw{[}{]}} causes all attribute-generation work within \texttt{p} to be skipped.

Similar to the re-use scenario for \texttt{omit{[}{]}} above, \texttt{raw{[}{]}} could be used to find the \textbf{locations} of all non-overlapping matches of \texttt{p} in a string.

Creates a \texttt{raw\_parser}.

\subsubsection{string\_view{[}{]}}

\texttt{string\_view{[}p{]}} is very similar to \texttt{raw{[}p{]}}, except that it changes the attribute of \texttt{p} to \texttt{std::basic\_string\_view<C>}, where \texttt{C} is the character type of the underlying range being parsed. \texttt{string\_view{[}{]}} requires that the underlying range being parsed is contiguous. Since this can only be detected in C++20 and later, \texttt{string\_view{[}{]}} is not available in C++17 mode.

Similar to the re-use scenario for \texttt{omit{[}{]}} above, \texttt{string\_view{[}{]}} could be used to find the \textbf{locations} of all non-overlapping matches of \texttt{p} in a string. Whether \texttt{raw{[}{]}} or \texttt{string\_view{[}{]}} is more natural to use to report the locations depends on your use case, but they are essentially the same.

Creates a \texttt{string\_view\_parser}.

\subsubsection{no\_case{[}{]}}

\texttt{no\_case{[}p{]}} enables case-insensitive parsing within the parse of \texttt{p}. This applies to the text parsed by \texttt{char\_()}, \texttt{string()}, and \texttt{bool\_} parsers. The number parsers are already case-insensitive. The case-insensitivity is achieved by doing Unicode case folding on the text being parsed and the values in the parser being matched (see note below if you want to know more about Unicode case folding). In the non-Unicode code path, a full Unicode case folding is not done; instead, only the transformations of values less than \texttt{0x100} are done. Examples:

\begin{code}
#include <boost/parser/transcode_view.hpp> // For as_utfN.

namespace bp = boost::parser;
auto const street_parser = bp::string(u8"Tobias Straße");
assert(!bp::parse("Tobias Strasse" | bp::as_utf32, street_parser));             // No match.
assert(bp::parse("Tobias Strasse" | bp::as_utf32, bp::no_case[street_parser])); // Match!

auto const alpha_parser = bp::no_case[bp::char_('a', 'z')];
assert(bp::parse("a" | bp::as_utf32, bp::no_case[alpha_parser])); // Match!
assert(bp::parse("B" | bp::as_utf32, bp::no_case[alpha_parser])); // Match!
\end{code}

Everything pretty much does what you'd naively expect inside \texttt{no\_case{[}{]}}, except that the two-character range version of \texttt{char\_} has a limitation. It only compares a code point from the input to its two arguments (e.g. \texttt{'a'} and \texttt{'z'} in the example above). It does not do anything special for multi-code point case folding expansions. For instance, \texttt{char\_(U'ß', U'ß')} matches the input \texttt{U"s"}, which makes sense, since \texttt{U'ß'} expands to \texttt{U"ss"}. However, that same parser \textbf{does not} match the input \texttt{U"ß"}! In short, stick to pairs of code points that have single-code point case folding expansions. If you need to support the multi-expanding code points, use the other overload, like: \texttt{char\_(U"abcd/*...*/ß")}.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Note \\
Unicode case folding is an operation that makes text uniformly one case, and if you do it to two bits of text \texttt{A} and \texttt{B}, then you can compare them bitwise to see if they are the same, except of case. Case folding may sometimes expand a code point into multiple code points (e.g. case folding \texttt{"ẞ"} yields \texttt{"ss"}. When such a multi-code point expansion occurs, the expanded code points are in the NFKC normalization form. & \\
\end{longtable}

Creates a \texttt{no\_case\_parser}.

\subsubsection{lexeme{[}{]}}

\texttt{lexeme{[}p{]}} disables use of the skipper, if a skipper is being used, within the parse of \texttt{p}. This is useful, for instance, if you want to enable skipping in most parts of your parser, but disable it only in one section where it doesn't belong. If you are skipping whitespace in most of your parser, but want to parse strings that may contain spaces, you should use \texttt{lexeme{[}{]}}:

\begin{code}
namespace bp = boost::parser;
auto const string_parser = bp::lexeme['"' >> *(bp::char_ - '"') >> '"'];
\end{code}

Without \texttt{lexeme{[}{]}}, our string parser would correctly match \texttt{"foo bar"}, but the generated attribute would be \texttt{"foobar"}.

Creates a \texttt{lexeme\_parser}.

\subsubsection{skip{[}{]}}

\texttt{skip{[}{]}} is like the inverse of \texttt{lexeme{[}{]}}. It enables skipping in the parse, even if it was not enabled before. For example, within a call to \texttt{parse()} that uses a skipper, let's say we have these parsers in use:

\begin{code}
namespace bp = boost::parser;
auto const one_or_more = +bp::char_;
auto const skip_or_skip_not_there_is_no_try = bp::lexeme[bp::skip[one_or_more] >> one_or_more];
\end{code}

The use of \texttt{lexeme{[}{]}} disables skipping, but then the use of \texttt{skip{[}{]}} turns it back on. The net result is that the first occurrence of \texttt{one\_or\_more} will use the skipper passed to \texttt{parse()}; the second will not.

\texttt{skip{[}{]}} has another use. You can parameterize skip with a different parser to change the skipper just within the scope of the directive. Let's say we passed \texttt{ws} to \texttt{parse()}, and we're using these parsers somewhere within that \texttt{parse()} call:

\begin{code}
namespace bp = boost::parser;
auto const zero_or_more = *bp::char_;
auto const skip_both_ways = zero_or_more >> bp::skip(bp::blank)[zero_or_more];
\end{code}

The first occurrence of \texttt{zero\_or\_more} will use the skipper passed to \texttt{parse()}, which is \texttt{ws}; the second will use \texttt{blank} as its skipper.

Creates a \texttt{skip\_parser}.

\subsubsection{\texorpdfstring{merge{[}{]}, separate{[}{]}, and \texttt{transform(f){[}{]}}}{merge{[}{]}, separate{[}{]}, and transform(f){[}{]}}}

These directives influence the generation of attributes. See Attribute Generation section for more details on them.

\texttt{merge{[}{]}} and \texttt{separate{[}{]}} create a copy of the given \texttt{seq\_parser}.

\texttt{transform(f){[}{]}} creates a \texttt{tranform\_parser}.

\subsection{Combining Operations}

Certain overloaded operators are defined for all parsers in Boost.Parser. We've already seen some of them used in this tutorial, especially \texttt{operator>>}, \texttt{operator|}, and \texttt{operator||}, which are used to form sequence parsers, alternative parsers, and permutation parsers, respectively.

Here are all the operator overloaded for parsers. In the tables below:

\begin{itemize}
\item
  \texttt{c} is a character of type \texttt{char} or \texttt{char32\_t};
\item
  \texttt{a} is a semantic action;
\item
  \texttt{r} is an object whose type models \texttt{parsable\_range} (see Concepts); and
\item
  \texttt{p}, \texttt{p1}, \texttt{p2}, ... are parsers.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Note \\
Some of the expressions in this table consume no input. All parsers consume the input they match unless otherwise stated in the table below. & \\
\end{longtable}

\textbf{Table~26.7.~Combining Operations and Their Semantics}

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Expression & Semantics & Attribute Type & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{!p} & Matches iff \texttt{p} does not match; consumes no input. & None. & \\
\texttt{\&p} & Matches iff \texttt{p} matches; consumes no input. & None. & \\
\texttt{*p} & Parses using \texttt{p} repeatedly until \texttt{p} no longer matches; always matches. & \texttt{std::string} if \emph{\texttt{ATTR}}\texttt{(p)} is \texttt{char} or \texttt{char32\_t}, otherwise \texttt{std::vector<}\emph{\texttt{ATTR}}\texttt{(p)>} & Matching \texttt{eps} an unlimited number of times creates an infinite loop, which is undefined behavior in C++. Boost.Parser will assert in debug mode when it encounters \texttt{*eps} (this applies to unconditional \texttt{eps} only). \\
\texttt{+p} & Parses using \texttt{p} repeatedly until \texttt{p} no longer matches; matches iff \texttt{p} matches at least once. & \texttt{std::string} if \emph{\texttt{ATTR}}\texttt{(p)} is \texttt{char} or \texttt{char32\_t}, otherwise \texttt{std::vector<}\emph{\texttt{ATTR}}\texttt{(p)>} & Matching \texttt{eps} an unlimited number of times creates an infinite loop, which is undefined behavior in C++. Boost.Parser will assert in debug mode when it encounters \texttt{+eps} (this applies to unconditional \texttt{eps} only). \\
\texttt{-p} & Equivalent to \texttt{p | eps}. & \texttt{std::optional<}\emph{\texttt{ATTR}}\texttt{(p)>} & \\
\texttt{p1 >> p2} & Matches iff \texttt{p1} matches and then \texttt{p2} matches. & \texttt{boost::parser::tuple<}\emph{\texttt{ATTR}}\texttt{(p1), }\emph{\texttt{ATTR}}\texttt{(p2)>} (See note.) & \texttt{>>} is associative; \texttt{p1 >> p2 >> p3}, \texttt{(p1 >> p2) >> p3}, and \texttt{p1 >> (p2 >> p3)} are all equivalent. This attribute type only applies to the case where \texttt{p1} and \texttt{p2} both generate attributes; see Attribute Generation for the full rules. \\
\texttt{p >> c} & Equivalent to \texttt{p >> lit(c)}. & \emph{\texttt{ATTR}}\texttt{(p)} & \\
\texttt{p >> r} & Equivalent to \texttt{p >> lit(r)}. & \emph{\texttt{ATTR}}\texttt{(p)} & \\
\texttt{p1 > p2} & Matches iff \texttt{p1} matches and then \texttt{p2} matches. No back-tracking is allowed after \texttt{p1} matches; if \texttt{p1} matches but then \texttt{p2} does not, the top-level parse fails. & \texttt{boost::parser::tuple<}\emph{\texttt{ATTR}}\texttt{(p1), }\emph{\texttt{ATTR}}\texttt{(p2)>} (See note.) & \texttt{>} is associative; \texttt{p1 > p2 > p3}, \texttt{(p1 > p2) > p3}, and \texttt{p1 > (p2 > p3)} are all equivalent. This attribute type only applies to the case where \texttt{p1} and \texttt{p2} both generate attributes; see Attribute Generation for the full rules. \\
\texttt{p > c} & Equivalent to \texttt{p > lit(c)}. & \emph{\texttt{ATTR}}\texttt{(p)} & \\
\texttt{p > r} & Equivalent to \texttt{p > lit(r)}. & \emph{\texttt{ATTR}}\texttt{(p)} & \\
\texttt{p1 | p2} & Matches iff either \texttt{p1} matches or \texttt{p2} matches. & \texttt{std::variant<}\emph{\texttt{ATTR}}\texttt{(p1), }\emph{\texttt{ATTR}}\texttt{(p2)>} (See note.) & \texttt{|} is associative; \texttt{p1 | p2 | p3}, \texttt{(p1 | p2) | p3}, and \texttt{p1 | (p2 | p3)} are all equivalent. This attribute type only applies to the case where \texttt{p1} and \texttt{p2} both generate attributes, and where the attribute types are different; see Attribute Generation for the full rules. \\
\texttt{p | c} & Equivalent to \texttt{p | lit(c)}. & \emph{\texttt{ATTR}}\texttt{(p)} & \\
\texttt{p | r} & Equivalent to \texttt{p | lit(r)}. & \emph{\texttt{ATTR}}\texttt{(p)} & \\
\texttt{p1 || p2} & Matches iff \texttt{p1} matches and \texttt{p2} matches, regardless of the order they match in. & \texttt{boost::parser::tuple<}\emph{\texttt{ATTR}}\texttt{(p1), }\emph{\texttt{ATTR}}\texttt{(p2)>} & \texttt{||} is associative; \texttt{p1 || p2 || p3}, \texttt{(p1 || p2) || p3}, and \texttt{p1 || (p2 || p3)} are all equivalent. It is an error to include a \texttt{eps} (conditional or non-conditional) in an \texttt{operator||} expression. Though the parsers are matched in any order, the attribute elements are always in the order written in the \texttt{operator||} expression. \\
\texttt{p1 - p2} & Equivalent to \texttt{!p2 >> p1}. & \emph{\texttt{ATTR}}\texttt{(p1)} & \\
\texttt{p - c} & Equivalent to \texttt{p - lit(c)}. & \emph{\texttt{ATTR}}\texttt{(p)} & \\
\texttt{p - r} & Equivalent to \texttt{p - lit(r)}. & \emph{\texttt{ATTR}}\texttt{(p)} & \\
\texttt{p1 \% p2} & Equivalent to \texttt{p1 >> *(p2 >> p1)}. & \texttt{std::string} if \emph{\texttt{ATTR}}\texttt{(p)} is \texttt{char} or \texttt{char32\_t}, otherwise \texttt{std::vector<}\emph{\texttt{ATTR}}\texttt{(p1)>} & \\
\texttt{p \% c} & Equivalent to \texttt{p \% lit(c)}. & \texttt{std::string} if \emph{\texttt{ATTR}}\texttt{(p)} is \texttt{char} or \texttt{char32\_t}, otherwise \texttt{std::vector<}\emph{\texttt{ATTR}}\texttt{(p)>} & \\
\texttt{p \% r} & Equivalent to \texttt{p \% lit(r)}. & \texttt{std::string} if \emph{\texttt{ATTR}}\texttt{(p)} is \texttt{char} or \texttt{char32\_t}, otherwise \texttt{std::vector<}\emph{\texttt{ATTR}}\texttt{(p)>} & \\
\texttt{p{[}a{]}} & Matches iff \texttt{p} matches. If \texttt{p} matches, the semantic action \texttt{a} is executed. & None. & \\
\end{longtable}

\hfill\break

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Important \\
All the character parsers, like \texttt{char\_}, \texttt{cp} and \texttt{cu} produce either \texttt{char} or \texttt{char32\_t} attributes. So when you see "\texttt{std::string} if \emph{\texttt{ATTR}}\texttt{(p)} is \texttt{char} or \texttt{char32\_t}, otherwise \texttt{std::vector<}\emph{\texttt{ATTR}}\texttt{(p)>}" in the table above, that effectively means that every sequences of character attributes get turned into a \texttt{std::string}. The only time this does not happen is when you introduce your own rules with attributes using another character type (or use \texttt{attribute} to do so). & \\
\end{longtable}

There are a couple of special rules not captured in the table above:

First, the zero-or-more and one-or-more repetitions (\texttt{operator*()} and \texttt{operator+()}, respectively) may collapse when combined. For any parser \texttt{p}, \texttt{+(+p)} collapses to \texttt{+p}; \texttt{**p}, \texttt{*+p}, and \texttt{+*p} each collapse to just \texttt{*p}.

Second, using \texttt{eps} in an alternative parser as any alternative \textbf{except} the last one is a common source of errors; Boost.Parser disallows it. This is true because, for any parser \texttt{p}, \texttt{eps | p} is equivalent to \texttt{eps}, since \texttt{eps} always matches. This is not true for \texttt{eps} parameterized with a condition. For any condition \texttt{cond}, \texttt{eps(cond)} is allowed to appear anywhere within an alternative parser.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Note \\
When looking at Boost.Parser parsers in a debugger, or when looking at their reference documentation, you may see reference to the template \texttt{parser\_interface}. This template exists to provide the operator overloads described above. It allows the parsers themselves to be very simple --- most parsers are just a struct with two member functions. \texttt{parser\_interface} is essentially invisible when using Boost.Parser, and you should never have to name this template in your own code. & \\
\end{longtable}

\subsection{Attribute Generation}

So far, we've seen several different types of attributes that come from different parsers, \texttt{int} for \texttt{int\_}, \texttt{boost::parser::tuple<char, int>} for \texttt{boost::parser::char\_ >> boost::parser::int\_}, etc. Let's get into how this works with more rigor.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Note \\
Some parsers have no attribute at all. In the tables below, the type of the attribute is listed as "None." There is a non-\texttt{void} type that is returned from each parser that lacks an attribute. This keeps the logic simple; having to handle the two cases --- \texttt{void} or non-\texttt{void} --- would make the library significantly more complicated. The type of this non-\texttt{void} attribute associated with these parsers is an implementation detail. The type comes from the \texttt{boost::parser::detail} namespace and is pretty useless. You should never see this type in practice. Within semantic actions, asking for the attribute of a non-attribute-producing parser (using \texttt{\_attr(ctx)}) will yield a value of the special type \texttt{boost::parser::none}. When calling \texttt{parse()} in a form that returns the attribute parsed, when there is no attribute, simply returns \texttt{bool}; this indicates the success of failure of the parse. & \\
\end{longtable}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Warning \\
Boost.Parser assumes that all attributes are semi-regular (see \texttt{std::semiregular}). Within the Boost.Parser code, attributes are assigned, moved, copy, and default constructed. There is no support for move-only or non-default-constructible types. & \\
\end{longtable}

\subsubsection{The attribute type trait, attribute}

You can use \texttt{attribute} (and the associated alias, \texttt{attribute\_t}) to determine the attribute a parser would have if it were passed to \texttt{parse()}. Since at least one parser (\texttt{char\_}) has a polymorphic attribute type, \texttt{attribute} also takes the type of the range being parsed. If a parser produces no attribute, \texttt{attribute} will produce \texttt{none}, not \texttt{void}.

If you want to feed an iterator/sentinel pair to \texttt{attribute}, create a range from it like so:

\begin{code}
constexpr auto parser = /* ... */;
auto first = /* ... */;
auto const last = /* ... */;

namespace bp = boost::parser;
// You can of course use std::ranges::subrange directly in C++20 and later.
using attr_type = bp::attribute_t<decltype(BOOST_PARSER_SUBRANGE(first, last)), decltype(parser)>;
\end{code}

There is no single attribute type for any parser, since a parser can be placed within \texttt{omit{[}{]}}, which makes its attribute type \texttt{none}. Therefore, \texttt{attribute} cannot tell you what attribute your parser will produce under all circumstances; it only tells you what it would produce if it were passed to \texttt{parse()}.

\subsubsection{Parser attributes}

This table summarizes the attributes generated for all Boost.Parser parsers. In the table below:

\begin{itemize}
\item
  \emph{\texttt{RESOLVE}}\texttt{()} is a notional macro that expands to the resolution of parse argument or evaluation of a parse predicate (see The Parsers And Their Uses); and
\item
  \texttt{x} and \texttt{y} represent arbitrary objects.
\end{itemize}

\textbf{Table~26.8.~Parsers and Their Attributes}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
Parser & Attribute Type & Notes \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{eps} & None. & \\
\texttt{eol} & None. & \\
\texttt{eoi} & None. & \\
\texttt{attr(x)} & \texttt{decltype(}\emph{\texttt{RESOLVE}}\texttt{(x))} & \\
\texttt{char\_} & The code point type in Unicode parsing, or \texttt{char} in non-Unicode parsing; see below. & Includes all the \texttt{\_p} UDLs that take a single character, and all character class parsers like \texttt{control} and \texttt{lower}. \\
\texttt{cp} & \texttt{char32\_t} & \\
\texttt{cu} & \texttt{char} & \\
\texttt{lit(x)} & None. & Includes all the \texttt{\_l} UDLs. \\
\texttt{string(x)} & \texttt{std::string} & Includes all the \texttt{\_p} UDLs that take a string. \\
\texttt{bool\_} & \texttt{bool} & \\
\texttt{bin} & \texttt{unsigned int} & \\
\texttt{oct} & \texttt{unsigned int} & \\
\texttt{hex} & \texttt{unsigned int} & \\
\texttt{ushort\_} & \texttt{unsigned short} & \\
\texttt{uint\_} & \texttt{unsigned int} & \\
\texttt{ulong\_} & \texttt{unsigned long} & \\
\texttt{ulong\_long} & \texttt{unsigned long long} & \\
\texttt{short\_} & \texttt{short} & \\
\texttt{int\_} & \texttt{int} & \\
\texttt{long\_} & \texttt{long} & \\
\texttt{long\_long} & \texttt{long long} & \\
\texttt{float\_} & \texttt{float} & \\
\texttt{double\_} & \texttt{double} & \\
\texttt{symbols<T>} & \texttt{T} & \\
\end{longtable}

\hfill\break

\texttt{char\_} is a bit odd, since its attribute type is polymorphic. When you use \texttt{char\_} to parse text in the non-Unicode code path (i.e. a string of \texttt{char}), the attribute is \texttt{char}. When you use the exact same \texttt{char\_} to parse in the Unicode-aware code path, all matching is code point based, and so the attribute type is the type used to represent code points, \texttt{char32\_t}. All parsing of UTF-8 falls under this case.

Here, we're parsing plain \texttt{char}s, meaning that the parsing is in the non-Unicode code path, the attribute of \texttt{char\_} is \texttt{char}:

\begin{code}
auto result = parse("some text", boost::parser::char_);
static_assert(std::is_same_v<decltype(result), std::optional<char>>));
\end{code}

When you parse UTF-8, the matching is done on a code point basis, so the attribute type is \texttt{char32\_t}:

\begin{code}
auto result = parse("some text" | boost::parser::as_utf8, boost::parser::char_);
static_assert(std::is_same_v<decltype(result), std::optional<char32_t>>));
\end{code}

The good news is that usually you don't parse characters individually. When you parse with \texttt{char\_}, you usually parse repetition of then, which will produce a \texttt{std::string}, regardless of whether you're in Unicode parsing mode or not. If you do need to parse individual characters, and want to lock down their attribute type, you can use \texttt{cp} and/or \texttt{cu} to enforce a non-polymorphic attribute type.

\subsubsection{Combining operation attributes}

Combining operations of course affect the generation of attributes. In the tables below:

\begin{itemize}
\item
  \texttt{m} and \texttt{n} are parse arguments that resolve to integral values;
\item
  \texttt{pred} is a parse predicate;
\item
  \texttt{arg0}, \texttt{arg1}, \texttt{arg2}, ... are parse arguments;
\item
  \texttt{a} is a semantic action; and
\item
  \texttt{p}, \texttt{p1}, \texttt{p2}, ... are parsers that generate attributes.
\end{itemize}

\textbf{Table~26.9.~Combining Operations and Their Attributes}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Parser & Attribute Type \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{!p} & None. \\
\texttt{\&p} & None. \\
\texttt{*p} & \texttt{std::string} if \emph{\texttt{ATTR}}\texttt{(p)} is \texttt{char} or \texttt{char32\_t}, otherwise \texttt{std::vector<}\emph{\texttt{ATTR}}\texttt{(p)>} \\
\texttt{+p} & \texttt{std::string} if \emph{\texttt{ATTR}}\texttt{(p)} is \texttt{char} or \texttt{char32\_t}, otherwise \texttt{std::vector<}\emph{\texttt{ATTR}}\texttt{(p)>} \\
\texttt{+*p} & \texttt{std::string} if \emph{\texttt{ATTR}}\texttt{(p)} is \texttt{char} or \texttt{char32\_t}, otherwise \texttt{std::vector<}\emph{\texttt{ATTR}}\texttt{(p)>} \\
\texttt{*+p} & \texttt{std::string} if \emph{\texttt{ATTR}}\texttt{(p)} is \texttt{char} or \texttt{char32\_t}, otherwise \texttt{std::vector<}\emph{\texttt{ATTR}}\texttt{(p)>} \\
\texttt{-p} & \texttt{std::optional<}\emph{\texttt{ATTR}}\texttt{(p)>} \\
\texttt{p1 >> p2} & \texttt{boost::parser::tuple<}\emph{\texttt{ATTR}}\texttt{(p1), }\emph{\texttt{ATTR}}\texttt{(p2)>} \\
\texttt{p1 > p2} & \texttt{boost::parser::tuple<}\emph{\texttt{ATTR}}\texttt{(p1), }\emph{\texttt{ATTR}}\texttt{(p2)>} \\
\texttt{p1 >> p2 >> p3} & \texttt{boost::parser::tuple<}\emph{\texttt{ATTR}}\texttt{(p1), }\emph{\texttt{ATTR}}\texttt{(p2), }\emph{\texttt{ATTR}}\texttt{(p3)>} \\
\texttt{p1 > p2 >> p3} & \texttt{boost::parser::tuple<}\emph{\texttt{ATTR}}\texttt{(p1), }\emph{\texttt{ATTR}}\texttt{(p2), }\emph{\texttt{ATTR}}\texttt{(p3)>} \\
\texttt{p1 >> p2 > p3} & \texttt{boost::parser::tuple<}\emph{\texttt{ATTR}}\texttt{(p1), }\emph{\texttt{ATTR}}\texttt{(p2), }\emph{\texttt{ATTR}}\texttt{(p3)>} \\
\texttt{p1 > p2 > p3} & \texttt{boost::parser::tuple<}\emph{\texttt{ATTR}}\texttt{(p1), }\emph{\texttt{ATTR}}\texttt{(p2), }\emph{\texttt{ATTR}}\texttt{(p3)>} \\
\texttt{p1 | p2} & \texttt{std::variant<}\emph{\texttt{ATTR}}\texttt{(p1), }\emph{\texttt{ATTR}}\texttt{(p2)>} \\
\texttt{p1 | p2 | p3} & \texttt{std::variant<}\emph{\texttt{ATTR}}\texttt{(p1), }\emph{\texttt{ATTR}}\texttt{(p2), }\emph{\texttt{ATTR}}\texttt{(p3)>} \\
\texttt{p1 || p2} & \texttt{boost::parser::tuple<}\emph{\texttt{ATTR}}\texttt{(p1), }\emph{\texttt{ATTR}}\texttt{(p2)>} \\
\texttt{p1 || p2 || p3} & \texttt{boost::parser::tuple<}\emph{\texttt{ATTR}}\texttt{(p1), }\emph{\texttt{ATTR}}\texttt{(p2), }\emph{\texttt{ATTR}}\texttt{(p3)>} \\
\texttt{p1 \% p2} & \texttt{std::string} if \emph{\texttt{ATTR}}\texttt{(p)} is \texttt{char} or \texttt{char32\_t}, otherwise \texttt{std::vector<}\emph{\texttt{ATTR}}\texttt{(p1)>} \\
\texttt{p{[}a{]}} & None. \\
\texttt{repeat(arg0){[}p{]}} & \texttt{std::string} if \emph{\texttt{ATTR}}\texttt{(p)} is \texttt{char} or \texttt{char32\_t}, otherwise \texttt{std::vector<}\emph{\texttt{ATTR}}\texttt{(p)>} \\
\texttt{repeat(arg0, arg1){[}p{]}} & \texttt{std::string} if \emph{\texttt{ATTR}}\texttt{(p)} is \texttt{char} or \texttt{char32\_t}, otherwise \texttt{std::vector<}\emph{\texttt{ATTR}}\texttt{(p)>} \\
\texttt{if\_(pred){[}p{]}} & \texttt{std::optional<}\emph{\texttt{ATTR}}\texttt{(p)>} \\
\texttt{switch\_(arg0)(arg1, p1)(arg2, p2)...} & \texttt{std::variant<}\emph{\texttt{ATTR}}\texttt{(p1), }\emph{\texttt{ATTR}}\texttt{(p2), ...>} \\
\end{longtable}

\hfill\break

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Important \\
All the character parsers, like \texttt{char\_}, \texttt{cp} and \texttt{cu} produce either \texttt{char} or \texttt{char32\_t} attributes. So when you see "\texttt{std::string} if \emph{\texttt{ATTR}}\texttt{(p)} is \texttt{char} or \texttt{char32\_t}, otherwise \texttt{std::vector<}\emph{\texttt{ATTR}}\texttt{(p)>}" in the table above, that effectively means that every sequences of character attributes get turned into a \texttt{std::string}. The only time this does not happen is when you introduce your own rules with attributes using another character type (or use \texttt{attribute} to do so). & \\
\end{longtable}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Important \\
In case you did not notice it above, adding a semantic action to a parser erases the parser's attribute. The attribute is still available inside the semantic action as \texttt{\_attr(ctx)}. & \\
\end{longtable}

There are a relatively small number of rules that define how sequence parsers and alternative parsers' attributes are generated. (Don't worry, there are examples below.)

\subsubsection{Sequence parser attribute rules}

The attribute generation behavior of sequence parsers is conceptually pretty simple:

\begin{itemize}
\item
  the attributes of subparsers form a tuple of values;
\item
  subparsers that do not generate attributes do not contribute to the sequence's attribute;
\item
  subparsers that do generate attributes usually contribute an individual element to the tuple result; except
\item
  when containers of the same element type are next to each other, or individual elements are next to containers of their type, the two adjacent attributes collapse into one attribute; and
\item
  if the result of all that is a degenerate tuple \texttt{boost::parser::tuple<T>} (even if \texttt{T} is a type that means "no attribute"), the attribute becomes \texttt{T}.
\end{itemize}

More formally, the attribute generation algorithm works like this. For a sequence parser \texttt{p}, let the list of attribute types for the subparsers of \texttt{p} be \texttt{a0, a1, a2, ..., an}.

We get the attribute of \texttt{p} by evaluating a compile-time left fold operation, \texttt{left-fold(\{a1, a2, ..., an\}, tuple<a0>, OP)}. \texttt{OP} is the combining operation that takes the current attribute type (initially \texttt{boost::parser::tuple<a0>}) and the next attribute type, and returns the new current attribute type. The current attribute type at the end of the fold operation is the attribute type for \texttt{p}.

\texttt{OP} attempts to apply a series of rules, one at a time. The rules are noted as \texttt{X >> Y -> Z}, where \texttt{X} is the type of the current attribute, \texttt{Y} is the type of the next attribute, and \texttt{Z} is the new current attribute type. In these rules, \texttt{C<T>} is a container of \texttt{T}; \texttt{none} is a special type that indicates that there is no attribute; \texttt{T} is a type; \texttt{CHAR} is a character type, either \texttt{char} or \texttt{char32\_t}; and \texttt{Ts...} is a parameter pack of one or more types. Note that \texttt{T} may be the special type \texttt{none}. The current attribute is always a tuple (call it \texttt{Tup}), so the "current attribute \texttt{X}" refers to the last element of \texttt{Tup}, not \texttt{Tup} itself, except for those rules that explicitly mention \texttt{boost::parser::tuple<>} as part of \texttt{X}'s type.

\begin{itemize}
\item
  \texttt{none >> T -> T}
\item
  \texttt{CHAR} \textgreater> \texttt{CHAR} -> \texttt{std::string}
\item
  \texttt{T >> none -> T}
\item
  \texttt{C<T> >> T -> C<T>}
\item
  \texttt{T >> C<T> -> C<T>}
\item
  \texttt{C<T> >> optional<T> -> C<T>}
\item
  \texttt{optional<T> >> C<T> -> C<T>}
\item
  \texttt{boost::parser::tuple<none> >> T -> boost::parser::tuple<T>}
\item
  \texttt{boost::parser::tuple<Ts...> >> T -> boost::parser::tuple<Ts..., T>}
\end{itemize}

The rules that combine containers with (possibly optional) adjacent values (e.g. \texttt{C<T> >> optional<T> -> C<T>}) have a special case for strings. If \texttt{C<T>} is exactly \texttt{std::string}, and \texttt{T} is either \texttt{char} or \texttt{char32\_t}, the combination yields a \texttt{std::string}.

Again, if the final result is that the attribute is \texttt{boost::parser::tuple<T>}, the attribute becomes \texttt{T}.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Note \\
\begin{minipage}[t]{\linewidth}\raggedright
What constitutes a container in the rules above is determined by the \texttt{container} concept:

\begin{code}
template<typename T>
concept container = std::ranges::common_range<T> && requires(T t) {
    { t.insert(t.begin(), *t.begin()) }
        -> std::same_as<std::ranges::iterator_t<T>>;
};
\end{code}
\end{minipage} & \\
\end{longtable}

\subsubsection{Alternative parser attribute rules}

The rules for alternative parsers are much simpler. For an alternative parer \texttt{p}, let the list of attribute types for the subparsers of \texttt{p} be \texttt{a0, a1, a2, ..., an}. The attribute of \texttt{p} is \texttt{std::variant<a0, a1, a2, ..., an>}, with the following steps applied:

\begin{itemize}
\item
  all the \texttt{none} attributes are left out, and if any are, the attribute is wrapped in a \texttt{std::optional}, like \texttt{std::optional<std::variant</*...*/>>};
\item
  duplicates in the \texttt{std::variant} template parameters \texttt{<T1, T2, ... Tn>} are removed; every type that appears does so exacly once;
\item
  if the attribute is \texttt{std::variant<T>} or \texttt{std::optional<std::variant<T>>}, the attribute becomes instead \texttt{T} or \texttt{std::optional<T>}, respectively; and
\item
  if the attribute is \texttt{std::variant<>} or \texttt{std::optional<std::variant<>>}, the result becomes \texttt{none} instead.
\end{itemize}

\subsubsection{Formation of containers in attributes}

The rule for forming containers from non-containers is simple. You get a vector from any of the repeating parsers, like \texttt{+p}, \texttt{*p}, \texttt{repeat(3){[}p{]}}, etc. The value type of the vector is \emph{\texttt{ATTR}}\texttt{(p)}.

Another rule for sequence containers is that a value \texttt{x} and a container \texttt{c} containing elements of \texttt{x}'s type will form a single container. However, \texttt{x}'s type must be exactly the same as the elements in \texttt{c}. There is an exception to this in the special case for strings and characters noted above. For instance, consider the attribute of \texttt{char\_ >> string("str")}. In the non-Unicode code path, \texttt{char\_}'s attribute type is guaranteed to be \texttt{char}, so \emph{\texttt{ATTR}}\texttt{(char\_ >> string("str"))} is \texttt{std::string}. If you are parsing UTF-8 in the Unicode code path, \texttt{char\_}'s attribute type is \texttt{char32\_t}, and the special rule makes it also produce a \texttt{std::string}. Otherwise, the attribute for \emph{\texttt{ATTR}}\texttt{(char\_ >> string("str"))} would be \texttt{boost::parser::tuple<char32\_t, std::string>}.

Again, there are no special rules for combining values and containers. Every combination results from an exact match, or fall into the string+character special case.

\phantomsection\label{tutorial_split_004.html}{}

\subsubsection{\texorpdfstring{Another special case: \texttt{std::string} assignment}{Another special case: std::string assignment}}

\texttt{std::string} can be assigned from a \texttt{char}. This is dumb. But, we're stuck with it. When you write a parser with a \texttt{char} attribute, and you try to parse it into a \texttt{std::string}, you've almost certainly made a mistake. More importantly, if you write this:

\begin{code}
namespace bp = boost::parser;
std::string result;
auto b = bp::parse("3", bp::int_, bp::ws, result);
\end{code}

... you are even more likely to have made a mistake. Though this should work, because the assignment in \texttt{std::string s; s = 3;} is well-formed, Boost.Parser forbids it. If you write parsing code like the snippet above, you will get a static assertion. If you really do want to assign a \texttt{float} or whatever to a \texttt{std::string}, do it in a semantic action.

\subsubsection{Examples of attributes generated by sequence and alternative parsers}

In the table: \texttt{a} is a semantic action; and \texttt{p}, \texttt{p1}, \texttt{p2}, ... are parsers that generate attributes. Note that only \texttt{>>} is used here; \texttt{>} has the exact same attribute generation rules.

\textbf{Table~26.10.~Sequence and Alternative Combining Operations and Their Attributes}

\begin{longtable}[]{@{}ll@{}}
\toprule\noalign{}
Expression & Attribute Type \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{eps >> eps} & None. \\
\texttt{p >> eps} & \emph{\texttt{ATTR}}\texttt{(p)} \\
\texttt{eps >> p} & \emph{\texttt{ATTR}}\texttt{(p)} \\
\texttt{cu >> string("str")} & \texttt{std::string} \\
\texttt{string("str") >> cu} & \texttt{std::string} \\
\texttt{*cu >> string("str")} & \texttt{boost::parser::tuple<std::string, std::string>} \\
\texttt{string("str") >> *cu} & \texttt{boost::parser::tuple<std::string, std::string>} \\
\texttt{p >> p} & \texttt{boost::parser::tuple<}\emph{\texttt{ATTR}}\texttt{(p), }\emph{\texttt{ATTR}}\texttt{(p)>} \\
\texttt{*p >> p} & \texttt{std::string} if \emph{\texttt{ATTR}}\texttt{(p)} is \texttt{char} or \texttt{char32\_t}, otherwise \texttt{std::vector<}\emph{\texttt{ATTR}}\texttt{(p)>} \\
\texttt{p >> *p} & \texttt{std::string} if \emph{\texttt{ATTR}}\texttt{(p)} is \texttt{char} or \texttt{char32\_t}, otherwise \texttt{std::vector<}\emph{\texttt{ATTR}}\texttt{(p)>} \\
\texttt{*p >> -p} & \texttt{std::string} if \emph{\texttt{ATTR}}\texttt{(p)} is \texttt{char} or \texttt{char32\_t}, otherwise \texttt{std::vector<}\emph{\texttt{ATTR}}\texttt{(p)>} \\
\texttt{-p >> *p} & \texttt{std::string} if \emph{\texttt{ATTR}}\texttt{(p)} is \texttt{char} or \texttt{char32\_t}, otherwise \texttt{std::vector<}\emph{\texttt{ATTR}}\texttt{(p)>} \\
\texttt{string("str") >> -cu} & \texttt{std::string} \\
\texttt{-cu >> string("str")} & \texttt{std::string} \\
\texttt{!p1 | p2{[}a{]}} & None. \\
\texttt{p | p} & \emph{\texttt{ATTR}}\texttt{(p)} \\
\texttt{p1 | p2} & \texttt{std::variant<}\emph{\texttt{ATTR}}\texttt{(p1), }\emph{\texttt{ATTR}}\texttt{(p2)>} \\
\texttt{p | }\texttt{eps} & \texttt{std::optional<}\emph{\texttt{ATTR}}\texttt{(p)>} \\
\texttt{p1 | p2 | eps} & \texttt{std::optional<std::variant<}\emph{\texttt{ATTR}}\texttt{(p1), }\emph{\texttt{ATTR}}\texttt{(p2)>>} \\
\texttt{p1 | p2{[}a{]} | p3} & \texttt{std::optional<std::variant<}\emph{\texttt{ATTR}}\texttt{(p1), }\emph{\texttt{ATTR}}\texttt{(p3)>>} \\
\end{longtable}

\hfill\break

\subsubsection{Controlling attribute generation with merge{[}{]} and separate{[}{]}}

As we saw in the previous Parsing into \texttt{struct}s and \texttt{class}es section, if you parse two strings in a row, you get two separate strings in the resulting attribute. The parser from that example was this:

\begin{code}
namespace bp = boost::parser;
auto employee_parser = bp::lit("employee")
    >> '{'
    >> bp::int_ >> ','
    >> quoted_string >> ','
    >> quoted_string >> ','
    >> bp::double_
    >> '}';
\end{code}

\texttt{employee\_parser}'s attribute is \texttt{boost::parser::tuple<int, std::string, std::string, double>}. The two \texttt{quoted\_string} parsers produce \texttt{std::string} attributes, and those attributes are not combined. That is the default behavior, and it is just what we want for this case; we don't want the first and last name fields to be jammed together such that we can't tell where one name ends and the other begins. What if we were parsing some string that consisted of a prefix and a suffix, and the prefix and suffix were defined separately for reuse elsewhere?

\begin{code}
namespace bp = boost::parser;
auto prefix = /* ... */;
auto suffix = /* ... */;
auto special_string = prefix >> suffix;
// Continue to use prefix and suffix to make other parsers....
\end{code}

In this case, we might want to use these separate parsers, but want \texttt{special\_string} to produce a single \texttt{std::string} for its attribute. \texttt{merge{[}{]}} exists for this purpose.

\begin{code}
namespace bp = boost::parser;
auto prefix = /* ... */;
auto suffix = /* ... */;
auto special_string = bp::merge[prefix >> suffix];
\end{code}

\texttt{merge{[}{]}} only applies to sequence parsers (like \texttt{p1 >> p2}), and forces all subparsers in the sequence parser to use the same variable for their attribute.

Another directive, \texttt{separate{[}{]}}, also applies only to sequence parsers, but does the opposite of \texttt{merge{[}{]}}. If forces all the attributes produced by the subparsers of the sequence parser to stay separate, even if they would have combined. For instance, consider this parser.

\begin{code}
namespace bp = boost::parser;
auto string_and_char = +bp::char_('a') >> ' ' >> bp::cp;
\end{code}

\texttt{string\_and\_char} matches one or more \texttt{'a'}s, followed by some other character. As written above, \texttt{string\_and\_char} produces a \texttt{std::string}, and the final character is appended to the string, after all the \texttt{'a'}s. However, if you wanted to store the final character as a separate value, you would use \texttt{separate{[}{]}}.

\begin{code}
namespace bp = boost::parser;
auto string_and_char = bp::separate[+bp::char_('a') >> ' ' >> bp::cp];
\end{code}

With this change, \texttt{string\_and\_char} produces the attribute \texttt{boost::parser::tuple<std::string, char32\_t>}.

\subsubsection{merge{[}{]} and separate{[}{]} in more detail}

As mentioned previously, \texttt{merge{[}{]}} applies only to sequence parsers. All subparsers must have the same attribute, or produce no attribute at all. At least one subparser must produce an attribute. When you use \texttt{merge{[}{]}}, you create a \emph{combining group}. Every parser in a combining group uses the same variable for its attribute. No parser in a combining group interacts with the attributes of any parsers outside of its combining group. Combining groups are disjoint; \texttt{merge{[}/*...*/{]} >> merge{[}/*...*/{]}} will produce a tuple of two attributes, not one.

\texttt{separate{[}{]}} also applies only to sequence parsers. When you use \texttt{separate{[}{]}}, you disable interaction of all the subparsers' attributes with adjacent attributes, whether they are inside or outside the \texttt{separate{[}{]}} directive; you force each subparser to have a separate attribute.

The rules for \texttt{merge{[}{]}} and \texttt{separate{[}{]}} overrule the steps of the algorithm described above for combining the attributes of a sequence parser. Consider an example.

\begin{code}
namespace bp = boost::parser;
constexpr auto parser =
    bp::char_ >> bp::merge[(bp::string("abc") >> bp::char_ >> bp::char_) >> bp::string("ghi")];
\end{code}

You might think that \emph{\texttt{ATTR}}\texttt{(parser)} would be \texttt{bp::tuple<char, std::string>}. It is not. The parser above does not even compile. Since we created a merge group above, we disabled the default behavior in which the \texttt{char\_} parsers would have collapsed into the \texttt{string} parser that preceded them. Since they are all treated as separate entities, and since they have different attribute types, the use of \texttt{merge{[}{]}} is an error.

Many directives create a new parser out of the parser they are given. \texttt{merge{[}{]}} and \texttt{separate{[}{]}} do not. Since they operate only on sequence parsers, all they do is create a copy of the sequence parser they are given. The \texttt{seq\_parser} template has a template parameter \texttt{CombiningGroups}, and all \texttt{merge{[}{]}} and \texttt{separate{[}{]}} do is take a given \texttt{seq\_parser} and create a copy of it with a different \texttt{CombiningGroups} template parameter. This means that \texttt{merge{[}{]}} and \texttt{separate{[}{]}} are can be ignored in \texttt{operator>>} expressions much like parentheses are. Consider an example.

\begin{code}
namespace bp = boost::parser;
constexpr auto parser1 = bp::separate[bp::int_ >> bp::int_] >> bp::int_;
constexpr auto parser2 = bp::lexeme[bp::int_ >> ' ' >> bp::int_] >> bp::int_;
\end{code}

Note that \texttt{separate{[}{]}} is a no-op here; it's only being used this way for this example. These parsers have different attribute types. \emph{\texttt{ATTR}}\texttt{(parser1)} is \texttt{boost::parser::tuple(int, int, int)}. \emph{\texttt{ATTR}}\texttt{(parser2)} is \texttt{boost::parser::tuple(boost::parser::tuple(int, int), int)}. This is because \texttt{bp::lexeme{[}{]}} wraps its given parser in a new parser. \texttt{merge{[}{]}} does not. That's why, even though \texttt{parser1} and \texttt{parser2} look so structurally similar, they have different attributes.

\subsubsection{\texorpdfstring{\texttt{transform(f){[}{]}}}{transform(f){[}{]}}}

\texttt{transform(f){[}{]}} is a directive that transforms the attribute of a parser using the given function \texttt{f}. For example:

\begin{code}
auto str_sum = [&](std::string const & s) {
    int retval = 0;
    for (auto ch : s) {
        retval += ch - '0';
    }
    return retval;
};

namespace bp = boost::parser;
constexpr auto parser = +bp::char_;
std::string str = "012345";

auto result = bp::parse(str, bp::transform(str_sum)[parser]);
assert(result);
assert(*result == 15);
static_assert(std::is_same_v<decltype(result), std::optional<int>>);
\end{code}

Here, we have a function \texttt{str\_sum} that we use for \texttt{f}. It assumes each character in the given \texttt{std::string} \texttt{s} is a digit, and returns the sum of all the digits in \texttt{s}. Out parser \texttt{parser} would normally return a \texttt{std::string}. However, since \texttt{str\_sum} returns a different type --- \texttt{int} --- that is the attribute type of the full parser, \texttt{bp::transform(by\_value\_str\_sum){[}parser{]}}, as you can see from the \texttt{static\_assert}.

As is the case with attributes all throughout Boost.Parser, the attribute passed to \texttt{f} will be moved. You can take it by \texttt{const \&}, \texttt{\&\&}, or by value.

No distinction is made between parsers with and without an attribute, because there is a Regular special no-attribute type that is generated by parsers with no attribute. You may therefore write something like \texttt{transform(f){[}eps{]}}, and Boost.Parser will happily call \texttt{f} with this special no-attribute type.

\subsubsection{Other directives that affect attribute generation}

\texttt{omit{[}p{]}} disables attribute generation for the parser \texttt{p}. \texttt{raw{[}p{]}} changes the attribute from \emph{\texttt{ATTR}}\texttt{(p)} to a view that indicates the subrange of the input that was matched by \texttt{p}. \texttt{string\_view{[}p{]}} is just like \texttt{raw{[}p{]}}, except that it produces \texttt{std::basic\_string\_view}s. See Directives for details.

\subsection{\texorpdfstring{The \texttt{parse()} API}{The parse() API}}

There are multiple top-level parse functions. They have some things in common:

\begin{itemize}
\item
  They each return a value contextually convertible to \texttt{bool}.
\item
  They each take at least a range to parse and a parser. The "range to parse" may be an iterator/sentinel pair or an single range object.
\item
  They each require forward iterability of the range to parse.
\item
  They each accept any range with a character element type. This means that they can each parse ranges of \texttt{char}, \texttt{wchar\_t}, \texttt{char8\_t}, \texttt{char16\_t}, or \texttt{char32\_t}.
\item
  The overloads with \texttt{prefix\_} in their name take an iterator/sentinel pair. For example \texttt{prefix\_parse(first, last, p, ws)}, which parses the range \texttt{{[}first, last)}, advancing \texttt{first} as it goes. If the parse succeeds, the entire input may or may not have been matched. The value of \texttt{first} will indicate the last location within the input that \texttt{p} matched. The \textbf{whole} input was matched if and only if \texttt{first == last} after the call to \texttt{parse()}.
\item
  When you call any of the range overloads of \texttt{parse()}, for example \texttt{parse(r, p, ws)}, \texttt{parse()} only indicates success if \textbf{all} of \texttt{r} was matched by \texttt{p}.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Note \\
\texttt{wchar\_t} is an accepted value type for the input. Please note that this is interpreted as UTF-16 on MSVC, and UTF-32 everywhere else. & \\
\end{longtable}

\subsubsection{The overloads}

There are eight overloads of \texttt{parse()} and \texttt{prefix\_parse()} combined, because there are three either/or options in how you call them.

\subsubsection{Iterator/sentinel versus range}

You can call \texttt{prefix\_parse()} with an iterator and sentinel that delimit a range of character values. For example:

\begin{code}
namespace bp = boost::parser;
auto const p = /* some parser ... */;

char const * str_1 = /* ... */;
// Using null_sentinel, str_1 can point to three billion characters, and
// we can call prefix_parse() without having to find the end of the string first.
auto result_1 = bp::prefix_parse(str_1, bp::null_sentinel, p, bp::ws);

char str_2[] = /* ... */;
auto result_2 = bp::prefix_parse(std::begin(str_2), std::end(str_2), p, bp::ws);
\end{code}

The iterator/sentinel overloads can parse successfully without matching the entire input. You can tell if the entire input was matched by checking if \texttt{first == last} is true after \texttt{prefix\_parse()} returns.

By contrast, you call \texttt{parse()} with a range of character values. When the range is a reference to an array of characters, any terminating \texttt{0} is ignored; this allows calls like \texttt{parse("str", p)} to work naturally.

\begin{code}
namespace bp = boost::parser;
auto const p = /* some parser ... */;

std::u8string str_1 = "str";
auto result_1 = bp::parse(str_1, p, bp::ws);

// The null terminator is ignored.  This call parses s-t-r, not s-t-r-0.
auto result_2 = bp::parse(U"str", p, bp::ws);

char const * str_3 = "str";
auto result_3 = bp::parse(bp::null_term(str_3) | bp::as_utf16, p, bp::ws);
\end{code}

Since there is no way to indicate that \texttt{p} matches the input, but only a prefix of the input was matched, the range (non-iterator/sentinel) overloads of \texttt{parse()} indicate failure if the entire input is not matched.

\subsubsection{With or without an attribute out-parameter}

\begin{code}
namespace bp = boost::parser;
auto const p = '"' >> *(bp::char_ - '"') >> '"';
char const * str = "\"two words\"" ;

std::string result_1;
bool const success = bp::parse(str, p, result_1);   // success is true; result_1 is "two words"
auto result_2 = bp::parse(str, p);                  // !!result_2 is true; *result_2 is "two words"
\end{code}

When you call \texttt{parse()} \textbf{with} an attribute out-parameter and parser \texttt{p}, the expected type is \textbf{something like} \emph{\texttt{ATTR}}\texttt{(p)}. It doesn't have to be exactly that; I'll explain in a bit. The return type is \texttt{bool}.

When you call \texttt{parse()} \textbf{without} an attribute out-parameter and parser \texttt{p}, the return type is \texttt{std::optional<}\emph{\texttt{ATTR}}\texttt{(p)>}. Note that when \emph{\texttt{ATTR}}\texttt{(p)} is itself an \texttt{optional}, the return type is \texttt{std::optional<std::optional<...>>}. Each of those optionals tells you something different. The outer one tells you whether the parse succeeded. If so, the parser was successful, but it still generates an attribute that is an \texttt{optional} --- that's the inner one.

\subsubsection{With or without a skipper}

\begin{code}
namespace bp = boost::parser;
auto const p = '"' >> *(bp::char_ - '"') >> '"';
char const * str = "\"two words\"" ;

auto result_1 = bp::parse(str, p);         // !!result_1 is true; *result_1 is "two words"
auto result_2 = bp::parse(str, p, bp::ws); // !!result_2 is true; *result_2 is "twowords"
\end{code}

\subsubsection{Compatibility of attribute out-parameters}

For any call to \texttt{parse()} that takes an attribute out-parameter, like \texttt{parse("str", p, bp::ws, out)}, the call is well-formed for a number of possible types of \texttt{out}; \texttt{decltype(out)} does not need to be exactly \emph{\texttt{ATTR}}\texttt{(p)}.

For instance, this is well-formed code that does not abort (remember that the attribute type of \texttt{string()} is \texttt{std::string}):

\begin{code}
namespace bp = boost::parser;
auto const p = bp::string("foo");

std::vector<char> result;
bool const success = bp::parse("foo", p, result);
assert(success && result == std::vector<char>({'f', 'o', 'o'}));
\end{code}

Even though \texttt{p} generates a \texttt{std::string} attribute, when it actually takes the data it generates and writes it into an attribute, it only assumes that the attribute is a \texttt{container} (see Concepts), not that it is some particular container type. It will happily \texttt{insert()} into a \texttt{std::string} or a \texttt{std::vector<char>} all the same. \texttt{std::string} and \texttt{std::vector<char>} are both containers of \texttt{char}, but it will also insert into a container with a different element type. \texttt{p} just needs to be able to insert the elements it produces into the attribute-container. As long as an implicit conversion allows that to work, everything is fine:

\begin{code}
namespace bp = boost::parser;
auto const p = bp::string("foo");

std::deque<int> result;
bool const success = bp::parse("foo", p, result);
assert(success && result == std::deque<int>({'f', 'o', 'o'}));
\end{code}

This works, too, even though it requires inserting elements from a generated sequence of \texttt{char32\_t} into a container of \texttt{char} (remember that the attribute type of \texttt{+cp} is \texttt{std::vector<char32\_t>}):

\begin{code}
namespace bp = boost::parser;
auto const p = +bp::cp;

std::string result;
bool const success = bp::parse("foo", p, result);
assert(success && result == "foo");
\end{code}

This next example works as well, even though the change to a container is not at the top level. It is an element of the result tuple:

\begin{code}
namespace bp = boost::parser;
auto const p = +(bp::cp - ' ') >> ' ' >> string("foo");

using attr_type = decltype(bp::parse(u8"", p));
static_assert(std::is_same_v<
              attr_type,
              std::optional<bp::tuple<std::string, std::string>>>);

using namespace bp::literals;

{
    // This is similar to attr_type, with the first std::string changed to a std::vector<int>.
    bp::tuple<std::vector<int>, std::string> result;
    bool const success = bp::parse(u8"rôle foo" | bp::as_utf8, p, result);
    assert(success);
    assert(bp::get(result, 0_c) == std::vector<int>({'r', U'ô', 'l', 'e'}));
    assert(bp::get(result, 1_c) == "foo");
}
{
    // This time, we have a std::vector<char> instead of a std::vector<int>.
    bp::tuple<std::vector<char>, std::string> result;
    bool const success = bp::parse(u8"rôle foo" | bp::as_utf8, p, result);
    assert(success);
    // The 4 code points "rôle" get transcoded to 5 UTF-8 code points to fit in the std::string.
    assert(bp::get(result, 0_c) == std::vector<char>({'r', (char)0xc3, (char)0xb4, 'l', 'e'}));
    assert(bp::get(result, 1_c) == "foo");
}
\end{code}

As indicated in the inline comments, there are a couple of things to take away from this example:

\begin{itemize}
\item
  If you change an attribute out-param (such as \texttt{std::string} to \texttt{std::vector<int>}, or \texttt{std::vector<char32\_t>} to \texttt{std::deque<int>}), the call to \texttt{parse()} will often still be well-formed.
\item
  When changing out a container type, if both containers contain character values, the removed container's element type is \texttt{char32\_t} (or \texttt{wchar\_t} for non-MSVC builds), and the new container's element type is \texttt{char} or \texttt{char8\_t}, Boost.Parser assumes that this is a UTF-32-to-UTF-8 conversion, and silently transcodes the data when inserting into the new container.
\end{itemize}

Let's look at a case where another simple-seeming type replacement does \textbf{not} work. First, the case that works:

\begin{code}
namespace bp = boost::parser;
auto parser = -(bp::char_ % ',');
std::vector<int> result;
auto b = bp::parse("a, b", parser, bp::ws, result);
\end{code}

\emph{\texttt{ATTR}}\texttt{(parser)} is \texttt{std::optional<std::string>}. Even though we pass a \texttt{std::vector<int>}, everything is fine. However, if we modify this case only sightly, so that the \texttt{std::optional<std::string>} is nested within the attribute, the code becomes ill-formed.

\begin{code}
struct S
{
    std::vector<int> chars;
    int i;
};
namespace bp = boost::parser;
auto parser = -(bp::char_ % ',') >> bp::int_;
S result;
auto b = bp::parse("a, b 42", parser, bp::ws, result);
\end{code}

If we change \texttt{chars} to a \texttt{std::vector<char>}, the code is still ill-formed. Same if we change \texttt{chars} to a \texttt{std::string}. We must actually use \texttt{std::optional<std::string>} exactly to make the code well-formed again.

The reason the same looseness from the top-level parser does not apply to a nested parser is that, at some point in the code, the parser \texttt{-(bp::char\_ \% ',')} would try to assign a \texttt{std::optional<std::string>} --- the element type of the attribute type it normally generates --- to a \texttt{chars}. If there's no implicit conversion there, the code is ill-formed.

The take-away for this last example is that the ability to arbitrarily swap out data types within the type of the attribute you pass to \texttt{parse()} is very flexible, but is also limited to structurally simple cases. When we discuss \texttt{rules} in the next section, we'll see how this flexibility in the types of attributes can help when writing complicated parsers.

Those were examples of swapping out one container type for another. They make good examples because that is more likely to be surprising, and so it's getting lots of coverage here. You can also do much simpler things like parse using a \texttt{uint\_}, and writing its attribute into a \texttt{double}. In general, you can swap any type \texttt{T} out of the attribute, as long as the swap would not result in some ill-formed assignment within the parse.

Here is another example that also produces surprising results, for a different reason.

\begin{code}
namespace bp = boost::parser;
constexpr auto parser = bp::char_('a') >> bp::char_('b') >> bp::char_('c') |
                        bp::char_('x') >> bp::char_('y') >> bp::char_('z');
std::string str = "abc";
bp::tuple<char, char, char> chars;
bool b = bp::parse(str, parser, chars);
assert(b);
assert(chars == bp::tuple('c', '\0', '\0'));
\end{code}

This looks wrong, but is expected behavior. At every stage of the parse that produces an attribute, Boost.Parser tries to assign that attribute to some part of the out-param attribute provided to \texttt{parse()}, if there is one. Note that \emph{\texttt{ATTR}}\texttt{(parser)} is \texttt{std::string}, because each sequence parser is three \texttt{char\_} parsers in a row, which forms a \texttt{std::string}; there are two such alternatives, so the overall attribute is also \texttt{std::string}. During the parse, when the first parser \texttt{bp::char\_('a')} matches the input, it produces the attribute \texttt{'a'} and needs to assign it to its destination. Some logic inside the sequence parser indicates that this \texttt{'a'} contributes to the value in the \texttt{0}th position in the result tuple, if the result is being written into a tuple. Here, we passed a \texttt{bp::tuple<char, char, char>}, so it writes \texttt{'a'} into the first element. Each subsequent \texttt{char\_} parser does the same thing, and writes over the first element. If we had passed a \texttt{std::string} as the out-param instead, the logic would have seen that the out-param attribute is a string, and would have appended \texttt{'a'} to it. Then each subsequent parser would have appended to the string.

Boost.Parser never looks at the arity of the tuple passed to \texttt{parse()} to see if there are too many or too few elements in it, compared to the expected attribute for the parser. In this case, there are two extra elements that are never touched. If there had been too few elements in the tuple, you would have seen a compilation error. The reason that Boost.Parser never does this kind of type-checking up front is that the loose assignment logic is spread out among the individual parsers; the top-level parse can determine what the expected attribute is, but not whether a passed attribute of another type is a suitable stand-in.

\subsubsection{\texorpdfstring{Compatibility of \texttt{variant} attribute out-parameters}{Compatibility of variant attribute out-parameters}}

The use of a variant in an out-param is compatible if the default attribute can be assigned to the \texttt{variant}. No other work is done to make the assignment compatible. For instance, this will work as you'd expect:

\begin{code}
namespace bp = boost::parser;
std::variant<int, double> v;
auto b = bp::parse("42", bp::int_, v);
assert(b);
assert(v.index() == 0);
assert(std::get<0>(v) == 42);
\end{code}

Again, this works because \texttt{v = 42} is well-formed. However, other kinds of substitutions will not work. In particular, the \texttt{boost::parser::tuple} to aggregate or aggregate to \texttt{boost::parser::tuple} transformations will not work. Here's an example.

\begin{code}
struct key_value
{
    int key;
    double value;
};

namespace bp = boost::parser;
std::variant<key_value, double> kv_or_d;
key_value kv;
bp::parse("42 13.0", bp::int_ >> bp::double_, kv);      // Ok.
bp::parse("42 13.0", bp::int_ >> bp::double_, kv_or_d); // Error: ill-formed!
\end{code}

In this case, it would be easy for Boost.Parser to look at the alternative types covered by the variant, and do a conversion. However, there are many cases in which there is no obviously correct variant alternative type, or in which the user might expect one variant alternative type and get another. Consider a couple of cases.

\begin{code}
struct i_d { int i; double d; };
struct d_i { double d; int i; };
using v1 = std::variant<i_d, d_i>;

struct i_s { int i; short s; };
struct d_d { double d1; double d2; };
using v2 = std::variant<i_s, d_d>;

using tup_t = boost::parser::tuple<short, short>;
\end{code}

If we have a parser that produces a \texttt{tup\_t}, and we have a \texttt{v1} attribute out-param, the correct variant alternative type clearly does not exist --- this case is ambiguous, and anyone can see that neither variant alternative is a better match. If we were assigning a \texttt{tup\_t} to \texttt{v2}, it's even worse. The same ambiguity exists, but to the user, \texttt{i\_s} is clearly "closer" than \texttt{d\_d}.

So, Boost.Parser only does assignment. If some parser \texttt{P} generates a default attribute that is not assignable to a variant alternative that you want to assign it to, you can just create a \texttt{rule} that creates either an exact variant alternative type, or the variant itself, and use \texttt{P} as your rule's parser.

\subsubsection{Unicode versus non-Unicode parsing}

A call to \texttt{parse()} either considers the entire input to be in a UTF format (UTF-8, UTF-16, or UTF-32), or it considers the entire input to be in some unknown encoding. Here is how it deduces which case the call falls under:

\begin{itemize}
\item
  If the range is a sequence of \texttt{char8\_t}, or if the input is a \texttt{boost::parser::utf8\_view}, the input is UTF-8.
\item
  Otherwise, if the value type of the range is \texttt{char}, the input is in an unknown encoding.
\item
  Otherwise, the input is in a UTF encoding.
\end{itemize}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Tip \\
if you want to want to parse in ASCII-only mode, or in some other non-Unicode encoding, use only sequences of \texttt{char}, like \texttt{std::string} or \texttt{char const *}. & \\
\end{longtable}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Tip \\
If you want to ensure all input is parsed as Unicode, pass the input range \texttt{r} as \texttt{r | boost::parser::as\_utf32} --- that's the first thing that happens to it inside \texttt{parse()} in the Unicode parsing path anyway. & \\
\end{longtable}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Note \\
Since passing \texttt{boost::parser::utfN\_view} is a special case, and since a sequence of \texttt{char}s \texttt{r} is otherwise considered an unknown encoding, \texttt{boost::parser::parse(r | boost::parser::as\_utf8, p)} treats \texttt{r} as UTF-8, whereas \texttt{boost::parser::parse(r, p)} does not. & \\
\end{longtable}

\subsubsection{\texorpdfstring{The \texttt{trace\_mode} parameter to parse()}{The trace\_mode parameter to parse()}}

Debugging parsers is notoriously difficult once they reach a certain size. To get a verbose trace of your parse, pass \texttt{boost::parser::trace::on} as the final parameter to \texttt{parse()}. It will show you the current parser being matched, the next few characters to be parsed, and any attributes generated. See the Error Handling and Debugging section of the tutorial for details.

\subsubsection{Globals and error handlers}

Each call to \texttt{parse()} can optionally have a globals object associated with it. To use a particular globals object with you parser, you call \texttt{with\_globals()} to create a new parser with the globals object in it:

\begin{code}
struct globals_t
{
    int foo;
    std::string bar;
};
auto const parser = /* ... */;
globals_t globals{42, "yay"};
auto result = boost::parser::parse("str", boost::parser::with_globals(parser, globals));
\end{code}

Every semantic action within that call to \texttt{parse()} can access the same \texttt{globals\_t} object using \texttt{\_globals(ctx)}.

The default error handler is great for most needs, but if you want to change it, you can do so by creating a new parser with a call to \texttt{with\_error\_handler()}:

\begin{code}
auto const parser = /* ... */;
my_error_handler error_handler;
auto result = boost::parser::parse("str", boost::parser::with_error_handler(parser, error_handler));
\end{code}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Tip \\
If your parsing environment does not allow you to report errors to a terminal, you may want to use \texttt{callback\_error\_handler} instead of the default error handler. & \\
\end{longtable}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Important \\
Globals and the error handler are ignored, if present, on any parser except the top-level parser. & \\
\end{longtable}

\subsection{More About Rules}

In the earlier page about \texttt{rules} (Rule Parsers), I described \texttt{rules} as being analogous to functions. \texttt{rules} are, at base, organizational. Here are the common use cases for \texttt{rules}. Use a \texttt{rule} if you want to:

\begin{itemize}
\item
  fix the attribute type produced by a parser to something other than the default;
\item
  create a parser that produces useful diagnostic text;
\item
  create a recursive rule (more on this below);
\item
  create a set of mutually-recursive parsers;
\item
  do callback parsing.
\end{itemize}

Let's look at the use cases in detail.

\subsubsection{Fixing the attribute type}

We saw in the previous section how \texttt{parse()} is flexible in what types it will accept as attribute out-parameters. Here's another example.

\begin{code}
namespace bp = boost::parser;
auto result = bp::parse(input, bp::int % ',', result);
\end{code}

\texttt{result} can be one of many different types. It could be \texttt{std::vector<int>}. It could be \texttt{std::set<long long>}. It could be a lot of things. Often, this is a very useful property; if you had to rewrite all of your parser logic because you changed the desired container in some part of your attribute from a \texttt{std::vector} to a \texttt{std::deque}, that would be annoying. However, that flexibility comes at the cost of type checking. If you want to write a parser that \textbf{always} produces exactly a \texttt{std::vector<unsigned int>} \textbf{and no other type}, you also probably want a compilation error if you accidentally pass that parser a \texttt{std::set<unsigned int>} attribute instead. There is no way with a plain parser to enforce that its attribute type may only ever be a single, fixed type.

Fortunately, \texttt{rules} allow you to write a parser that has a fixed attribute type. Every rule has a specific attribute type, provided as a template parameter. If one is not specified, the rule has no attribute. The fact that the attribute is a specific type allows you to remove attribute flexibility. For instance, say we have a rule defined like this:

\begin{code}
bp::rule<struct doubles, std::vector<double>> doubles = "doubles";
auto const doubles_def = bp::double_ % ',';
BOOST_PARSER_DEFINE_RULES(doubles);
\end{code}

You can then use it in a call to \texttt{parse()}, and \texttt{parse()} will return a \texttt{std::optional<std::vector<double>>}:

\begin{code}
auto const result = bp::parse(input, doubles, bp::ws);
\end{code}

If you call \texttt{parse()} with an attribute out-parameter, it must be exactly \texttt{std::vector<double>}:

\begin{code}
std::vector<double> vec_result;
bp::parse(input, doubles, bp::ws, vec_result); // Ok.
std::deque<double> deque_result;
bp::parse(input, doubles, bp::ws, deque_result); // Ill-formed!
\end{code}

If we wanted to use a \texttt{std::deque<double>} as the attribute type of our rule:

\begin{code}
// Attribute changed to std::deque<double>.
bp::rule<struct doubles, std::deque<double>> doubles = "doubles";
auto const doubles_def = bp::double_ % ',';
BOOST_PARSER_DEFINE_RULES(doubles);

int main()
{
    std::deque<double> deque_result;
    bp::parse(input, doubles, bp::ws, deque_result); // Ok.
}
\end{code}

The take-away here is that the attribute flexibility is still available, but only \textbf{within} the rule --- the parser \texttt{bp::double\_ \% ','} can parse into a \texttt{std::vector<double>} or a \texttt{std::deque<double>}, but the rule \texttt{doubles} must parse into only the exact attribute it was declared to generate.

The reason for this is that, inside the rule parsing implementation, there is code something like this:

\begin{code}
using attr_t = ATTR(doubles_def);
attr_t attr;
parse(first, last, parser, attr);
attribute_out_param = std::move(attr);
\end{code}

Where \texttt{attribute\_out\_param} is the attribute out-parameter we pass to \texttt{parse()}. If that final move assignment is ill-formed, the call to \texttt{parse()} is too.

You can also use rules to exploit attribute flexibility. Even though a rule reduces the flexibility of attributes it can generate, the fact that it is so easy to write a new rule means that we can use rules themselves to get the attribute flexibility we want across our code:

\begin{code}
namespace bp = boost::parser;

// We only need to write the definition once...
auto const generic_doubles_def = bp::double_ % ',';

bp::rule<struct vec_doubles, std::vector<double>> vec_doubles = "vec_doubles";
auto const & vec_doubles_def = generic_doubles_def; // ... and re-use it,
BOOST_PARSER_DEFINE_RULES(vec_doubles);

// Attribute changed to std::deque<double>.
bp::rule<struct deque_doubles, std::deque<double>> deque_doubles = "deque_doubles";
auto const & deque_doubles_def = generic_doubles_def; // ... and re-use it again.
BOOST_PARSER_DEFINE_RULES(deque_doubles);
\end{code}

Now we have one of each, and we did not have to copy any parsing logic that would have to be maintained in two places.

Sometimes, you need to create a rule to enforce a certain attribute type, but the rule's attribute is not constructible from its parser's attribute. When that happens, you'll need to write a semantic action.

\begin{code}
struct type_t
{
    type_t() = default;
    explicit type_t(double x) : x_(x) {}
    // etc.

    double x_;
};

namespace bp = boost::parser;

auto doubles_to_type = [](auto & ctx) {
    using namespace bp::literals;
    _val(ctx) = type_t(_attr(ctx)[0_c] * _attr(ctx)[1_c]);
};

bp::rule<struct type_tag, type_t> type = "type";
auto const type_def = (bp::double_ >> bp::double_)[doubles_to_type];
BOOST_PARSER_DEFINE_RULES(type);
\end{code}

For a rule \texttt{R} and its parser \texttt{P}, we do not need to write such a semantic action if:

- \emph{\texttt{ATTR}}\texttt{(R)} is an aggregate, and \emph{\texttt{ATTR}}\texttt{(P)} is a compatible tuple;

- \emph{\texttt{ATTR}}\texttt{(R)} is a tuple, and \emph{\texttt{ATTR}}\texttt{(P)} is a compatible aggregate;

- \emph{\texttt{ATTR}}\texttt{(R)} is a non-aggregate class type \texttt{C}, and \emph{\texttt{ATTR}}\texttt{(P)} is a tuple whose elements can be used to construct \texttt{C}; or

- \emph{\texttt{ATTR}}\texttt{(R)} and \emph{\texttt{ATTR}}\texttt{(P)} are compatible types.

The notion of "compatible" is defined in The \texttt{parse()} API.

\subsubsection{Creating a parser for better diagnostics}

Each \texttt{rule} has associated diagnostic text that Boost.Parser can use for failures of that rule. This is useful when the parse reaches a parse failure at an expectation point (see Expectation points). Let's say you have the following code defined somewhere.

\begin{code}
namespace bp = boost::parser;

bp::rule<struct value_tag> value =
    "an integer, or a list of integers in braces";

auto const ints = '{' > (value % ',') > '}';
auto const value_def = bp::int_ | ints;

BOOST_PARSER_DEFINE_RULES(value);
\end{code}

Notice the two expectation points. One before \texttt{(value \% ',')}, one before the final \texttt{'\}'}. Later, you call parse in some input:

\begin{code}
bp::parse("{ 4, 5 a", value, bp::ws);
\end{code}

This runs should of the second expectation point, and produces output like this:

\begin{code}
1:7: error: Expected '}' here:
{ 4, 5 a
       ^
\end{code}

That's a pretty good error message. Here's what it looks like if we violate the earlier expectation:

\begin{code}
bp::parse("{ }", value, bp::ws);
\end{code}

\begin{code}
1:2: error: Expected an integer, or a list of integers in braces % ',' here:
{ }
  ^
\end{code}

Not nearly as nice. The problem is that the expectation is on \texttt{(value \% ',')}. So, even thought we gave \texttt{value} reasonable dianostic text, we put the text on the wrong thing. We can introduce a new rule to put the diagnstic text in the right place.

\begin{code}
namespace bp = boost::parser;

bp::rule<struct value_tag> value =
    "an integer, or a list of integers in braces";
bp::rule<struct comma_values_tag> comma_values =
    "a comma-delimited list of integers";

auto const ints = '{' > comma_values > '}';
auto const value_def = bp::int_ | ints;
auto const comma_values_def = (value % ',');

BOOST_PARSER_DEFINE_RULES(value, comma_values);
\end{code}

Now when we call \texttt{bp::parse("\{ \}", value, bp::ws)} we get a much better message:

\begin{code}
1:2: error: Expected a comma-delimited list of integers here:
{ }
  ^
\end{code}

The \texttt{rule} \texttt{value} might be useful elsewhere in our code, perhaps in another parser. It's diagnostic text is appropriate for those other potential uses.

\subsubsection{Recursive rules}

It's pretty common to see grammars that include recursive rules. Consider this EBNF rule for balanced parentheses:

\begin{code}
<parens> ::= "" | ( "(" <parens> ")" )
\end{code}

We can try to write this using Boost.Parser like this:

\begin{code}
namespace bp = boost::parser;
auto const parens = '(' >> parens >> ')' | bp::eps;
\end{code}

We had to put the \texttt{bp::eps} second, because Boost.Parser's parsing algorithm is greedy. Otherwise, it's just a straight transliteration. Unfortunately, it does not work. The code is ill-formed because you can't define a variable in terms of itself. Well you can, but nothing good comes of it. If we instead make the parser in terms of a forward-declared \texttt{rule}, it works.

\begin{code}
namespace bp = boost::parser;
bp::rule<struct parens_tag> parens = "matched parentheses";
auto const parens_def = '(' >> parens > ')' | bp::eps;
BOOST_PARSER_DEFINE_RULES(parens);
\end{code}

Later, if we use it to parse, it does what we want.

\begin{code}
assert(bp::parse("(((())))", parens, bp::ws));
\end{code}

When it fails, it even produces nice diagnostics.

\begin{code}
bp::parse("(((()))", parens, bp::ws);
\end{code}

\begin{code}
1:7: error: Expected ')' here (end of input):
(((()))
       ^
\end{code}

Recursive \texttt{rules} work differently from other parsers in one way: when re-entering the rule recursively, only the attribute variable (\texttt{\_attr(ctx)} in your semantic actions) is unique to that instance of the rule. All the other state of the uppermost instance of that rule is shared. This includes the value of the rule (\texttt{\_val(ctx)}), and the locals and parameters to the rule. In other words, \texttt{\_val(ctx)} returns a reference to the \textbf{same object} in every instance of a recursive \texttt{rule}. This is because each instance of the rule needs a place to put the attribute it generates from its parse. However, we only want a single return value for the uppermost rule; if each instance had a separate value in \texttt{\_val(ctx)}, then it would be impossible to build up the result of a recursive rule step by step during in the evaluation of the recursive instantiations.

Also, consider this rule:

\begin{code}
namespace bp = boost::parser;
bp::rule<struct ints_tag, std::vector<int>> ints = "ints";
auto const ints_def = bp::int_ >> ints | bp::eps;
\end{code}

What is the default attribute type for ints\_def? It sure looks like \texttt{std::optional<std::vector<int>>}. Inside the evaluation of \texttt{ints}, Boost.Parser must evaluate \texttt{ints\_def}, and then produce a \texttt{std::vector<int>} --- the return type of \texttt{ints} --- from it. How? How do you turn a \texttt{std::optional<std::vector<int>>} into a \texttt{std::vector<int>}? To a human, it seems obvious, but the metaprogramming that properly handles this simple example and the general case is certainly beyond me.

Boost.Parser has a specific semantic for what consitutes a recursive rule. Each rule has a tag type associated with it, and if Boost.Parser enters a rule with a certain tag \texttt{Tag}, and the currently-evaluating rule (if there is one) also has the tag \texttt{Tag}, then rule instance being entered is considered to be a recursion. No other situations are considered recursion. In particular, if you have rules \texttt{Ra} and \texttt{Rb}, and \texttt{Ra} uses \texttt{Rb}, which in turn used \texttt{Ra}, the second use of \texttt{Ra} is not considered recursion. \texttt{Ra} and \texttt{Rb} are of course mutually recursive, but neither is considered a "recursive rule" for purposes of getting a unique value, locals, and parameters.

\subsubsection{Mutually-recursive rules}

One of the advantages of using rules is that you can declare all your rules up front and then use them immediately afterward. This lets you make rules that use each other without introducing cycles:

\begin{code}
namespace bp = boost::parser;

// Assume we have some polymorphic type that can be an object/dictionary,
// array, string, or int, called `value_type`.

bp::rule<class string, std::string> const string = "string";
bp::rule<class object_element, bp::tuple<std::string, value_type>> const object_element = "object-element";
bp::rule<class object, value_type> const object = "object";
bp::rule<class array, value_type> const array = "array";
bp::rule<class value_tag, value_type> const value = "value";

auto const string_def = bp::lexeme['"' >> *(bp::char_ - '"') > '"'];
auto const object_element_def = string > ':' > value;
auto const object_def = '{'_l >> -(object_element % ',') > '}';
auto const array_def = '['_l >> -(value % ',') > ']';
auto const value_def = bp::int_ | bp::bool_ | string | array | object;

BOOST_PARSER_DEFINE_RULES(string, object_element, object, array, value);
\end{code}

Here we have a parser for a Javascript-value-like type \texttt{value\_type}. \texttt{value\_type} may be an array, which itself may contain other arrays, objects, strings, etc. Since we need to be able to parse objects within arrays and vice versa, we need each of those two parsers to be able to refer to each other.

\subsubsection{Callback parsing}

Only \texttt{rules} can be callback parsers, so if you want to get attributes supplied to you via callbacks instead of somewhere in the middle of a giant attribute that represents the whole parse result, you need to use \texttt{rules}. See Parsing JSON With Callbacks for an extended example of callback parsing.

\subsubsection{Accessors available in semantic actions on rules}

\subsubsection{\_val()}

Inside all of a rule's semantic actions, the expression \texttt{\_val(ctx)} is a reference to the attribute that the rule generates. This can be useful when you want subparsers to build up the attribute in a specific way:

\begin{code}
namespace bp = boost::parser;
using namespace bp::literals;

bp::rule<class ints, std::vector<int>> const ints = "ints";
auto twenty_zeros = [](auto & ctx) { _val(ctx).resize(20, 0); };
auto push_back = [](auto & ctx) { _val(ctx).push_back(_attr(ctx)); };
auto const ints_def = "20-zeros"_l[twenty_zeros] | +bp::int_[push_back];
BOOST_PARSER_DEFINE_RULES(ints);
\end{code}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Tip \\
That's just an example. It's almost always better to do things without using semantic actions. We could have instead written \texttt{ints\_def} as \texttt{"20-zeros" >> bp::attr(std::vector<int>(20)) | +bp::int\_}, which has the same semantics, is a lot easier to read, and is a lot less code. & \\
\end{longtable}

\subsubsection{Locals}

The \texttt{rule} template takes another template parameter we have not discussed yet. You can pass a third parameter \texttt{LocalState} to \texttt{rule}, which will be defaulted csontructed by the \texttt{rule}, and made available within semantic actions used in the rule as \texttt{\_locals(ctx)}. This gives your rule some local state, if it needs it. The type of \texttt{LocalState} can be anything regular. It could be a single value, a struct containing multiple values, or a tuple, among others.

\begin{code}
struct foo_locals
{
    char first_value = 0;
};

namespace bp = boost::parser;

bp::rule<class foo, int, foo_locals> const foo = "foo";

auto record_first = [](auto & ctx) { _locals(ctx).first_value = _attr(ctx); }
auto check_against_first = [](auto & ctx) {
    char const first = _locals(ctx).first_value;
    char const attr = _attr(ctx);
    if (attr == first)
        _pass(ctx) = false;
    _val(ctx) = (int(first) << 8) | int(attr);
};

auto const foo_def = bp::cu[record_first] >> bp::cu[check_against_first];
BOOST_PARSER_DEFINE_RULES(foo);
\end{code}

\texttt{foo} matches the input if it can match two elements of the input in a row, but only if they are not the same value. Without locals, it's a lot harder to write parsers that have to track state as they parse.

\subsubsection{Parameters}

Sometimes, it is convenient to parameterize parsers. Consider these parsing rules from the YAML 1.2 spec:

\begin{code}
[80]
s-separate(n,BLOCK-OUT) ::= s-separate-lines(n)
s-separate(n,BLOCK-IN)  ::= s-separate-lines(n)
s-separate(n,FLOW-OUT)  ::= s-separate-lines(n)
s-separate(n,FLOW-IN)   ::= s-separate-lines(n)
s-separate(n,BLOCK-KEY) ::= s-separate-in-line
s-separate(n,FLOW-KEY)  ::= s-separate-in-line

[136]
in-flow(n,FLOW-OUT)  ::= ns-s-flow-seq-entries(n,FLOW-IN)
in-flow(n,FLOW-IN)   ::= ns-s-flow-seq-entries(n,FLOW-IN)
in-flow(n,BLOCK-KEY) ::= ns-s-flow-seq-entries(n,FLOW-KEY)
in-flow(n,FLOW-KEY)  ::= ns-s-flow-seq-entries(n,FLOW-KEY)

[137]
c-flow-sequence(n,c) ::= “[” s-separate(n,c)? in-flow(c)? “]”
\end{code}

YAML {[}137{]} says that the parsing should proceed into two YAML subrules, both of which have these \texttt{n} and \texttt{c} parameters. It is certainly possible to transliterate these YAML parsing rules to something that uses unparameterized Boost.Parser \texttt{rules}, but it is quite painful to do so. It is better to use a parameterized rule.

You give parameters to a \texttt{rule} by calling its \texttt{with()} member. The values you pass to \texttt{with()} are used to create a \texttt{boost::parser::tuple} that is available in semantic actions attached to the rule, using \texttt{\_params(ctx)}.

Passing parameters to \texttt{rules} like this allows you to easily write parsers that change the way they parse depending on contextual data that they have already parsed.

Here is an implementation of YAML {[}137{]}. It also implements the two YAML rules used directly by {[}137{]}, rules {[}136{]} and {[}80{]}. The rules that \textbf{those} rules use are also represented below, but are implemented using only \texttt{eps}, so that I don't have to repeat too much of the (very large) YAML spec.

\begin{code}
namespace bp = boost::parser;

// A type to represent the YAML parse context.
enum class context {
    block_in,
    block_out,
    block_key,
    flow_in,
    flow_out,
    flow_key
};

// A YAML value; no need to fill it in for this example.
struct value
{
    // ...
};

// YAML [66], just stubbed in here.
auto const s_separate_in_line = bp::eps;

// YAML [137].
bp::rule<struct c_flow_seq_tag, value> c_flow_sequence = "c-flow-sequence";
// YAML [80].
bp::rule<struct s_separate_tag> s_separate = "s-separate";
// YAML [136].
bp::rule<struct in_flow_tag, value> in_flow = "in-flow";
// YAML [138]; just eps below.
bp::rule<struct ns_s_flow_seq_entries_tag, value> ns_s_flow_seq_entries =
    "ns-s-flow-seq-entries";
// YAML [81]; just eps below.
bp::rule<struct s_separate_lines_tag> s_separate_lines = "s-separate-lines";

// Parser for YAML [137].
auto const c_flow_sequence_def =
    '[' >>
    -s_separate.with(bp::_p<0>, bp::_p<1>) >>
    -in_flow.with(bp::_p<0>, bp::_p<1>) >>
    ']';
// Parser for YAML [80].
auto const s_separate_def = bp::switch_(bp::_p<1>)
    (context::block_out, s_separate_lines.with(bp::_p<0>))
    (context::block_in, s_separate_lines.with(bp::_p<0>))
    (context::flow_out, s_separate_lines.with(bp::_p<0>))
    (context::flow_in, s_separate_lines.with(bp::_p<0>))
    (context::block_key, s_separate_in_line)
    (context::flow_key, s_separate_in_line);
// Parser for YAML [136].
auto const in_flow_def = bp::switch_(bp::_p<1>)
    (context::flow_out, ns_s_flow_seq_entries.with(bp::_p<0>, context::flow_in))
    (context::flow_in, ns_s_flow_seq_entries.with(bp::_p<0>, context::flow_in))
    (context::block_out, ns_s_flow_seq_entries.with(bp::_p<0>, context::flow_key))
    (context::flow_key, ns_s_flow_seq_entries.with(bp::_p<0>, context::flow_key));

auto const ns_s_flow_seq_entries_def = bp::eps;
auto const s_separate_lines_def = bp::eps;

BOOST_PARSER_DEFINE_RULES(
    c_flow_sequence,
    s_separate,
    in_flow,
    ns_s_flow_seq_entries,
    s_separate_lines);
\end{code}

YAML {[}137{]} (\texttt{c\_flow\_sequence}) parses a list. The list may be empty, and must be surrounded by brackets, as you see here. But, depending on the current YAML context (the \texttt{c} parameter to {[}137{]}), we may require certain spacing to be matched by \texttt{s-separate}, and how sub-parser \texttt{in-flow} behaves also depends on the current context.

In \texttt{s\_separate} above, we parse differently based on the value of \texttt{c}. This is done above by using the value of the second parameter to \texttt{s\_separate} in a switch-parser. The second parameter is looked up by using \texttt{\_p} as a parse argument.

\texttt{in\_flow} does something similar. Note that \texttt{in\_flow} calls its subrule by passing its first parameter, but using a fixed value for the second value. \texttt{s\_separate} only passes its \texttt{n} parameter conditionally. The point is that a rule can be used with and without \texttt{.with()}, and that you can pass constants or parse arguments to \texttt{.with()}.

With those rules defined, we could write a unit test for YAML {[}137{]} like this:

\begin{code}
auto const test_parser = c_flow_sequence.with(4, context::block_out);
auto result = bp::parse("[]", test_parser);
assert(result);
\end{code}

You could extend this with tests for different values of \texttt{n} and \texttt{c}. Obviously, in real tests, you parse actual contents inside the \texttt{"{[}{]}"}, if the other rules were implemented, like {[}138{]}.

\subsubsection{The \_p variable template}

Getting at one of a rule's arguments and passing it as an argument to another parser can be very verbose. \texttt{\_p} is a variable template that allows you to refer to the \texttt{n}th argument to the current rule, so that you can, in turn, pass it to one of the rule's subparsers. Using this, \texttt{foo\_def} above can be rewritten as:

\begin{code}
auto const foo_def = bp::repeat(bp::_p<0>)[' '_l];
\end{code}

Using \texttt{\_p} can prevent you from having to write a bunch of lambdas that get each get an argument out of the parse context using \texttt{\_params(ctx){[}0\_c{]}} or similar.

Note that \texttt{\_p} is a parse argument (see The Parsers And Their Uses), meaning that it is an invocable that takes the context as its only parameter. If you want to use it inside a semantic action, you have to call it.

\subsubsection{Special forms of semantic actions usable within a rule}

Semantic actions in this tutorial are usually of the signature \texttt{void (auto \& ctx)}. That is, they take a context by reference, and return nothing. If they were to return something, that something would just get dropped on the floor.

It is a pretty common pattern to create a rule in order to get a certain kind of value out of a parser, when you don't normally get it automatically. If I want to parse an \texttt{int}, \texttt{int\_} does that, and the thing that I parsed is also the desired attribute. If I parse an \texttt{int} followed by a \texttt{double}, I get a \texttt{boost::parser::tuple} containing one of each. But what if I don't want those two values, but some function of those two values? I probably write something like this.

\begin{code}
struct obj_t { /* ... */ };
obj_t to_obj(int i, double d) { /* ... */ }

namespace bp = boost::parser;
bp::rule<struct obj_tag, obj_t> obj = "obj";
auto make_obj = [](auto & ctx) {
    using boost::hana::literals;
    _val(ctx) = to_obj(_attr(ctx)[0_c], _attr(ctx)[1_c]);
};
constexpr auto obj_def = (bp::int_ >> bp::double_)[make_obj];
\end{code}

That's fine, if a little verbose. However, you can also do this instead:

\begin{code}
namespace bp = boost::parser;
bp::rule<struct obj_tag, obj_t> obj = "obj";
auto make_obj = [](auto & ctx) {
    using boost::hana::literals;
    return to_obj(_attr(ctx)[0_c], _attr(ctx)[1_c]);
};
constexpr auto obj_def = (bp::int_ >> bp::double_)[make_obj];
\end{code}

Above, we return the value from a semantic action, and the returned value gets assigned to \texttt{\_val(ctx)}.

Finally, you can provide a function that takes the individual elements of the attribute (if it's a tuple), and returns the value to assign to \texttt{\_val(ctx)}:

\begin{code}
namespace bp = boost::parser;
bp::rule<struct obj_tag, obj_t> obj = "obj";
constexpr auto obj_def = (bp::int_ >> bp::double_)[to_obj];
\end{code}

More formally, within a rule, the use of a semantic action is determined as follows. Assume we have a function \texttt{APPLY} that calls a function with the elements of a tuple, like \texttt{std::apply}. For some context \texttt{ctx}, semantic action \texttt{action}, and attribute \texttt{attr}, \texttt{action} is used like this:

- \texttt{\_val(ctx) = APPLY(action, std::move(attr))}, if that is well-formed, and \texttt{attr} is a tuple of size 2 or larger;

- otherwise, \texttt{\_val(ctx) = action(ctx)}, if that is well-formed;

- otherwise, \texttt{action(ctx)}.

The first case does not pass the context to the action at all. The last case is the normal use of semantic actions outside of rules.

\subsection{Algorithms and Views That Use Parsers}

Unless otherwise noted, all the algorithms and views are constrained very much like the way the \texttt{parse()} overloads are. The kinds of ranges, parsers, etc., that they accept are the same.

\phantomsection\label{tutorial_split_005.html}{}

\subsubsection{boost::parser::search()}

As shown in The \texttt{parse()} API, the two patterns of parsing in Boost.Parser are whole-parse and prefix-parse. When you want to find something in the middle of the range being parsed, there's no \texttt{parse} API for that. You can of course make a simple parser that skips everything before what you're looking for.

\begin{code}
namespace bp = boost::parser;
constexpr auto parser = /* ... */;
constexpr auto middle_parser = bp::omit[*(bp::char_ - parser)] >> parser;
\end{code}

\texttt{middle\_parser} will skip over everything, one \texttt{char\_} at a time, as long as the next \texttt{char\_} is not the beginning of a successful match of \texttt{parser}. After this, control passes to \texttt{parser} itself. Ok, so that's not too hard to write. If you need to parse something from the middle in order to generate attributes, this is what you should use.

However, it often turns out you only need to find some subrange in the parsed range. In these cases, it would be nice to turn this into a proper algorithm in the pattern of the ones in \texttt{std::ranges}, since that's more idiomatic. \texttt{boost::parser::search()} is that algorithm. It has very similar semantics to \texttt{std::ranges::search}, except that it searches not for a match to an exact subrange, but to a match with the given parser. Like \texttt{std::ranges::search()}, it returns a subrange (\texttt{boost::parser::subrange} in C++17, \texttt{std::ranges::subrange} in C++20 and later).

\begin{code}
namespace bp = boost::parser;
auto result = bp::search("aaXYZq", bp::lit("XYZ"), bp::ws);
assert(!result.empty());
assert(std::string_view(result.begin(), result.end() - result.begin()) == "XYZ");
\end{code}

Since \texttt{boost::parser::search()} returns a subrange, whatever parser you give it produces no attribute. I wrote \texttt{bp::lit("XYZ")} above; if I had written \texttt{bp::string("XYZ")} instead, the result (and lack of \texttt{std::string} construction) would not change.

As you can see above, one aspect of \texttt{boost::parser::search()} differs intentionally from the conventions of the \texttt{std::ranges} algorithms --- it accepts C-style strings, treating them as if they were proper ranges.

Also, \texttt{boost::parser::search()} knows how to accommodate your iterator type. You can pass the C-style string \texttt{"aaXYZq"} as in the example above, or \texttt{"aaXYZq" | bp::as\_utf32}, or \texttt{"aaXYZq" | bp::as\_utf8}, or even \texttt{"aaXYZq" | bp::as\_utf16}, and it will return a subrange whose iterators are the type that you passed as input, even though internally the iterator type might be something different (a UTF-8 -> UTF-32 transcoding iterator in Unicode parsing, as with all the \texttt{| bp::as\_utfN} examples above). As long as you pass a range to be parsed whose value type is \texttt{char}, \texttt{char8\_t}, \texttt{char32\_t}, or that is adapted using some combination of \texttt{as\_utfN} adaptors, this accommodation will operate correctly.

\texttt{boost::parser::search()} has multiple overloads. You can pass a range or an iterator/sentinel pair, and you can pass a skip parser or not. That's four overloads. Also, all four overloads take an optional \texttt{boost::parser::trace} parameter at the end. This is really handy for investigating why you're not finding something in the input that you expected to.

\subsubsection{boost::parser::search\_all}

\texttt{boost::parser::search\_all} creates \texttt{boost::parser::search\_all\_views}. \texttt{boost::parser::search\_all\_view} is a \texttt{std::views}-style view. It produces a range of subranges. Each subrange it produces is the next match of the given parser in the parsed range.

\begin{code}
namespace bp = boost::parser;
auto r = "XYZaaXYZbaabaXYZXYZ" | bp::search_all(bp::lit("XYZ"));
int count = 0;
// Prints XYZ XYZ XYZ XYZ.
for (auto subrange : r) {
    std::cout << std::string_view(subrange.begin(), subrange.end() - subrange.begin()) << " ";
    ++count;
}
std::cout << "\n";
assert(count == 4);
\end{code}

All the details called out in the subsection on \texttt{boost::parser::search()} above apply to \texttt{boost::parser::search\_all}: its parser produces no attributes; it accepts C-style strings as if they were ranges; and it knows how to get from the internally-used iterator type back to the given iterator type, in typical cases.

\texttt{boost::parser::search\_all} can be called with, and \texttt{boost::parser::search\_all\_view} can be constructed with, a skip parser or not, and you can always pass \texttt{boost::parser::trace} at the end of any of their overloads.

\subsubsection{boost::parser::split}

\texttt{boost::parser::split} creates \texttt{boost::parser::split\_views}. \texttt{boost::parser::split\_view} is a \texttt{std::views}-style view. It produces a range of subranges of the parsed range split on matches of the given parser. You can think of \texttt{boost::parser::split\_view} as being the complement of \texttt{boost::parser::search\_all\_view}, in that \texttt{boost::parser::split\_view} produces the subranges between the subranges produced by \texttt{boost::parser::search\_all\_view}. \texttt{boost::parser::split\_view} has very similar semantics to \texttt{std::views::split\_view}. Just like \texttt{std::views::split\_view}, \texttt{boost::parser::split\_view} will produce empty ranges between the beginning/end of the parsed range and an adjacent match, or between adjacent matches.

\begin{code}
namespace bp = boost::parser;
auto r = "XYZaaXYZbaabaXYZXYZ" | bp::split(bp::lit("XYZ"));
int count = 0;
// Prints '' 'aa' 'baaba' '' ''.
for (auto subrange : r) {
    std::cout << "'" << std::string_view(subrange.begin(), subrange.end() - subrange.begin()) << "' ";
    ++count;
}
std::cout << "\n";
assert(count == 5);
\end{code}

All the details called out in the subsection on \texttt{boost::parser::search()} above apply to \texttt{boost::parser::split}: its parser produces no attributes; it accepts C-style strings as if they were ranges; and it knows how to get from the internally-used iterator type back to the given iterator type, in typical cases.

\texttt{boost::parser::split} can be called with, and \texttt{boost::parser::split\_view} can be constructed with, a skip parser or not, and you can always pass \texttt{boost::parser::trace} at the end of any of their overloads.

\subsubsection{boost::parser::replace}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Important \\
\texttt{boost::parser::replace} and \texttt{boost::parser::replace\_view} are not available on MSVC in C++17 mode. & \\
\end{longtable}

\texttt{boost::parser::replace} creates \texttt{boost::parser::replace\_views}. \texttt{boost::parser::replace\_view} is a \texttt{std::views}-style view. It produces a range of subranges from the parsed range \texttt{r} and the given replacement range \texttt{replacement}. Wherever in the parsed range a match to the given parser \texttt{parser} is found, \texttt{replacement} is the subrange produced. Each subrange of \texttt{r} that does not match \texttt{parser} is produced as a subrange as well. The subranges are produced in the order in which they occur in \texttt{r}. Unlike \texttt{boost::parser::split\_view}, \texttt{boost::parser::replace\_view} does not produce empty subranges, unless \texttt{replacement} is empty.

\begin{code}
namespace bp = boost::parser;
auto card_number = bp::int_ >> bp::repeat(3)['-' >> bp::int_];
auto rng = "My credit card number is 1234-5678-9012-3456." | bp::replace(card_number, "XXXX-XXXX-XXXX-XXXX");
int count = 0;
// Prints My credit card number is XXXX-XXXX-XXXX-XXXX.
for (auto subrange : rng) {
    std::cout << std::string_view(subrange.begin(), subrange.end() - subrange.begin());
    ++count;
}
std::cout << "\n";
assert(count == 3);
\end{code}

If the iterator types \texttt{Ir} and \texttt{Ireplacement} for the \texttt{r} and \texttt{replacement} ranges passed are identical (as in the example above), the iterator type for the subranges produced is \texttt{Ir}. If they are different, an implementation-defined type is used for the iterator. This type is the moral equivalent of a \texttt{std::variant<Ir, Ireplacement>}. This works as long as \texttt{Ir} and \texttt{Ireplacement} are compatible. To be compatible, they must have common reference, value, and rvalue reference types, as determined by \texttt{std::common\_type\_t}. One advantage to this scheme is that the range of subranges represented by \texttt{boost::parser::replace\_view} is easily joined back into a single range.

\begin{code}
namespace bp = boost::parser;
auto card_number = bp::int_ >> bp::repeat(3)['-' >> bp::int_];
auto rng = "My credit card number is 1234-5678-9012-3456." | bp::replace(card_number, "XXXX-XXXX-XXXX-XXXX") | std::views::join;
std::string replace_result;
for (auto ch : rng) {
    replace_result.push_back(ch);
}
assert(replace_result == "My credit card number is XXXX-XXXX-XXXX-XXXX.");
\end{code}

Note that we could \textbf{not} have written \texttt{std::string replace\_result(r.begin(), r.end())}. This is ill-formed because the \texttt{std::string} range constructor takes two iterators of the same type, but \texttt{decltype(rng.end())} is a sentinel type different from \texttt{decltype(rng.begin())}.

Though the ranges \texttt{r} and \texttt{replacement} can both be C-style strings, \texttt{boost::parser::replace\_view} must know the end of \texttt{replacement} before it does any work. This is because the subranges produced are all common ranges, and so if \texttt{replacement} is not, a common range must be formed from it. If you expect to pass very long C-style strings to \texttt{boost::parser::replace} and not pay to see the end until the range is used, don't.

\texttt{ReplacementV} is constrained almost exactly the same as \texttt{V}. \texttt{V} must model \texttt{parsable\_range} and \texttt{std::ranges::viewable\_range}. \texttt{ReplacementV} is the same, except that it can also be a \texttt{std::ranges::input\_range}, whereas \texttt{V} must be a \texttt{std::ranges::forward\_range}.

You may wonder what happens when you pass a UTF-N range for \texttt{r}, and a UTF-M range for \texttt{replacement}. What happens in this case is silent transcoding of \texttt{replacement} from UTF-M to UTF-N by the \texttt{boost::parser::replace} range adaptor. This doesn't require memory allocation; \texttt{boost::parser::replace} just slaps \texttt{| boost::parser::as\_utfN} onto \texttt{replacement}. However, since Boost.Parser treats \texttt{char} ranges as unknown encoding, \texttt{boost::parser::replace} will not transcode from \texttt{char} ranges. So calls like this won't work:

\begin{code}
char const str[] = "some text";
char const replacement_str[] = "some text";
using namespace bp = boost::parser;
auto r = empty_str | bp::replace(parser, replacement_str | bp::as_utf8); // Error: ill-formed!  Can't mix plain-char inputs and UTF replacements.
\end{code}

This does not work, even though \texttt{char} and UTF-8 are the same size. If \texttt{r} and \texttt{replacement} are both ranges of \texttt{char}, everything will work of course. It's just mixing \texttt{char} and UTF-encoded ranges that does not work.

All the details called out in the subsection on \texttt{boost::parser::search()} above apply to \texttt{boost::parser::replace}: its parser produces no attributes; it accepts C-style strings for the \texttt{r} and \texttt{replacement} parameters as if they were ranges; and it knows how to get from the internally-used iterator type back to the given iterator type, in typical cases.

\texttt{boost::parser::replace} can be called with, and \texttt{boost::parser::replace\_view} can be constructed with, a skip parser or not, and you can always pass \texttt{boost::parser::trace} at the end of any of their overloads.

\subsubsection{boost::parser::transform\_replace}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Important \\
\texttt{boost::parser::transform\_replace} and \texttt{boost::parser::transform\_replace\_view} are not available on MSVC in C++17 mode. & \\
\end{longtable}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Important \\
\texttt{boost::parser::transform\_replace} and \texttt{boost::parser::transform\_replace\_view} are not available on GCC in C++20 mode before GCC 12. & \\
\end{longtable}

\texttt{boost::parser::transform\_replace} creates \texttt{boost::parser::transform\_replace\_views}. \texttt{boost::parser::transform\_replace\_view} is a \texttt{std::views}-style view. It produces a range of subranges from the parsed range \texttt{r} and the given invocable \texttt{f}. Wherever in the parsed range a match to the given parser \texttt{parser} is found, let \texttt{parser}'s attribute be \texttt{attr}; \texttt{f(std::move(attr))} is the subrange produced. Each subrange of \texttt{r} that does not match \texttt{parser} is produced as a subrange as well. The subranges are produced in the order in which they occur in \texttt{r}. Unlike \texttt{boost::parser::split\_view}, \texttt{boost::parser::transform\_replace\_view} does not produce empty subranges, unless \texttt{f(std::move(attr))} is empty. Here is an example.

\begin{code}
auto string_sum = [](std::vector<int> const & ints) {
    return std::to_string(std::accumulate(ints.begin(), ints.end(), 0));
};

auto rng = "There are groups of [1, 2, 3, 4, 5] in the set." |
           bp::transform_replace('[' >> bp::int_ % ',' >> ']', bp::ws, string_sum);
int count = 0;
// Prints "There are groups of 15 in the set".
for (auto subrange : rng) {
    for (auto ch : subrange) {
        std::cout << ch;
    }
    ++count;
}
std::cout << "\n";
assert(count == 3);
\end{code}

Let the type \texttt{decltype(f(std::move(attr)))} be \texttt{Replacement}. \texttt{Replacement} must be a range, and must be compatible with \texttt{r}. See the description of \texttt{boost::parser::replace\_view}'s iterator compatibility requirements in the section above for details.

As with \texttt{boost::parser::replace}, \texttt{boost::parser::transform\_replace} can be flattened from a view of subranges into a view of elements by piping it to \texttt{std::views::join}. See the section on \texttt{boost::parser::replace} above for an example.

Just like \texttt{boost::parser::replace} and \texttt{boost::parser::replace\_view}, \texttt{boost::parser::transform\_replace} and \texttt{boost::parser::transform\_replace\_view} do silent transcoding of the result to the appropriate UTF, if applicable. If both \texttt{r} and \texttt{f(std::move(attr))} are ranges of \texttt{char}, or are both the same UTF, no transcoding occurs. If one of \texttt{r} and \texttt{f(std::move(attr))} is a range of \texttt{char} and the other is some UTF, the program is ill-formed.

\texttt{boost::parser::transform\_replace\_view} will move each attribute into \texttt{f}; \texttt{f} may move from the argument or copy it as desired. \texttt{f} may return an lvalue reference. If it does so, the address of the reference will be taken and stored within \texttt{boost::parser::transform\_replace\_view}. Otherwise, the value returned by \texttt{f} is moved into \texttt{boost::parser::transform\_replace\_view}. In either case, the value type of \texttt{boost::parser::transform\_replace\_view} is always a subrange.

\texttt{boost::parser::transform\_replace} can be called with, and \texttt{boost::parser::transform\_replace\_view} can be constructed with, a skip parser or not, and you can always pass \texttt{boost::parser::trace} at the end of any of their overloads.

\subsection{Unicode Support}

Boost.Parser was designed from the start to be Unicode friendly. There are numerous references to the "Unicode code path" and the "non-Unicode code path" in the Boost.Parser documentation. Though there are in fact two code paths for Unicode and non-Unicode parsing, the code is not very different in the two code paths, as they are written generically. The only difference is that the Unicode code path parses the input as a range of code points, and the non-Unicode path does not. In effect, this means that, in the Unicode code path, when you call \texttt{parse(r, p)} for some input range \texttt{r} and some parser \texttt{p}, the parse happens as if you called \texttt{parse(r | boost::parser::as\_utf32, p)} instead. (Of course, it does not matter if \texttt{r} is a proper range, or an iterator/sentinel pair; those both work fine with \texttt{boost::parser::as\_utf32}.)

Matching "characters" within Boost.Parser's parsers is assumed to be a code point match. In the Unicode path there is a code point from the input that is matched to each \texttt{char\_} parser. In the non-Unicode path, the encoding is unknown, and so each element of the input is considered to be a whole "character" in the input encoding, analogous to a code point. From this point on, I will therefore refer to a single element of the input exclusively as a code point.

So, let's say we write this parser:

\begin{code}
constexpr auto char8_parser = boost::parser::char_('\xcc');
\end{code}

For any \texttt{char\_} parser that should match a value or values, the type of the value to match is retained. So \texttt{char8\_parser} contains a \texttt{char} that it will use for matching. If we had written:

\begin{code}
constexpr auto char32_parser = boost::parser::char_(U'\xcc');
\end{code}

\texttt{char32\_parser} would instead contain a \texttt{char32\_t} that it would use for matching.

So, at any point during the parse, if \texttt{char8\_parser} were being used to match a code point \texttt{next\_cp} from the input, we would see the moral equivalent of \texttt{next\_cp == '\textbackslash{}xcc'}, and if \texttt{char32\_parser} were being used to match \texttt{next\_cp}, we'd see the equivalent of \texttt{next\_cp == U'\textbackslash{}xcc'}. The take-away here is that you can write \texttt{char\_} parsers that match specific values, without worrying if the input is Unicode or not because, under the covers, what takes place is a simple comparison of two integral values.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Note \\
Boost.Parser actually promotes any two values to a common type using \texttt{std::common\_type} before comparing them. This is almost always works because the input and any parameter passed to \texttt{char\_} must be character types. & \\
\end{longtable}

Since matches are always done at a code point level (remember, a "code point" in the non-Unicode path is assumed to be a single \texttt{char}), you get different results trying to match UTF-8 input in the Unicode and non-Unicode code paths:

\begin{code}
namespace bp = boost::parser;

{
    std::string str = (char const *)u8"\xcc\x80"; // encodes the code point U+0300
    auto first = str.begin();

    // Since we've done nothing to indicate that we want to do Unicode
    // parsing, and we've passed a range of char to parse(), this will do
    // non-Unicode parsing.
    std::string chars;
    assert(bp::parse(first, str.end(), *bp::char_('\xcc'), chars));

    // Finds one match of the *char* 0xcc, because the value in the parser
    // (0xcc) was matched against the two code points in the input (0xcc and
    // 0x80), and the first one was a match.
    assert(chars == "\xcc");
}
{
    std::u8string str = u8"\xcc\x80"; // encodes the code point U+0300
    auto first = str.begin();

    // Since the input is a range of char8_t, this will do Unicode
    // parsing.  The same thing would have happened if we passed
    // str | boost::parser::as_utf32 or even str | boost::parser::as_utf8.
    std::string chars;
    assert(bp::parse(first, str.end(), *bp::char_('\xcc'), chars));

    // Finds zero matches of the *code point* 0xcc, because the value in
    // the parser (0xcc) was matched against the single code point in the
    // input, 0x0300.
    assert(chars == "");
}
\end{code}

\subsubsection{Implicit transcoding}

Additionally, it is expected that most programs will use UTF-8 for the encoding of Unicode strings. Boost.Parser is written with this typical case in mind. This means that if you are parsing 32-bit code points (as you always are in the Unicode path), and you want to catch the result in a container \texttt{C} of \texttt{char} or \texttt{char8\_t} values, Boost.Parser will silently transcode from UTF-32 to UTF-8 and write the attribute into \texttt{C}. This means that \texttt{std::string}, \texttt{std::u8string}, etc. are fine to use as attribute out-parameters for \texttt{*char\_}, and the result will be UTF-8.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Note \\
UTF-16 strings as attributes are not supported directly. If you want to use UTF-16 strings as attributes, you may need to do so by transcoding a UTF-8 or UTF-32 attribute to UTF-16 within a semantic action. You can do this by using \texttt{boost::parser::as\_utf16}. & \\
\end{longtable}

The treatment of strings as UTF-8 is nearly ubiquitous within Boost.Parser. For instance, though the entire interface of \texttt{symbols} uses \texttt{std::string} or \texttt{std::string\_view}, UTF-32 comparisons are used internally.

\subsubsection{Explicit transcoding}

I mentioned above that the use of \texttt{boost::parser::utf*\_view} as the range to parse opts you in to Unicode parsing. Here's a bit more about these views and how best to use them.

If you want to do Unicode parsing, you're always going to be comparing code points at each step of the parse. As such, you're going to implicitly convert any parse input to UTF-32, if needed. This is what all the parse API functions do internally.

However, there are times when you have parse input that is a sequence of UTF-8-encoded \texttt{char}s, and you want to do Unicode-aware parsing. As mentioned previously, Boost.Parser has a special case for \texttt{char} inputs, and it will \textbf{not} assume that \texttt{char} sequences are UTF-8. If you want to tell the parse API to do Unicode processing on them anyway, you can use the \texttt{as\_utf32} range adapter. (Note that you can use any of the \texttt{as\_utf*} adaptors and the semantics will not differ from the semantics below.)

\begin{code}
namespace bp = boost::parser;

auto const p = '"' >> *(bp::char_ - '"' - 0xb6) >> '"';
char const * str = "\"two wörds\""; // ö is two code units, 0xc3 0xb6

auto result_1 = bp::parse(str, p);                // Treat each char as a code point (typically ASCII).
assert(!result_1);
auto result_2 = bp::parse(str | bp::as_utf32, p); // Unicode-aware parsing on code points.
assert(result_2);
\end{code}

The first call to \texttt{parse()} treats each \texttt{char} as a code point, and since \texttt{"ö"} is the pair of code units \texttt{0xc3} \texttt{0xb6}, the parse matches the second code unit against the \texttt{- 0xb6} part of the parser above, causing the parse to fail. This happens because each code unit/\texttt{char} in \texttt{str} is treated as an independent code point.

The second call to \texttt{parse()} succeeds because, when the parse gets to the code point for \texttt{'ö'}, it is \texttt{0xf6} (U+00F6), which does not match the \texttt{- 0xb6} part of the parser.

The other adaptors \texttt{as\_utf8} and \texttt{as\_utf16} are also provided for completeness, if you want to use them. They each can transcode any sequence of character types.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Important \\
The \texttt{as\_utfN} adaptors are optional, so they don't come with \texttt{parser.hpp}. To get access to them, \texttt{\#include <boost/parser/transcode\_view.hpp>}. & \\
\end{longtable}

\subsubsection{(Lack of) normalization}

One thing that Boost.Parser does not handle for you is normalization; Boost.Parser is completely normalization-agnostic. Since all the parsers do their matching using equality comparisons of code points, you should make sure that your parsed range and your parsers all use the same normalization form.

\subsection{Callback Parsing}

In most parsing cases, being able to generate an attribute that represents the result of the parse, or being able to parse into such an attribute, is sufficient. Sometimes, it is not. If you need to parse a very large chunk of text, the generated attribute may be too large to fit in memory. In other cases, you may want to generate attributes sometimes, and not others. \texttt{callback\_rules} exist for these kinds of uses. A \texttt{callback\_rule} is just like a rule, except that it allows the rule's attribute to be returned to the caller via a callback, as long as the parse is started with a call to \texttt{callback\_parse()} instead of \texttt{parse()}. Within a call to \texttt{parse()}, a \texttt{callback\_rule} is identical to a regular \texttt{rule}.

For a rule with no attribute, the signature of a callback function is \texttt{void (tag)}, where \texttt{tag} is the tag-type used when declaring the rule. For a rule with an attribute \texttt{attr}, the signature is \texttt{void (tag, attr)}. For instance, with this rule:

\begin{code}
boost::parser::callback_rule<struct foo_tag> foo = "foo";
\end{code}

this would be an appropriate callback function:

\begin{code}
void foo_callback(foo_tag)
{
    std::cout << "Parsed a 'foo'!\n";
}
\end{code}

For this rule:

\begin{code}
boost::parser::callback_rule<struct bar_tag, std::string> bar = "bar";
\end{code}

this would be an appropriate callback function:

\begin{code}
void bar_callback(bar_tag, std::string const & s)
{
    std::cout << "Parsed a 'bar' containing " << s << "!\n";
}
\end{code}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Important \\
In the case of \texttt{bar\_callback()}, we don't need to do anything with \texttt{s} besides insert it into a stream, so we took it as a \texttt{const} lvalue reference. Boost.Parser moves all attributes into callbacks, so the signature could also have been \texttt{void bar\_callback(bar\_tag, std::string s)} or \texttt{void bar\_callback(bar\_tag, std::string \&\& s)}. & \\
\end{longtable}

You opt into callback parsing by parsing with a call to \texttt{callback\_parse()} instead of \texttt{parse()}. If you use \texttt{callback\_rules} with \texttt{parse()}, they're just regular \texttt{rules}. This allows you to choose whether to do "normal" attribute-generating/attribute-assigning parsing with \texttt{parse()}, or callback parsing with \texttt{callback\_parse()}, without rewriting much parsing code, if any.

The only reason all \texttt{rules} are not \texttt{callback\_rules} is that you may want to have some \texttt{rules} use callbacks within a parse, and have some that do not. For instance, if you want to report the attribute of \texttt{callback\_rule} \texttt{r1} via callback, \texttt{r1}'s implementation may use some rule \texttt{r2} to generate some or all of its attribute.

See Parsing JSON With Callbacks for an extended example of callback parsing.

\subsection{Error Handling and Debugging}

\subsubsection{Error handling}

Boost.Parser has good error reporting built into it. Consider what happens when we fail to parse at an expectation point (created using \texttt{operator>}). If I feed the parser from the Parsing JSON With Callbacks example a file called sample.json containing this input (note the unmatched \texttt{'{[}'}):

\begin{code}
{
    "key": "value",
    "foo": [, "bar": []
}
\end{code}

This is the error message that is printed to the terminal:

\begin{code}
sample.json:3:12: error: Expected ']' here:
    "foo": [, "bar": []
            ^
\end{code}

That message is formatted like the diagnostics produced by Clang and GCC. It quotes the line on which the failure occurred, and even puts a caret under the exact position at which the parse failed. This error message is suitable for many kinds of end-users, and interoperates well with anything that supports Clang and/or GCC diagnostics.

Most of Boost.Parser's error handlers format their diagnostics this way, though you are not bound by that. You can make an error handler type that does whatever you want, as long as it meets the error handler interface.

The Boost.Parser error handlers are:

\begin{itemize}
\item
  \texttt{default\_error\_handler}: Produces formatted diagnostics like the one above, and prints them to \texttt{std::cerr}. \texttt{default\_error\_handler} has no associated file name, and both errors and diagnostics are printed to \texttt{std::cerr}. This handler is \texttt{constexpr}-friendly.
\item
  \texttt{stream\_error\_handler}: Produces formatted diagnostics. One or two streams may be used. If two are used, errors go to one stream and warnings go to the other. A file name can be associated with the parse; if it is, that file name will appear in all diagnostics.
\item
  \texttt{callback\_error\_handler}: Produces formatted diagnostics. Calls a callback with the diagnostic message to report the diagnostic, rather than streaming out the diagnostic. A file name can be associated with the parse; if it is, that file name will appear in all diagnostics. This handler is useful for recording the diagnostics in memory.
\item
  \texttt{rethrow\_error\_handler}: Does nothing but re-throw any exception that it is asked to handle. Its \texttt{diagnose()} member functions are no-ops.
\item
  \texttt{vs\_output\_error\_handler}: Directs all errors and warnings to the debugging output panel inside Visual Studio. Available on Windows only. Probably does nothing useful desirable when executed outside of Visual Studio.
\end{itemize}

You can set the error handler to any of these, or one of your own, using \texttt{with\_error\_handler()} (see The \texttt{parse()} API). If you do not set one, \texttt{default\_error\_handler} will be used.

\subsubsection{How diagnostics are generated}

Boost.Parser only generates error messages like the ones in this page at failed expectation points, like \texttt{a > b}, where you have successfully parsed \texttt{a}, but then cannot successfully parse \texttt{b}. This may seem limited to you. It's actually the best that we can do.

In order for error handling to happen other than at expectation points, we have to know that there is no further processing that might take place. This is true because Boost.Parser has \texttt{P1 | P2 | ... | Pn} parsers ("\texttt{or\_parser}s"). If any one of these parsers \texttt{Pi} fails to match, it is not allowed to fail the parse --- the next one (\texttt{Pi+1}) might match. If we get to the end of the alternatives of the or\_parser and \texttt{Pn} fails, we still cannot fail the top-level parse, because the \texttt{or\_parser} might be a subparser within a parent \texttt{or\_parser}.

Ok, so what might we do? Perhaps we could at least indicate when we ran into end-of-input. But we cannot, for exactly the same reason already stated. For any parser \texttt{P}, reaching end-of-input is a failure for \texttt{P}, but not necessarily for the whole parse.

Perhaps we could record the farthest point ever reached during the parse, and report that at the top level, if the top level parser fails. That would be little help without knowing which parser was active when we reached that point. This would require some sort of repeated memory allocation, since in Boost.Parser the progress point of the parser is stored exclusively on the stack --- by the time we fail the top-level parse, all those far-reaching stack frames are long gone. Not the best.

Worse still, knowing how far you got in the parse and which parser was active is not very useful. Consider this.

\begin{code}
namespace bp = boost::parser;
auto a_b = bp::char_('a') >> bp::char_('b');
auto c_b = bp::char_('c') >> bp::char_('b');
auto result = bp::parse("acb", a_b | c_b);
\end{code}

If we reported the farthest-reaching parser and it's position, it would be the \texttt{a\_b} parser, at position \texttt{"bc"} in the input. Is this really enlightening? Was the error in the input putting the \texttt{'a'} at the beginning or putting the \texttt{'c'} in the middle? If you point the user at \texttt{a\_b} as the parser that failed, and never mention \texttt{c\_b}, you are potentially just steering them in the wrong direction.

All error messages must come from failed expectation points. Consider parsing JSON. If you open a list with \texttt{'{[}'}, you know that you're parsing a list, and if the list is ill-formed, you'll get an error message saying so. If you open an object with \texttt{'\{'}, the same thing is possible --- when missing the matching \texttt{'\}'}, you can tell the user, "That's not an object", and this is useful feedback. The same thing with a partially parsed number, etc. If the JSON parser does not build in expectations like matched braces and brackets, how can Boost.Parser know that a missing \texttt{'\}'} is really a problem, and that no later parser will match the input even without the \texttt{'\}'}?

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Important \\
The bottom line is that you should build expectation points into your parsers using \texttt{operator>} as much as possible. & \\
\end{longtable}

\subsubsection{Using error handlers in semantic actions}

You can get access to the error handler within any semantic action by calling \texttt{\_error\_handler(ctx)} (see The Parse Context). Any error handler must have the following member functions:

\begin{code}
template<typename Context, typename Iter>
void diagnose(
    diagnostic_kind kind,
    std::string_view message,
    Context const & context,
    Iter it) const;
\end{code}

\begin{code}
template<typename Context>
void diagnose(
    diagnostic_kind kind,
    std::string_view message,
    Context const & context) const;
\end{code}

If you call the second one, the one without the iterator parameter, it will call the first with \texttt{\_where(context).begin()} as the iterator parameter. The one without the iterator is the one you will use most often. The one with the explicit iterator parameter can be useful in situations where you have messages that are related to each other, associated with multiple locations. For instance, if you are parsing XML, you may want to report that a close-tag does not match its associated open-tag by showing the line where the open-tag was found. That may of course not be located anywhere near \texttt{\_where(ctx).begin()}. (A description of \texttt{\_globals()} is below.)

\begin{code}
[](auto & ctx) {
    // Assume we have a std::vector of open tags, and another
    // std::vector of iterators to where the open tags were parsed, in our
    // globals.
    if (_attr(ctx) != _globals(ctx).open_tags.back()) {
        std::string open_tag_msg =
            "Previous open-tag \"" + _globals(ctx).open_tags.back() + "\" here:";
        _error_handler(ctx).diagnose(
            boost::parser::diagnostic_kind::error,
            open_tag_msg,
            ctx,
            _globals(ctx).open_tags_position.back());
        std::string close_tag_msg =
            "does not match close-tag \"" + _attr(ctx) + "\" here:";
        _error_handler(ctx).diagnose(
            boost::parser::diagnostic_kind::error,
            close_tag_msg,
            ctx);

        // Explicitly fail the parse.  Diagnostics do not affect parse success.
        _pass(ctx) = false;
    }
}
\end{code}

\subsubsection{\_report\_error() and \_report\_warning()}

There are also some convenience functions that make the above code a little less verbose, \texttt{\_report\_error()} and \texttt{\_report\_warning()}:

\begin{code}
[](auto & ctx) {
    // Assume we have a std::vector of open tags, and another
    // std::vector of iterators to where the open tags were parsed, in our
    // globals.
    if (_attr(ctx) != _globals(ctx).open_tags.back()) {
        std::string open_tag_msg =
            "Previous open-tag \"" + _globals(ctx).open_tags.back() + "\" here:";
        _report_error(ctx, open_tag_msg, _globals(ctx).open_tag_positions.back());
        std::string close_tag_msg =
            "does not match close-tag \"" + _attr(ctx) + "\" here:";
        _report_error(ctx, close_tag_msg);

        // Explicitly fail the parse.  Diagnostics do not affect parse success.
        _pass(ctx) = false;
    }
}
\end{code}

You should use these less verbose functions almost all the time. The only time you would want to use \texttt{\_error\_handler()} directly is when you are using a custom error handler, and you want access to some part of its interface besides \texttt{diagnose()}.

Though there is support for reporting warnings using the functions above, none of the error handlers supplied by Boost.Parser will ever report a warning. Warnings are strictly for user code.

For more information on the rest of the error handling and diagnostic API, see the header reference pages for \texttt{error\_handling\_fwd.hpp} and \texttt{error\_handling.hpp}.

\subsubsection{Creating your own error handler}

Creating your own error handler is pretty easy; you just need to implement three member functions. Say you want an error handler that writes diagnostics to a file. Here's how you might do that.

\begin{code}
struct logging_error_handler
{
    logging_error_handler() {}
    logging_error_handler(std::string_view filename) :
        filename_(filename), ofs_(filename_)
    {
        if (!ofs_)
            throw std::runtime_error("Could not open file.");
    }

    // This is the function called by Boost.Parser after a parser fails the
    // parse at an expectation point and throws a parse_error.  It is expected
    // to create a diagnostic message, and put it where it needs to go.  In
    // this case, we're writing it to a log file.  This function returns a
    // bp::error_handler_result, which is an enum with two enumerators -- fail
    // and rethrow.  Returning fail fails the top-level parse; returning
    // rethrow just re-throws the parse_error exception that got us here in
    // the first place.
    template<typename Iter, typename Sentinel>
    bp::error_handler_result
    operator()(Iter first, Sentinel last, bp::parse_error<Iter> const & e) const
    {
        bp::write_formatted_expectation_failure_error_message(
            ofs_, filename_, first, last, e);
        return bp::error_handler_result::fail;
    }

    // This function is for users to call within a semantic action to produce
    // a diagnostic.
    template<typename Context, typename Iter>
    void diagnose(
        bp::diagnostic_kind kind,
        std::string_view message,
        Context const & context,
        Iter it) const
    {
        bp::write_formatted_message(
            ofs_,
            filename_,
            bp::_begin(context),
            it,
            bp::_end(context),
            message);
    }

    // This is just like the other overload of diagnose(), except that it
    // determines the Iter parameter for the other overload by calling
    // _where(ctx).
    template<typename Context>
    void diagnose(
        bp::diagnostic_kind kind,
        std::string_view message,
        Context const & context) const
    {
        diagnose(kind, message, context, bp::_where(context).begin());
    }

    std::string filename_;
    mutable std::ofstream ofs_;
};
\end{code}

That's it. You just need to do the important work of the error handler in its call operator, and then implement the two overloads of \texttt{diagnose()} that it must provide for use inside semantic actions. The default implementation of these is even available as the free function \texttt{write\_formatted\_message()}, so you can just call that, as you see above. Here's how you might use it.

\begin{code}
int main()
{
    std::cout << "Enter a list of integers, separated by commas. ";
    std::string input;
    std::getline(std::cin, input);

    constexpr auto parser = bp::int_ >> *(',' > bp::int_);
    logging_error_handler error_handler("parse.log");
    auto const result = bp::parse(input, bp::with_error_handler(parser, error_handler));

    if (result) {
        std::cout << "It looks like you entered:\n";
        for (int x : *result) {
            std::cout << x << "\n";
        }
    }
}
\end{code}

We just define a \texttt{logging\_error\_handler}, and pass it by reference to \texttt{with\_error\_handler()}, which decorates the top-level parser with the error handler. We \textbf{could not} have written \texttt{bp::with\_error\_handler(parser, logging\_error\_handler("parse.log"))}, because \texttt{with\_error\_handler()} does not accept rvalues. This is becuse the error handler eventually goes into the parse context. The parse context only stores pointers and iterators, keeping it cheap to copy.

If we run the example and give it the input \texttt{"1,"}, this shows up in the log file:

\begin{code}
parse.log:1:2: error: Expected int_ here (end of input):
1,
  ^
\end{code}

\subsubsection{Fixing ill-formed code}

Sometimes, during the writing of a parser, you make a simple mistake that is diagnosed horrifyingly, due to the high number of template instantiations between the line you just wrote and the point of use (usually, the call to \texttt{parse()}). By "sometimes", I mean "almost always and many, many times". Boost.Parser has a workaround for situations like this. The workaround is to make the ill-formed code well-formed in as many circumstances as possible, and then do a runtime assert instead.

Usually, C++ programmers try whenever they can to catch mistakes as early as they can. That usually means making as much bad code ill-formed as possible. Counter-intuitively, this does not work well in parser combinator situations. For an example of just how dramatically different these two debugging scenarios can be with Boost.Parser, please see the very long discussion in the \texttt{none} is weird section of Rationale.

If you are morally opposed to this approach, or just hate fun, good news: you can turn off the use of this technique entirely by defining \texttt{BOOST\_PARSER\_NO\_RUNTIME\_ASSERTIONS}.

\subsubsection{Runtime debugging}

Debugging parsers is hard. Any parser above a certain complexity level is nearly impossible to debug simply by looking at the parser's code. Stepping through the parse in a debugger is even worse. To provide a reasonable chance of debugging your parsers, Boost.Parser has a trace mode that you can turn on simply by providing an extra parameter to \texttt{parse()} or \texttt{callback\_parse()}:

\begin{code}
boost::parser::parse(input, parser, boost::parser::trace::on);
\end{code}

Every overload of \texttt{parse()} and \texttt{callback\_parse()} takes this final parameter, which is defaulted to \texttt{boost::parser::trace::off}.

If we trace a substantial parser, we will see a \textbf{lot} of output. Each code point of the input must be considered, one at a time, to see if a certain rule matches. An an example, let's trace a parse using the JSON parser from Parsing JSON. The input is \texttt{"null"}. \texttt{null} is one of the types that a Javascript value can have; the top-level parser in the JSON parser example is:

\begin{code}
auto const value_p_def =
    number | bp::bool_ | null | string | array_p | object_p;
\end{code}

So, a JSON value can be a number, or a Boolean, a \texttt{null}, etc. During the parse, each alternative will be tried in turn, until one is matched. I picked \texttt{null} because it is relatively close to the beginning of the \texttt{value\_p\_def} alternative parser. Even so, the output is pretty huge. Let's break it down as we go:

\begin{code}
[begin value; input="null"]
\end{code}

Each parser is traced as \texttt{{[}begin foo; ...{]}}, then the parsing operations themselves, and then \texttt{{[}end foo; ...{]}}. The name of a rule is used as its name in the \texttt{begin} and \texttt{end} parts of the trace. Non-rules have a name that is similar to the way the parser looked when you wrote it. Most lines will have the next few code points of the input quoted, as we have here (\texttt{input="null"}).

\begin{code}
[begin number | bool_ | null | string | ...; input="null"]
\end{code}

This shows the beginning of the parser \textbf{inside} the rule \texttt{value} --- the parser that actually does all the work. In the example code, this parser is called \texttt{value\_p\_def}. Since it isn't a rule, we have no name for it, so we show its implementation in terms of subparsers. Since it is a bit long, we don't print the entire thing. That's why that ellipsis is there.

\begin{code}
[begin number; input="null"]
  [begin raw[lexeme[ >> ...]][<<action>>]; input="null"]
\end{code}

Now we're starting to see the real work being done. \texttt{number} is a somewhat complicated parser that does not match \texttt{"null"}, so there's a lot to wade through when following the trace of its attempt to do so. One thing to note is that, since we cannot print a name for an action, we just print \texttt{"<<action>>"}. Something similar happens when we come to an attribute that we cannot print, because it has no stream insertion operation. In that case, \texttt{"<<unprintable-value>>"} is printed.

\begin{code}
    [begin raw[lexeme[ >> ...]]; input="null"]
      [begin lexeme[-char_('-') >> char_('1', '9') >> ... | ... >> ...]; input="null"]
        [begin -char_('-') >> char_('1', '9') >> *digit | char_('0') >> -(char_('.') >> ...) >> -( >> ...); input="null"]
          [begin -char_('-'); input="null"]
            [begin char_('-'); input="null"]
              no match
            [end char_('-'); input="null"]
            matched ""
            attribute: <<empty>>
          [end -char_('-'); input="null"]
          [begin char_('1', '9') >> *digit | char_('0'); input="null"]
            [begin char_('1', '9') >> *digit; input="null"]
              [begin char_('1', '9'); input="null"]
                no match
              [end char_('1', '9'); input="null"]
              no match
            [end char_('1', '9') >> *digit; input="null"]
            [begin char_('0'); input="null"]
              no match
            [end char_('0'); input="null"]
            no match
          [end char_('1', '9') >> *digit | char_('0'); input="null"]
          no match
        [end -char_('-') >> char_('1', '9') >> *digit | char_('0') >> -(char_('.') >> ...) >> -( >> ...); input="null"]
        no match
      [end lexeme[-char_('-') >> char_('1', '9') >> ... | ... >> ...]; input="null"]
      no match
    [end raw[lexeme[ >> ...]]; input="null"]
    no match
  [end raw[lexeme[ >> ...]][<<action>>]; input="null"]
  no match
[end number; input="null"]
[begin bool_; input="null"]
  no match
[end bool_; input="null"]
\end{code}

\texttt{number} and \texttt{boost::parser::bool\_} did not match, but \texttt{null} will:

\begin{code}
[begin null; input="null"]
  [begin "null" >> attr(null); input="null"]
    [begin "null"; input="null"]
      [begin string("null"); input="null"]
        matched "null"
        attribute:
      [end string("null"); input=""]
      matched "null"
      attribute: null
\end{code}

Finally, this parser actually matched, and the match generated the attribute \texttt{null}, which is a special value of the type \texttt{json::value}. Since we were matching a string literal \texttt{"null"}, earlier there was no attribute until we reached the \texttt{attr(null)} parser.

\begin{code}
        [end "null"; input=""]
        [begin attr(null); input=""]
          matched ""
          attribute: null
        [end attr(null); input=""]
        matched "null"
        attribute: null
      [end "null" >> attr(null); input=""]
      matched "null"
      attribute: null
    [end null; input=""]
    matched "null"
    attribute: null
  [end number | bool_ | null | string | ...; input=""]
  matched "null"
  attribute: null
[end value; input=""]
--------------------
parse succeeded
--------------------
\end{code}

At the very end of the parse, the trace code prints out whether the top-level parse succeeded or failed.

Some things to be aware of when looking at Boost.Parser trace output:

\begin{itemize}
\item
  There are some parsers you don't know about, because they are not directly documented. For instance, \texttt{p{[}a{]}} forms an \texttt{action\_parser} containing the parser \texttt{p} and semantic action \texttt{a}. This is essentially an implementation detail, but unfortunately the trace output does not hide this from you.
\item
  For a parser \texttt{p}, the trace-name may be intentionally different from the actual structure of \texttt{p}. For example, in the trace above, you see a parser called simply \texttt{"null"}. This parser is actually \texttt{boost::parser::omit{[}boost::parser::string("null"){]}}, but what you typically write is just \texttt{"null"}, so that's the name used. There are two special cases like this: the one described here for \texttt{omit{[}string{]}}, and another for \texttt{omit{[}char\_{]}}.
\item
  Since there are no other special cases for how parser names are printed, you may see parsers that are unlike what you wrote in your code. In the sections about the parsers and combining operations, you will sometimes see a parser or combining operation described in terms of an equivalent parser. For example, \texttt{if\_(pred){[}p{]}} is described as "Equivalent to \texttt{eps(pred) >> p}". In a trace, you will not see \texttt{if\_}; you will see \texttt{eps} and \texttt{p} instead.
\item
  The values of arguments passed to parsers is printed whenever possible. Sometimes, a parse argument is not a value itself, but a callable that produces that value. In these cases, you'll see the resolved value of the parse argument.
\end{itemize}

\subsection{Memory Allocation}

Boost.Parser seldom allocates memory. The exceptions to this are:

\begin{itemize}
\item
  \texttt{symbols} allocates memory for the symbol/attribute pairs it contains. If symbols are added during the parse, allocations must also occur then. The data structure used by \texttt{symbols} is also a trie, which is a node-based tree. So, lots of allocations are likely if you use \texttt{symbols}.
\item
  The error handlers that can take a file name allocate memory for the file name, if one is provided.
\item
  If trace is turned on by passing \texttt{boost::parser::trace::on} to a top-level parsing function, the names of parsers are allocated.
\item
  When a failed expectation is encountered (using \texttt{operator>}), the name of the failed parser is placed into a \texttt{std::string}, which will usually cause an allocation.
\item
  \texttt{string()}'s attribute is a \texttt{std::string}, the use of which implies allocation. You can avoid this allocation by explicitly using a different string type for the attribute that does not allocate.
\item
  The attribute for \texttt{repeat(p)} in all its forms, including \texttt{operator*}, \texttt{operator+}, and \texttt{operator\%}, is \texttt{std::vector<}\emph{\texttt{ATTR}}\texttt{(p)>}, the use of which implies allocation. You can avoid this allocation by explicitly using a different sequence container for the attribute that does not allocate. \texttt{boost::container::static\_vector} or C++26's \texttt{std::inplace\_vector} may be useful as such replacements.
\end{itemize}

With the exception of allocating the name of the parser that was expected in a failed expectation situation, Boost.Parser does not does not allocate unless you tell it to, by using \texttt{symbols}, using a particular error\_handler, turning on trace, or parsing into attributes that allocate.

\subsection{Best Practices}

\subsubsection{Parse unicode from the start}

If you want to parse ASCII, using the Unicode parsing API will not actually cost you anything. Your input will be parsed, \texttt{char} by \texttt{char}, and compared to values that are Unicode code points (which are \texttt{char32\_t}s). One caveat is that there may be an extra branch on each char, if the input is UTF-8. If your performance requirements can tolerate this, your life will be much easier if you just start with Unicode and stick with it.

Starting with Unicode support and UTF-8 input will allow you to properly handle unexpected input, like non-ASCII languages (that's most of them), with no additional effort on your part.

\subsubsection{Write rules, and test them in isolation}

Treat rules as the unit of work in your parser. Write a rule, test its corners, and then use it to build larger rules or parsers. This allows you to get better coverage with less work, since exercising all the code paths of your rules, one by one, keeps the combinatorial number of paths through your code manageable.

\subsubsection{Prefer auto-generated attributes to semantic actions}

There are multiple ways to get attributes out of a parser. You can:

\begin{itemize}
\item
  use whatever attribute the parser generates;
\item
  provide an attribute out-argument to \texttt{parse()} for the parser to fill in;
\item
  use one or more semantic actions to assign attributes from the parser to variables outside the parser;
\item
  use callback parsing to provide attributes via callback calls.
\end{itemize}

All of these are fairly similar in how much effort they require, except for the semantic action method. For the semantic action approach, you need to have values to fill in from your parser, and keep them in scope for the duration of the parse.

It is much more straight forward, and leads to more reusable parsers, to have the parsers produce the attributes of the parse directly as a result of the parse.

This does not mean that you should never use semantic actions. They are sometimes necessary. However, you should default to using the other non-semantic action methods, and only use semantic actions with a good reason.

\subsubsection{If your parser takes end-user input, give rules names that you would want an end-user to see}

A typical error message produced by Boost.Parser will say something like, "Expected FOO here", where FOO is some rule or parser. Give your rules names that will read well in error messages like this. For instance, the JSON examples have these rules:

\begin{code}
bp::rule<class escape_seq, uint32_t> const escape_seq =
    "\\uXXXX hexadecimal escape sequence";
bp::rule<class escape_double_seq, uint32_t, double_escape_locals> const
    escape_double_seq = "\\uXXXX hexadecimal escape sequence";
bp::rule<class single_escaped_char, uint32_t> const single_escaped_char =
    "'\"', '\\', '/', 'b', 'f', 'n', 'r', or 't'";
\end{code}

Some things to note:

- \texttt{escape\_seq} and \texttt{escape\_double\_seq} have the same name-string. To an end-user who is trying to figure out why their input failed to parse, it doesn't matter which kind of result a parser rule generates. They just want to know how to fix their input. For either rule, the fix is the same: put a hexadecimal escape sequence there.

- \texttt{single\_escaped\_char} has a terrible-looking name. However, it's not really used as a name anywhere per se. In error messages, it works nicely, though. The error will be "Expected \textquotesingle"\textquotesingle, \textquotesingle\textquotesingle, \textquotesingle/\textquotesingle, 'b\textquotesingle, 'f\textquotesingle, 'n\textquotesingle, 'r\textquotesingle, or 't' here", which is pretty helpful.

\subsubsection{Have a simple test that you can run to find ill-formed-code-as-asserts}

Most of these errors are found at parser construction time, so no actual parsing is even necessary. For instance, a test case might look like this:

\begin{code}
TEST(my_parser_tests, my_rule_test) {
    my_rule r;
}
\end{code}

\subsection{Writing Your Own Parsers}

You should probably never need to write your own low-level parser. You have primitives like \texttt{char\_} from which to build up the parsers that you need. It is unlikely that you're going to need to do things on a lower level than a single character.

However. Some people are obsessed with writing everything for themselves. We call them C++ programmers. This section is for them. However, this section is not an in-depth tutorial. It is a basic orientation to get you familiar enough with all the moving parts of writing a parser that you can then learn by reading the Boost.Parser code.

Each parser must provide two overloads of a function \texttt{call()}. One overload parses, producing an attribute (which may be the special no-attribute type \texttt{detail::nope}). The other one parses, filling in a given attribute. The type of the given attribute is a template parameter, so it can take any type that you can form a reference to.

Let's take a look at a Boost.Parser parser, \texttt{opt\_parser}. This is the parser produced by use of \texttt{operator-}. First, here is the beginning of its definition.

\begin{code}
template<typename Parser>
struct opt_parser
{
\end{code}

The end of its definition is:

\begin{code}
    Parser parser_;
};
\end{code}

As you can see, \texttt{opt\_parser}'s only data member is the parser it adapts, \texttt{parser\_}. Here is its attribute-generating overload to \texttt{call()}.

\begin{code}
template<
    typename Iter,
    typename Sentinel,
    typename Context,
    typename SkipParser>
auto call(
    Iter & first,
    Sentinel last,
    Context const & context,
    SkipParser const & skip,
    detail::flags flags,
    bool & success) const
{
    using attr_t = decltype(parser_.call(
        first, last, context, skip, flags, success));
    detail::optional_of<attr_t> retval;
    call(first, last, context, skip, flags, success, retval);
    return retval;
}
\end{code}

First, let's look at the template and function parameters.

\begin{itemize}
\item
  \texttt{Iter \& first} is the iterator. It is taken as an out-param. It is the responsibility of \texttt{call()} to advance \texttt{first} if and only if the parse succeeds.
\item
  \texttt{Sentinel last} is the sentinel. If the parse has not yet succeeded within \texttt{call()}, and \texttt{first == last} is \texttt{true}, \texttt{call()} must fail (by setting \texttt{bool \& success} to \texttt{false}).
\item
  \texttt{Context const \& context} is the parse context. It will be some specialization of \texttt{detail::parse\_context}. The context is used in any call to a subparser's \texttt{call()}, and in some cases a new context should be created, and the new context passed to a subparser instead; more on that below.
\item
  \texttt{SkipParser const \& skip} is the current skip parser. \texttt{skip} should be used at the beginning of the parse, and in between any two uses of any subparser(s).
\item
  \texttt{detail::flags flags} are a collection of flags indicating various things about the current state of the parse. \texttt{flags} is concerned with whether to produce attributes at all; whether to apply the skip parser \texttt{skip}; whether to produce a verbose trace (as when \texttt{boost::parser::trace::on} is passed at the top level); and whether we are currently inside the utility function \texttt{detail::apply\_parser}.
\item
  \texttt{bool \& success} is the final function parameter. It should be set to \texttt{true} if the parse succeeds, and \texttt{false} otherwise.
\end{itemize}

Now the body of the function. Notice that it just dispatches to the other \texttt{call()} overload. This is really common, since both overloads need to to the same parsing; only the attribute may differ. The first line of the body defines \texttt{attr\_t}, the default attribute type of our wrapped parser \texttt{parser\_}. It does this by getting the \texttt{decltype()} of a use of \texttt{parser\_.call()}. (This is the logic represented by \emph{\texttt{ATTR}}\texttt{()} in the rest of the documentation.) Since \texttt{opt\_parser} represents an optional value, the natural type for its attribute is \texttt{std::optional<}\emph{\texttt{ATTR}}\texttt{(parser)>}. However, this does not work for all cases. In particular, it does not work for the "no-attribute" type \texttt{detail::nope}, nor for \texttt{std::optional<T>} --- \emph{\texttt{ATTR}}\texttt{(-\/-p)} is just \emph{\texttt{ATTR}}\texttt{(-p)}. So, the second line uses an alias that takes care of those details, \texttt{detail::optional\_of<>}. The third line just calls the other overload of \texttt{call()}, passing \texttt{retval} as the out-param. Finally, \texttt{retval} is returned on the last line.

Now, on to the other overload.

\begin{code}
template<
    typename Iter,
    typename Sentinel,
    typename Context,
    typename SkipParser,
    typename Attribute>
void call(
    Iter & first,
    Sentinel last,
    Context const & context,
    SkipParser const & skip,
    detail::flags flags,
    bool & success,
    Attribute & retval) const
{
    [[maybe_unused]] auto _ = detail::scoped_trace(
        *this, first, last, context, flags, retval);

    detail::skip(first, last, skip, flags);

    if (!detail::gen_attrs(flags)) {
        parser_.call(first, last, context, skip, flags, success);
        success = true;
        return;
    }

    parser_.call(first, last, context, skip, flags, success, retval);
    success = true;
}
\end{code}

The template and function parameters here are identical to the ones from the other overload, except that we have \texttt{Attribute \& retval}, our out-param.

Let's look at the implementation a bit at a time.

\begin{code}
[[maybe_unused]] auto _ = detail::scoped_trace(
    *this, first, last, context, flags, retval);
\end{code}

This defines a RAII trace object that will produce the verbose trace requested by the user if they passed \texttt{boost::parser::trace::on} to the top-level parse. It only has effect if \texttt{detail::enable\_trace(flags)} is \texttt{true}. If trace is enabled, it will show the state of the parse at the point at which it is defined, and then again when it goes out of scope.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\end{minipage} & Important \\
For the tracing code to work, you must define an overload of \texttt{detail::print\_parser} for your new parser type/template. See \texttt{<boost/parser/detail/printing.hpp>} for examples. & \\
\end{longtable}

\begin{code}
detail::skip(first, last, skip, flags);
\end{code}

This one is pretty simple; it just applies the skip parser. \texttt{opt\_parser} only has one subparser, but if it had more than one, or if it had one that it applied more than once, it would need to repeat this line using \texttt{skip} between every pair of uses of any subparser.

\begin{code}
if (!detail::gen_attrs(flags)) {
    parser_.call(first, last, context, skip, flags, success);
    success = true;
    return;
}
\end{code}

This path accounts for the case where we don't want to generate attributes at all, perhaps because this parser sits inside an \texttt{omit{[}{]}} directive.

\begin{code}
parser_.call(first, last, context, skip, flags, success, retval);
success = true;
\end{code}

This is the other, typical, path. Here, we do want to generate attributes, and so we do the same call to \texttt{parser\_.call()}, except that we also pass \texttt{retval}.

Note that we set \texttt{success} to \texttt{true} after the call to \texttt{parser\_.call()} in both code paths. Since \texttt{opt\_parser} is zero-or-one, if the subparser fails, \texttt{opt\_parse} still succeeds.

\subsubsection{When to make a new parse context}

Sometimes, you need to change something about the parse context before calling a subparser. For instance, \texttt{rule\_parser} sets up the value, locals, etc., that are available for that rule. \texttt{action\_parser} adds the generated attribute to the context (available as \texttt{\_attr(ctx)}). Contexts are immutable in Boost.Parser. To "modify" one for a subparser, you create a new one with the appropriate call to \texttt{detail::make\_context()}.

\subsubsection{\texorpdfstring{\texttt{detail::apply\_parser()}}{detail::apply\_parser()}}

Sometimes a parser needs to operate on an out-param that is not exactly the same as its default attribute, but that is compatible in some way. To do this, it's often useful for the parser to call itself, but with slightly different parameters. \texttt{detail::apply\_parser()} helps with this. See the out-param overload of \texttt{repeat\_parser::call()} for an example. Note that since this creates a new scope for the ersatz parser, the \texttt{scoped\_trace} object needs to know whether we're inside \texttt{detail::apply\_parser} or not.

That's a lot, I know. Again, this section is not meant to be an in-depth tutorial. You know enough now that the parsers in \texttt{parser.hpp} are at least readable.



\section{Extended Examples}



\subsection{Parsing JSON}

This is a conforming JSON parser. It passes all the required tests in the JSON Test Suite, and all but 5 of the optional ones. Notice that the actual parsing bits are only about 150 lines of code.

\begin{code}
// This header includes a type called json::value that acts as a
// Javascript-like polymorphic value type.
#include "json.hpp"

#include <boost/parser/parser.hpp>

#include <fstream>
#include <vector>
#include <climits>


namespace json {

    namespace bp = ::boost::parser;
    using namespace bp::literals;

    // The JSON spec imposes a limit on how deeply JSON data structures are
    // allowed to nest.  This exception is thrown when that limit is exceeded
    // during the parse.
    template<typename Iter>
    struct excessive_nesting : std::runtime_error
    {
        excessive_nesting(Iter it) :
            runtime_error("excessive_nesting"),
            iter(it)
        {}
        Iter iter;
    };


    // The only globals we need to parse JSON are: "How many data structures
    // deep are we?", and "What is the limit of open data structures
    // allowed?".
    struct global_state
    {
        int recursive_open_count = 0;
        int max_recursive_open_count = 0;
    };

    // When matching paired UTF-16 surrogates, we need to track a bit of state
    // between matching the first and second UTF-16 code units: namely, the
    // value of the first code unit.
    struct double_escape_locals
    {
        int first_surrogate = 0;
    };


    // Here are all the rules declared.  I've given them names that are
    // end-user friendly, so that if there is a parse error, you get a message
    // like "expected four hexadecimal digits here:", instead of "expected
    // hex_4 here:".

    bp::rule<class ws> const ws = "whitespace";

    bp::rule<class string_char, uint32_t> const string_char =
        "code point (code points <= U+001F must be escaped)";
    bp::rule<class four_hex_digits, uint32_t> const hex_4 =
        "four hexadecimal digits";
    bp::rule<class escape_seq, uint32_t> const escape_seq =
        "\\uXXXX hexadecimal escape sequence";
    bp::rule<class escape_double_seq, uint32_t, double_escape_locals> const
        escape_double_seq = "\\uXXXX hexadecimal escape sequence";
    bp::rule<class single_escaped_char, uint32_t> const single_escaped_char =
        "'\"', '\\', '/', 'b', 'f', 'n', 'r', or 't'";

    bp::rule<class null, value> const null = "null";
    bp::rule<class string, std::string> const string = "string";
    bp::rule<class number, double> const number = "number";
    bp::rule<class object_element, boost::parser::tuple<std::string, value>> const
        object_element = "object-element";
    bp::rule<class object_tag, value> const object_p = "object";
    bp::rule<class array_tag, value> const array_p = "array";

    bp::rule<class value_tag, value> const value_p = "value";



    // JSON limits whitespace to just these four characters.
    auto const ws_def = '\x09'_l | '\x0a' | '\x0d' | '\x20';

    // Since our json object representation, json::value, is polymorphic, and
    // since its default-constructed state represents the JSON value "null",
    // we need to tell a json::value that it is an object (similar to a map)
    // before we start inserting values into it.  That's why we need
    // object_init.
    auto object_init = [](auto & ctx) {
        auto & globals = _globals(ctx);
        if (globals.max_recursive_open_count < ++globals.recursive_open_count)
            throw excessive_nesting(_where(ctx).begin());
        _val(ctx) = object();
    };

    // We need object_insert because we can't just insert into the json::value
    // itself.  The json::value does not have an insert() member, because if
    // it is currently holding a number, that makes no sense.  So, for a
    // json::value x, we need to call get<object>(x) to get the object
    // interface.
    auto object_insert = [](auto & ctx) {
        value & v = _val(ctx);
        get<object>(v).insert(std::make_pair(
            std::move(_attr(ctx))[0_c], std::move(_attr(ctx)[1_c])));
    };

    // These are the array analogues of the object semantic actions above.
    auto array_init = [](auto & ctx) {
        auto & globals = _globals(ctx);
        if (globals.max_recursive_open_count < ++globals.recursive_open_count)
            throw excessive_nesting(_where(ctx).begin());
        _val(ctx) = array();
    };
    auto array_append = [](auto & ctx) {
        value & v = _val(ctx);
        get<array>(v).push_back(std::move(_attr(ctx)));
    };

    // escape_double_seq is used to match pairs of UTF-16 surrogates that form
    // a single code point.  So, after matching one UTF-16 code unit c, we
    // only want to keep going if c is a lead/high surrogate.
    auto first_hex_escape = [](auto & ctx) {
        auto & locals = _locals(ctx);
        uint32_t const cu = _attr(ctx);
        if (!boost::parser::detail::text::high_surrogate(cu))
            _pass(ctx) = false; // Not a high surrogate; explicitly fail the parse.
        else
            locals.first_surrogate = cu; // Save this initial code unit for later.
    };
    // This is also used in escape_double_seq.  When we get to this action, we
    // know we've already matched a high surrogate, and so this one had better
    // be a low surrogate, or we have a (local) parse failure.
    auto second_hex_escape = [](auto & ctx) {
        auto & locals = _locals(ctx);
        uint32_t const cu = _attr(ctx);
        if (!boost::parser::detail::text::low_surrogate(cu)) {
            _pass(ctx) = false; // Not a low surrogate; explicitly fail the parse.
        } else {
            // Success!  Write to the rule's attribute the code point that the
            // first and second code points form.
            uint32_t const high_surrogate_min = 0xd800;
            uint32_t const low_surrogate_min = 0xdc00;
            uint32_t const surrogate_offset =
                0x10000 - (high_surrogate_min << 10) - low_surrogate_min;
            uint32_t const first_cu = locals.first_surrogate;
            _val(ctx) = (first_cu << 10) + cu + surrogate_offset;
        }
    };

    // This is the verbose form of declaration for the integer and unsigned
    // integer parsers int_parser and uint_parser.  In this case, we don't
    // want to use boost::parser::hex directly, since it has a variable number
    // of digits.  We want to match exactly 4 digits, and this is how we
    // declare a hexadecimal parser that matches exactly 4.
    bp::parser_interface<bp::uint_parser<uint32_t, 16, 4, 4>> const hex_4_def;

    // We use > here instead of >>, because once we see \u, we know that
    // exactly four hex digits must follow -- no other production rule starts
    // with \u.
    auto const escape_seq_def = "\\u" > hex_4;

    // This uses the actions above and the simpler rule escape_seq to find
    // matched UTF-16 surrogate pairs.
    auto const escape_double_seq_def =
        escape_seq[first_hex_escape] >> escape_seq[second_hex_escape];

    // This symbol table recognizes each character that can appear right after
    // an escaping backslash, and, if it finds one, produces the associated
    // code point as its attribute.
    bp::symbols<uint32_t> const single_escaped_char_def = {
        {"\"", 0x0022u},
        {"\\", 0x005cu},
        {"/", 0x002fu},
        {"b", 0x0008u},
        {"f", 0x000cu},
        {"n", 0x000au},
        {"r", 0x000du},
        {"t", 0x0009u}};

    // A string may be a matched UTF-16 escaped surrogate pair, a single
    // escaped UTF-16 code unit treated as a whole code point, a single
    // escaped character like \f, or any other code point outside the range
    // [0x0000u, 0x001fu].  Note that we had to put escape_double_seq before
    // escape_seq.  Otherwise, escape_seq would eat all the escape sequences
    // before escape_double_seq could try to match them.
    auto const string_char_def = escape_double_seq | escape_seq |
                                 ('\\'_l > single_escaped_char) |
                                 (bp::cp - bp::char_(0x0000u, 0x001fu));

    // If we see the special token null, treat that as a default-constructed
    // json::value.  Note that we could have done this with a semantic action,
    // but it is best to do everything you can without semantic actions;
    // they're a lot of code.
    auto const null_def = "null" >> bp::attr(value());

    auto const string_def = bp::lexeme['"' >> *(string_char - '"') > '"'];

    // Since the JSON format for numbers is not exactly what
    // boost::parser::double_ accepts (double_ accepts too much), we need to
    // parse a JSON number as a sequence of characters, and then pass the
    // result to double_ to actually get the numeric value.  This action does
    // that.  The parser uses boost::parser::raw to produce the subrange of
    // the input that covers the number as an attribute, which is used here.
    auto parse_double = [](auto & ctx) {
        auto const cp_range = _attr(ctx);
        auto cp_first = cp_range.begin();
        auto const cp_last = cp_range.end();

        auto const result = bp::prefix_parse(cp_first, cp_last, bp::double_);
        if (result) {
            _val(ctx) = *result;
        } else {
            // This would be more efficient if we used
            // boost::container::small_vector, or std::inplace_vector from
            // C++26.
            std::vector<char> chars(cp_first, cp_last);
            auto const chars_first = &*chars.begin();
            auto chars_last = chars_first + chars.size();
            _val(ctx) = std::strtod(chars_first, &chars_last);
        }
    };

    // As indicated above, we want to match the specific formats JSON allows,
    // and then re-parse the resulting matched range within the semantic
    // action.
    auto const number_def =
        bp::raw[bp::lexeme
                    [-bp::char_('-') >>
                     (bp::char_('1', '9') >> *bp::digit | bp::char_('0')) >>
                     -(bp::char_('.') >> +bp::digit) >>
                     -(bp::char_("eE") >> -bp::char_("+-") >> +bp::digit)]]
               [parse_double];

    // Note how, in the next three parsers, we turn off backtracking by using
    // > instead of >>, once we know that there is no backtracking alternative
    // that might match if we fail to match the next element.  This produces
    // much better error messages than if you always use >>.

    auto const object_element_def = string > ':' > value_p;

    auto const object_p_def = '{'_l[object_init] >>
                              -(object_element[object_insert] % ',') > '}';

    auto const array_p_def = '['_l[array_init] >>
                             -(value_p[array_append] % ',') > ']';

    // This is the top-level parser.
    auto const value_p_def =
        number | bp::bool_ | null | string | array_p | object_p;

    // Here, we define all the rules we've declared above, which also connects
    // each rule to its _def-suffixed parser.
    BOOST_PARSER_DEFINE_RULES(
        ws,
        hex_4,
        escape_seq,
        escape_double_seq,
        single_escaped_char,
        string_char,
        null,
        string,
        number,
        object_element,
        object_p,
        array_p,
        value_p);

    // json::parse() takes a string_view as input.  It takes an optional
    // callback to use for error reporting, which defaults to a no-op that
    // ignores all errors.  It also takes an optional max recursion depth
    // limit, which defaults to the one from the JSON spec, 512.
    std::optional<value> parse(
        std::string_view str,
        diagnostic_function errors_callback = diagnostic_function(),
        int max_recursion = 512)
    {
        // Turn the input range into a UTF-32 range, so that we can be sure
        // that we fall into the Unicode-aware parsing path inside parse()
        // below.
        auto const range = boost::parser::as_utf32(str);
        using iter_t = decltype(range.begin());

        if (max_recursion <= 0)
            max_recursion = INT_MAX;

        // Initialize our globals to the current depth (0), and the max depth
        // (max_recursion).
        global_state globals{0, max_recursion};
        bp::callback_error_handler error_handler(errors_callback);
        // Make a new parser that includes the globals and error handler.
        auto const parser = bp::with_error_handler(
            bp::with_globals(value_p, globals), error_handler);

        try {
            // Parse.  If no exception is thrown, due to: a failed expectation
            // (such as foo > bar, where foo matches the input, but then bar
            // cannot); or because the nesting depth is exceeded; we simply
            // return the result of the parse.  The result will contextually
            // convert to false if the parse failed.  Note that the
            // failed-expectation exception is caught internally, and used to
            // generate an error message.
            return bp::parse(range, parser, ws);
        } catch (excessive_nesting<iter_t> const & e) {
            // If we catch an excessive_nesting exception, just report it
            // and return an empty/failure result.
            if (errors_callback) {
                std::string const message = "error: Exceeded maximum number (" +
                                            std::to_string(max_recursion) +
                                            ") of open arrays and/or objects";
                std::stringstream ss;
                bp::write_formatted_message(
                    ss, "", range.begin(), e.iter, range.end(), message);
                errors_callback(ss.str());
            }
        }

        return {};
    }

}

std::string file_slurp(std::ifstream & ifs)
{
    std::string retval;
    while (ifs) {
        char const c = ifs.get();
        retval += c;
    }
    if (!retval.empty() && retval.back() == -1)
        retval.pop_back();
    return retval;
}

int main(int argc, char * argv[])
{
    if (argc < 2) {
        std::cerr << "A filename to parse is required.\n";
        exit(1);
    }

    std::ifstream ifs(argv[1]);
    if (!ifs) {
        std::cerr << "Unable to read file '" << argv[1] << "'.\n";
        exit(1);
    }

    // Read in the entire file.
    std::string const file_contents = file_slurp(ifs);
    // Parse the contents.  If there is an error, just stream it to cerr.
    auto json = json::parse(
        file_contents, [](std::string const & msg) { std::cerr << msg; });
    if (!json) {
        std::cerr << "Parse failure.\n";
        exit(1);
    }

    std::cout << "Parse successful; contents:\n" << *json << "\n";

    return 0;
}
\end{code}

\subsection{Parsing JSON With Callbacks}

This is just like the previous extended JSON parser example, except that it drops all the code that defines a JSON value, array, object, etc. It communicates events within the parse, and the value associated with each event. For instance, when a string is parsed, a callback is called that indicates this, along with the resulting \texttt{std::string}.

\begin{code}
#include <boost/parser/parser.hpp>
#include <boost/parser/transcode_view.hpp>

#include <fstream>
#include <vector>
#include <climits>


namespace json {

    namespace bp = ::boost::parser;
    using namespace bp::literals;

    template<typename Iter>
    struct excessive_nesting : std::runtime_error
    {
        excessive_nesting(Iter it) :
            runtime_error("excessive_nesting"), iter(it)
        {}
        Iter iter;
    };


    struct global_state
    {
        int recursive_open_count = 0;
        int max_recursive_open_count = 0;
    };

    struct double_escape_locals
    {
        int first_surrogate = 0;
    };


    bp::rule<class ws> const ws = "whitespace";

    bp::rule<class string_char, uint32_t> const string_char =
        "code point (code points <= U+001F must be escaped)";
    bp::rule<class four_hex_digits, uint32_t> const hex_4 =
        "four hexadecimal digits";
    bp::rule<class escape_seq, uint32_t> const escape_seq =
        "\\uXXXX hexadecimal escape sequence";
    bp::rule<class escape_double_seq, uint32_t, double_escape_locals> const
        escape_double_seq = "\\uXXXX hexadecimal escape sequence";
    bp::rule<class single_escaped_char, uint32_t> const single_escaped_char =
        "'\"', '\\', '/', 'b', 'f', 'n', 'r', or 't'";

    bp::callback_rule<class null_tag> const null = "null";

    // Since we don't create polymorphic values in this parse, we need to be
    // able to report that we parsed a bool, so we need a callback rule for
    // this.
    bp::callback_rule<class bool_tag, bool> const bool_p = "boolean";

    bp::callback_rule<class string_tag, std::string> const string = "string";
    bp::callback_rule<class number_tag, double> const number = "number";

    // object_element is broken up into the key (object_element_key) and the
    // whole thing (object_element).  This was done because the value after
    // the ':' may have many parts.  It may be an array, for example.  This
    // implies that we need to report that we have the string part of the
    // object-element, and that the rest -- the value -- is coming.
    bp::callback_rule<class object_element_key_tag, std::string> const
        object_element_key = "string";
    bp::rule<class object_element_tag> const object_element = "object-element";

    // object gets broken up too, to enable the reporting of the beginning and
    // end of the object when '{' or '}' is parsed, respectively.  The same
    // thing is done for array, below.
    bp::callback_rule<class object_open_tag> const object_open = "'{'";
    bp::callback_rule<class object_close_tag> const object_close = "'}'";
    bp::rule<class object_tag> const object = "object";

    bp::callback_rule<class array_open_tag> const array_open = "'['";
    bp::callback_rule<class array_close_tag> const array_close = "']'";
    bp::rule<class array_tag> const array = "array";

    // value no longer produces an attribute, and it has no callback either.
    // Each individual possible kind of value (string, array, etc.) gets
    // reported separately.
    bp::rule<class value_tag> const value = "value";


    // Since we use these tag types as function parameters in the callbacks,
    // they need to be complete types.
    class null_tag {};
    class bool_tag {};
    class string_tag {};
    class number_tag {};
    class object_element_key_tag {};
    class object_open_tag {};
    class object_close_tag {};
    class array_open_tag {};
    class array_close_tag {};


    auto const ws_def = '\x09'_l | '\x0a' | '\x0d' | '\x20';

    auto first_hex_escape = [](auto & ctx) {
        auto & locals = _locals(ctx);
        uint32_t const cu = _attr(ctx);
        if (!boost::parser::detail::text::high_surrogate(cu))
            _pass(ctx) = false;
        else
            locals.first_surrogate = cu;
    };
    auto second_hex_escape = [](auto & ctx) {
        auto & locals = _locals(ctx);
        uint32_t const cu = _attr(ctx);
        if (!boost::parser::detail::text::low_surrogate(cu)) {
            _pass(ctx) = false;
        } else {
            uint32_t const high_surrogate_min = 0xd800;
            uint32_t const low_surrogate_min = 0xdc00;
            uint32_t const surrogate_offset =
                0x10000 - (high_surrogate_min << 10) - low_surrogate_min;
            uint32_t const first_cu = locals.first_surrogate;
            _val(ctx) = (first_cu << 10) + cu + surrogate_offset;
        }
    };

    bp::parser_interface<bp::uint_parser<uint32_t, 16, 4, 4>> const hex_4_def;

    auto const escape_seq_def = "\\u" > hex_4;

    auto const escape_double_seq_def =
        escape_seq[first_hex_escape] >> escape_seq[second_hex_escape];

    bp::symbols<uint32_t> const single_escaped_char_def = {
        {"\"", 0x0022u},
        {"\\", 0x005cu},
        {"/", 0x002fu},
        {"b", 0x0008u},
        {"f", 0x000cu},
        {"n", 0x000au},
        {"r", 0x000du},
        {"t", 0x0009u}};

    auto const string_char_def = escape_double_seq | escape_seq |
                                 ('\\'_l > single_escaped_char) |
                                 (bp::cp - bp::char_(0x0000u, 0x001fu));

    auto const null_def = "null"_l;

    auto const bool_p_def = bp::bool_;

    auto const string_def = bp::lexeme['"' >> *(string_char - '"') > '"'];

    auto parse_double = [](auto & ctx) {
        auto const cp_range = _attr(ctx);
        auto cp_first = cp_range.begin();
        auto const cp_last = cp_range.end();

        auto const result = bp::prefix_parse(cp_first, cp_last, bp::double_);
        if (result) {
            _val(ctx) = *result;
        } else {
            // This would be more efficient if we used
            // boost::container::small_vector, or std::inplace_vector from
            // C++26.
            std::vector<char> chars(cp_first, cp_last);
            auto const chars_first = &*chars.begin();
            auto chars_last = chars_first + chars.size();
            _val(ctx) = std::strtod(chars_first, &chars_last);
        }
    };

    auto const number_def =
        bp::raw[bp::lexeme
                    [-bp::char_('-') >>
                     (bp::char_('1', '9') >> *bp::digit | bp::char_('0')) >>
                     -(bp::char_('.') >> +bp::digit) >>
                     -(bp::char_("eE") >> -bp::char_("+-") >> +bp::digit)]]
               [parse_double];

    // The object_element_key parser is exactly the same as the string parser.
    // Note that we did *not* use string here, though; we used string_def.  If
    // we had used string, its callback would have been called first, and
    // worse still, since it moves its attribute, the callback for
    // object_element_key would always report the empty string, because the
    // string callback would have consumed it first.
    auto const object_element_key_def = string_def;

    auto const object_element_def = object_element_key > ':' > value;

    // This is a very straightforward way to write object_def when we know we
    // don't care about attribute-generating (non-callback) parsing.  If we
    // wanted to support both modes in one parser definition, we could have
    // written:
    //    auto const object_open_def = eps;
    //    auto const object_close_def = eps;
    //    auto const object_def = '{' >> object_open >>
    //                             -(object_element % ',') >
    //                            '}' >> object_close;
    auto const object_open_def = '{'_l;
    auto const object_close_def = '}'_l;
    auto const object_def = object_open >>
                            -(object_element % ',') > object_close;

    auto const array_open_def = '['_l;
    auto const array_close_def = ']'_l;
    auto const array_def = array_open >> -(value % ',') > array_close;

    auto const value_def = number | bool_p | null | string | array | object;

    BOOST_PARSER_DEFINE_RULES(
        ws,
        hex_4,
        escape_seq,
        escape_double_seq,
        single_escaped_char,
        string_char,
        null,
        bool_p,
        string,
        number,
        object_element_key,
        object_element,
        object_open,
        object_close,
        object,
        array_open,
        array_close,
        array,
        value);

    // The parse function loses its attribute from the return type; now the
    // return type is just bool.
    template<typename Callbacks>
    bool parse(
        std::string_view str,
        std::string_view filename,
        Callbacks const & callbacks,
        int max_recursion = 512)
    {
        auto const range = boost::parser::as_utf32(str);
        using iter_t = decltype(range.begin());

        if (max_recursion <= 0)
            max_recursion = INT_MAX;

        global_state globals{0, max_recursion};
        // This is a different error handler from the json.cpp example, just
        // to show different options.
        bp::stream_error_handler error_handler(filename);
        auto const parser = bp::with_error_handler(
            bp::with_globals(value, globals), error_handler);

        try {
            // This is identical to the parse() call in json.cpp, except that
            // it is callback_parse() instead, and it takes the callbacks
            // parameter.
            return bp::callback_parse(range, parser, ws, callbacks);
        } catch (excessive_nesting<iter_t> const & e) {
            std::string const message = "error: Exceeded maximum number (" +
                                        std::to_string(max_recursion) +
                                        ") of open arrays and/or objects";
            bp::write_formatted_message(
                std::cout,
                filename,
                range.begin(),
                e.iter,
                range.end(),
                message);
        }

        return {};
    }

}

std::string file_slurp(std::ifstream & ifs)
{
    std::string retval;
    while (ifs) {
        char const c = ifs.get();
        retval += c;
    }
    if (!retval.empty() && retval.back() == -1)
        retval.pop_back();
    return retval;
}

// This is our callbacks-struct.  It has a callback for each of the kinds of
// callback rules in our parser.  If one were missing, you'd get a pretty
// nasty template instantiation error.  Note that these are all const members;
// callback_parse() takes the callbacks object by constant reference.
struct json_callbacks
{
    void operator()(json::null_tag) const { std::cout << "JSON null value\n"; }
    void operator()(json::bool_tag, bool b) const
    {
        indent();
        std::cout << "JSON bool " << (b ? "true" : "false") << "\n";
    }
    void operator()(json::string_tag, std::string s) const
    {
        indent();
        std::cout << "JSON string \"" << s << "\"\n";
    }
    void operator()(json::number_tag, double d) const
    {
        indent();
        std::cout << "JSON number " << d << "\n";
    }
    void operator()(json::object_element_key_tag, std::string key) const
    {
        indent();
        std::cout << "JSON object element with key \"" << key
                  << "\" and value...\n";
    }
    void operator()(json::object_open_tag) const
    {
        indent(1);
        std::cout << "Beginning of JSON object.\n";
    }
    void operator()(json::object_close_tag) const
    {
        indent(-1);
        std::cout << "End of JSON object.\n";
    }
    void operator()(json::array_open_tag) const
    {
        indent(1);
        std::cout << "Beginning of JSON array.\n";
    }
    void operator()(json::array_close_tag) const
    {
        indent(-1);
        std::cout << "End of JSON array.\n";
    }

    void indent(int level_bump = 0) const
    {
        if (level_bump < 0)
            indent_.resize(indent_.size() - 2);
        std::cout << indent_;
        if (0 < level_bump)
            indent_ += "  ";
    }
    mutable std::string indent_;
};

int main(int argc, char * argv[])
{
    if (argc < 2) {
        std::cerr << "A filename to parse is required.\n";
        exit(1);
    }

    std::ifstream ifs(argv[1]);
    if (!ifs) {
        std::cerr << "Unable to read file '" << argv[1] << "'.\n";
        exit(1);
    }

    std::string const file_contents = file_slurp(ifs);
    bool success = json::parse(file_contents, argv[1], json_callbacks{});
    if (success) {
        std::cout << "Parse successful!\n";
    } else {
        std::cerr << "Parse failure.\n";
        exit(1);
    }

    return 0;
}
\end{code}

Note that here, I was keeping things simple to stay close to the previous parser. If you want to do callback parsing, you might want that because you're limited in how much memory you can allocate, or because the JSON you're parsing is really huge, and you only need to retain certain parts of it.

If this is the case, one possible change that might be appealing would be to reduce the memory allocations. The only memory allocation that the parser does is the one we told it to do --- it allocates \texttt{std::strings}. If we instead used \texttt{boost::container::small\_vector<char, 1024>}, it would only ever allocate if it encountered a string larger than 1024 bytes. We would also want to change the callbacks to take \texttt{const \&} parameters instead of using pass-by-value.
